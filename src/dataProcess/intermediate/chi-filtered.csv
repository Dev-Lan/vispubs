Conference,Year,Title,DOI,Abstract,AuthorNames-Deduped,Award
CHI,2023,VRGit: A Version Control System for Collaborative Content Creation in Virtual Reality,10.1145/3544548.3581136,"Immersive authoring tools allow users to intuitively create and manipulate 3D scenes while immersed in Virtual Reality (VR). Collaboratively designing these scenes is a creative process that involves numerous edits, explorations of design alternatives, and frequent communication with collaborators. Version Control Systems (VCSs) help users achieve this by keeping track of the version history and creating a shared hub for communication. However, most VCSs are unsuitable for managing the version history of VR content because their underlying line differencing mechanism is designed for text and lacks the semantic information of 3D content; and the widely adopted commit model is designed for asynchronous collaboration rather than real-time awareness and communication in VR. We introduce VRGit, a new collaborative VCS that visualizes version history as a directed graph composed of 3D miniatures, and enables users to easily navigate versions, create branches, as well as preview and reuse versions directly in VR. Beyond individual uses, VRGit also facilitates synchronous collaboration in VR by providing awareness of users’ activities and version history through portals and shared history visualizations. In a lab study with 14 participants (seven groups), we demonstrate that VRGit enables users to easily manage version history both individually and collaboratively in VR.",Lei Zhang;Ashutosh Agrawal;Steve Oney;Anhong Guo,
CHI,2023,Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces,10.1145/3544548.3580879,"Transitional Interfaces are a yet underexplored, emerging class of cross-reality user interfaces that enable users to freely move along the reality-virtuality continuum during collaboration. To analyze and understand how such collaboration unfolds, we propose four analytical lenses derived from an exploratory study of transitional collaboration with 15 dyads. While solving a complex spatial optimization task, participants could freely switch between three contexts, each with different displays (desktop screens, tablet-based augmented reality, head-mounted virtual reality), input techniques (mouse, touch, handheld controllers), and visual representations (monoscopic and allocentric 2D/3D maps, stereoscopic egocentric views). Using the rich qualitative and quantitative data from our study, we evaluated participants’ perceptions of transitional collaboration and identified commonalities and differences between dyads. We then derived four lenses including metrics and visualizations to analyze key aspects of transitional collaboration: (1) place and distance, (2) temporal patterns, (3) group use of contexts, (4) individual use of contexts.",Jan-Henrik Schröder;Daniel Schacht;Niklas Peper;Anita Marie Hamurculu;Hans-Christian Jetter,BP
CHI,2023,Collaboration with Conversational AI Assistants for UX Evaluation: Questions and How to Ask them (Voice vs. Text),10.1145/3544548.3581247,"AI is promising in assisting UX evaluators with analyzing usability tests, but its judgments are typically presented as non-interactive visualizations. Evaluators may have questions about test recordings, but have no way of asking them. Interactive conversational assistants provide a Q&A dynamic that may improve analysis efficiency and evaluator autonomy. To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice. We found that participants asked for five categories of information: user actions, user mental model, help from the AI assistant, product and task information, and user demographics. Those who used the text assistant asked more questions, but the question lengths were similar. The text assistant was perceived as significantly more efficient, but both were rated equally in satisfaction and trust. We also provide design considerations for future conversational AI assistants for UX evaluation.",Emily Kuang;Ehsan Jahangirzadeh Soure;Mingming Fan 0001;Jian Zhao 0010;Kristen Shinohara,
CHI,2023,Rapsai: Accelerating Machine Learning Prototyping of Multimedia Applications through Visual Programming,10.1145/3544548.3581338,"In recent years, there has been a proliferation of multimedia applications that leverage machine learning (ML) for interactive experiences. Prototyping ML-based applications is, however, still challenging, given complex workflows that are not ideal for design and experimentation. To better understand these challenges, we conducted a formative study with seven ML practitioners to gather insights about common ML evaluation workflows. The study helped us derive six design goals, which informed Rapsai1, a visual programming platform for rapid and iterative development of end-to-end ML-based multimedia applications. Rapsai features a node-graph editor to facilitate interactive characterization and visualization of ML model performance. Rapsai streamlines end-to-end prototyping with interactive data augmentation and model comparison capabilities in its no-coding environment. Our evaluation of Rapsai in four real-world case studies (N=15) suggests that practitioners can accelerate their workflow, make more informed decisions, analyze strengths and weaknesses, and holistically evaluate model behavior with real-world input.",Ruofei Du;Na Li;Jing Jin;Michelle Carney;Scott Miles;Maria Kleiner;Xiuxiu Yuan;Yinda Zhang 0001;Anuva Kulkarni;Xingyu Liu;Ahmed Sabie;Sergio Orts-Escolano;Abhishek Kar;Ping Yu;Ram Iyengar;Adarsh Kowdle;Alex Olwal,HM
CHI,2023,Charagraph: Interactive Generation of Charts for Realtime Annotation of Data-Rich Paragraphs,10.1145/3544548.3581091,"Documents often have paragraphs packed with numbers that are difficult to extract, compare, and interpret. To help readers make sense of data in text, we introduce the concept of Charagraphs: dynamically generated interactive charts and annotations for in-situ visualization, comparison, and manipulation of numeric data included within text. Three Charagraph characteristics are defined: leveraging related textual information about data; integrating textual and graphical representations; and interacting at different contexts. We contribute a document viewer to select in-text data; generate and customize Charagraphs; merge and refine a Charagraph using other in-text data; and identify, filter, compare, and sort data synchronized between text and visualization. Results of a study show participants can easily create Charagraphs for diverse examples of data-rich text, and when answering questions about data in text, participants were more correct compared to only reading text.",Damien Masson;Sylvain Malacria;Géry Casiez;Daniel Vogel 0001,
CHI,2023,ChartDetective: Easy and Accurate Interactive Data Extraction from Complex Vector Charts,10.1145/3544548.3581113,"Extracting underlying data from rasterized charts is tedious and inaccurate; values might be partially occluded or hard to distinguish, and the quality of the image limits the precision of the data being recovered. To address these issues, we introduce a semi-automatic system leveraging vector charts to extract the underlying data easily and accurately. The system is designed to make the most of vector information by relying on a drag-and-drop interface combined with selection, filtering, and previsualization features. A user study showed that participants spent less than 4 minutes to accurately recover data from charts published at CHI with diverse styles, thousands of data points, a combination of different encodings, and elements partially or completely occluded. Compared to other approaches relying on raster images, our tool successfully recovered all data, even when hidden, with a 78% lower relative error.",Damien Masson;Sylvain Malacria;Daniel Vogel 0001;Edward Lank;Géry Casiez,BP
CHI,2023,How Instructional Data Physicalisation Fosters Reflection in Personal Informatics,10.1145/3544548.3581198,"The ever-increasing number of devices quantifying our lives offers a perspective of high awareness of one’s wellbeing, yet it remains a challenge for personal informatics (PI) to effectively support data-based reflection. Effective reflection is recognised as a key factor for PI technologies to foster wellbeing. Here, we investigate whether building tangible representations of health data can offer engaging and reflective experiences. We conducted a between-subjects study where n = 60 participants explored their immediate blood pressure data in relation to medical norms. They either used a standard mobile app, built a data representation from LEGO® bricks based on instructions, or completed a free-form brick build. We found that building with instructions fostered more comparison and using bricks fostered focused attention. The free-form condition required extra time to complete, and lacked usability. Our work shows that designing instructional physicalisation experiences for PI is a means of improving engagement and understanding of personal data.",Marit Bentvelzen;Julia Dominiak;Jasmin Niess;Frederique Henraat;Pawel W. Wozniak,
CHI,2023,Speech-Augmented Cone-of-Vision for Exploratory Data Analysis,10.1145/3544548.3581283,"Mutual awareness of visual attention is crucial for successful collaboration. Previous research has explored various ways to represent visual attention, such as field-of-view visualizations and cursor visualizations based on eye-tracking, but these methods have limitations. Verbal communication is often utilized as a complementary strategy to overcome such disadvantages. This paper proposes a novel method that combines verbal communication with the Cone of Vision to improve gaze inference and mutual awareness in VR. We conducted a within-group study with pairs of participants who performed a collaborative analysis of data visualizations in VR. We found that our proposed method provides a better approximation of eye gaze than the approximation provided by head direction. Furthermore, we release the first collaborative head, eyes, and verbal behaviour dataset. The results of this study provide a foundation for investigating the potential of verbal communication as a tool for enhancing visual cues for joint attention.",Riccardo Bovo;Daniele Giunchi;Ludwig Sidenmark;Joshua Newn;Hans Gellersen;Enrico Costanza;Thomas Heinis,
CHI,2023,"Communicating Consequences: Visual Narratives, Abstraction, and Polysemy in Rural Bangladesh",10.1145/3544548.3581149,"Information communication and visualization practices reflect two centuries of developments of conventions and best practices which may not be reflective of global audiences’ methods for conveying information. Contrasting between rural traditional visual culture and contemporary HCI and data-visualization, we argue that an understanding of traditional practices for information visualization is required for building rich data-narratives and making data-driven systems more accessible and culturally situated. Our ten-month ethnographic study investigates how rural Bangladeshi communities construct narratives through visual media. 1 Our observation, interviews, and FGDs (n=54) expose how participants convey risk management, decision-making, and monetary management practices to their peers. We find that villagers used a rich network of polysemic symbols and abstractions to manifest subjectivity, factuality, consequence, situatedness, and uncertainty; varied visual attributes for constructing narratives; and emphasized material relations among components in visuals. These findings inform the design of future systems for decision support in a culturally situated manner.",Sharifa Sultana;Syed Ishtiaque Ahmed;Jeffrey M. Rzeszotarski,
CHI,2023,GeoCamera: Telling Stories in Geographic Visualizations with Camera Movements,10.1145/3544548.3581470,"In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements.",Wenchao Li 0005;Zhan Wang;Yun Wang 0012;Di Weng;Liwenhan Xie;Siming Chen 0001;Haidong Zhang;Huamin Qu,
CHI,2023,NetworkNarratives: Data Tours for Visual Network Exploration and Analysis,10.1145/3544548.3581452,"This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about network exploration, and can aid the dissemination of analysis results. NetworkNarratives is available online, together with detailed illustrations for each tour.",Wenchao Li 0005;Sarah Schöttler;James Scott-Brown;Yun Wang 0012;Siming Chen 0001;Huamin Qu;Benjamin Bach,
CHI,2023,Notable: On-the-fly Assistant for Data Storytelling in Computational Notebooks,10.1145/3544548.3580965,"Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user study with 12 data workers. The feedback from user study participants verifies its effectiveness and usability.",Haotian Li 0001;Lu Ying;Haidong Zhang;Yingcai Wu;Huamin Qu;Yun Wang 0012,
CHI,2023,When do data visualizations persuade? The impact of prior attitudes on learning about correlations from scatterplot visualizations,10.1145/3544548.3581330,"Data visualizations are vital to scientific communication on critical issues such as public health, climate change, and socioeconomic policy. They are often designed not just to inform, but to persuade people to make consequential decisions (e.g., to get vaccinated). Are such visualizations persuasive, especially when audiences have beliefs and attitudes that the data contradict? In this paper we examine the impact of existing attitudes (e.g., positive or negative attitudes toward COVID-19 vaccination) on changes in beliefs about statistical correlations when viewing scatterplot visualizations with different representations of statistical uncertainty. We find that strong prior attitudes are associated with smaller belief changes when presented with data that contradicts existing views, and that visual uncertainty representations may amplify this effect. Finally, even when participants’ beliefs about correlations shifted their attitudes remained unchanged, highlighting the need for further research on whether data visualizations can drive longer-term changes in views and behavior.",Douglas Markant;Milad Rogha;Alireza Karduni;Ryan Wesslen;Wenwen Dou,
CHI,2023,Here and Now: Creating Improvisational Dance Movements with a Mixed Reality Mirror,10.1145/3544548.3580666,"This paper explores using mixed reality (MR) mirrors for supporting improvisational dance making. Motivated by the prevalence of mirrors in dance studios and inspired by Forsythe’s Improvisation Technologies, we conducted workshops with 13 dancers and choreographers to inform the design of future MR visualisation and annotation tools for dance. The workshops involved using a prototype MR mirror as a technology probe that reveals the spatial and temporal relationships between the reflected dancing body and its surroundings during improvisation; speed dating group interviews around future design ideas; follow-up surveys and extended interviews with a digital media dance artist and a dance educator. Our findings highlight how the MR mirror enriches dancers’ temporal and spatial perception, creates multi-layered presence, and affords appropriation by dancers. We also discuss the unique place of MR mirrors in the theoretical context of dance and in the history of movement visualisation, and distil lessons for broader HCI research.",Qiushi Zhou;Louise Grebel;Andrew Irlitti;Julie Ann Minaai;Jorge Gonçalves 0001;Eduardo Velloso,
CHI,2023,ConceptEVA: Concept-Based Interactive Exploration and Customization of Document Summaries,10.1145/3544548.3581260,"With the most advanced natural language processing and artificial intelligence approaches, effective summarization of long and multi-topic documents—such as academic papers—for readers from different domains still remains a challenge. To address this, we introduce ConceptEVA, a mixed-initiative approach to generate, evaluate, and customize summaries for long and multi-topic documents. ConceptEVA incorporates a custom multi-task longformer encoder decoder to summarize longer documents. Interactive visualizations of document concepts as a network reflecting both semantic relatedness and co-occurrence help users focus on concepts of interest. The user can select these concepts and automatically update the summary to emphasize them. We present two iterations of ConceptEVA evaluated through an expert review and a within-subjects study. We find that participants’ satisfaction with customized summaries through ConceptEVA is higher than their own manually-generated summary, while incorporating critique into the summaries proved challenging. Based on our findings, we make recommendations for designing summarization systems incorporating mixed-initiative interactions.",Xiaoyu Zhang;Jianping Kelvin Li;Po-Wei Chi;Senthil K. Chandrasegaran;Kwan-Liu Ma,
CHI,2023,NFTDisk: Visual Detection of Wash Trading in NFT Markets,10.1145/3544548.3581466,"With the growing popularity of Non-Fungible Tokens (NFT), a new type of digital assets, various fraudulent activities have appeared in NFT markets. Among them, wash trading has become one of the most common frauds in NFT markets, which attempts to mislead investors by creating fake trading volumes. Due to the sophisticated patterns of wash trading, only a subset of them can be detected by automatic algorithms, and manual inspection is usually required. We propose NFTDisk, a novel visualization for investors to identify wash trading activities in NFT markets, where two linked visualization modules are presented: a radial visualization module with a disk metaphor to overview NFT transactions and a flow-based visualization module to reveal detailed NFT flows at multiple levels. We conduct two case studies and an in-depth user interview with 14 NFT investors to evaluate NFTDisk. The results demonstrate its effectiveness in exploring wash trading activities in NFT markets.",Xiaolin Wen;Yong Wang 0021;Xuanwu Yue;Feida Zhu 0001;Min Zhu,
CHI,2023,"UndoPort: Exploring the Influence of Undo-Actions for Locomotion in Virtual Reality on the Efficiency, Spatial Understanding and User Experience",10.1145/3544548.3581557,"When we get lost in Virtual Reality (VR) or want to return to a previous location, we use the same methods of locomotion for the way back as for the way forward. This is time-consuming and requires additional physical orientation changes, increasing the risk of getting tangled in the headsets’ cables. In this paper, we propose the use of undo actions to revert locomotion steps in VR. We explore eight different variations of undo actions as extensions of point&teleport, based on the possibility to undo position and orientation changes together with two different visualizations of the undo step (discrete and continuous). We contribute the results of a controlled experiment with 24 participants investigating the efficiency and orientation of the undo techniques in a radial maze task. We found that the combination of position and orientation undo together with a discrete visualization resulted in the highest efficiency without increasing orientation errors.",Florian Müller 0003;Arantxa Ye;Dominik Schön;Julian Rasch,
CHI,2023,AeroRigUI: Actuated TUIs for Spatial Interaction using Rigging Swarm Robots on Ceilings in Everyday Space,10.1145/3544548.3581437,"We present AeroRigUI, an actuated tangible UI for 3D spatial embodied interaction. Using strings controlled by self-propelled swarm robots with a reeling mechanism on ceiling surfaces, our approach enables rigging (control through strings) physical objects’ position and orientation in the air. This can be applied to novel interactions in 3D space, including dynamic physical affordances, 3D information displays, and haptics. Utilizing the ceiling, an often underused room area, AeroRigUI can be applied for a range of applications such as room organization, data physicalization, and animated expressions. We demonstrate the applications based on our proof-of-concept prototype, which includes the hardware design of the rigging robots, named RigBots, and the software design for mid-air object control via interactive string manipulation. We also introduce technical evaluation and analysis of our approach prototype to address the hardware feasibility and safety. Overall, AeroRigUI enables a novel spatial and tangible UI system with great controllability and deployability.",Lilith Yu;Chenfeng Gao;David Wu;Ken Nakagaki,
CHI,2023,Polagons: Designing and Fabricating Polarized Light Mosaics with User-Defined Color-Changing Behaviors,10.1145/3544548.3580639,"Polarized light mosaics (PLMs) are color-changing structures that alter their appearance based on the orientation of incident polarized light. While a few artists have developed techniques for crafting PLMs by hand, the underlying material properties are difficult to reason about; there exist no tools to bridge the high-level design objectives with the low-level physics knowledge needed to create PLMs. In this paper, we introduce the first system for creating Polagons: machine-made PLMs crafted from cellophane with user-defined color changing behaviors. Our system includes an interface for designing and visualizing Polagons as well as a fabrication process based on laser cutting and welding that requires minimal assembly by the user. We define the design space for Polagons and demonstrate how formalizing the process for creating PLMs can enable new applications in fields such as education, data visualization, and fashion.",Ticha Sethapakdi;Laura Huang;Vivian Hsinyueh Chan;Lung-Pan Cheng;Fernando Fuzinatto Dall'Agnol;Mackenzie Leake;Stefanie Mueller 0001,
CHI,2023,"Computational Notebooks as Co-Design Tools: Engaging Young Adults Living with Diabetes, Family Carers, and Clinicians with Machine Learning Models",10.1145/3544548.3581424,"Engaging end user groups with machine learning (ML) models can help align the design of predictive systems with people's needs and expectations. We present a co-design study investigating the benefits and challenges of using computational notebooks to inform ML models with end user groups. We used a computational notebook to engage young adults, carers, and clinicians with an example ML model that predicted health risk in diabetes care. Through co-design workshops and retrospective interviews, we found that participants particularly valued using the interactive data visualisations of the computational notebook to scaffold multidisciplinary learning, anticipate benefits and harms of the example ML model, and create fictional feature importance plots to highlight care needs. Participants also reported challenges, from running code cells to managing information asymmetries and power imbalances. We discuss the potential of leveraging computational notebooks as interactive co-design tools to meet end user needs early in ML model lifecycles.",Amid Ayobi;Jacob Hughes;Christopher J. Duckworth;Jakub J. Dylag;Sam James;Paul Marshall;Matthew Guy;Anitha Kumaran;Adriane Chapman;Michael J. Boniface;Aisling Ann O'Kane,
CHI,2023,DataLev: Mid-air Data Physicalisation Using Acoustic Levitation,10.1145/3544548.3581016,"Data physicalisation is a technique that encodes data through the geometric and material properties of an artefact, allowing users to engage with data in a more immersive and multi-sensory way. However, current methods of data physicalisation are limited in terms of their reconfigurability and the types of materials that can be used. Acoustophoresis—a method of suspending and manipulating materials using sound waves—offers a promising solution to these challenges. In this paper, we present DataLev, a design space and platform for creating reconfigurable, multimodal data physicalisations with enriched materiality using acoustophoresis. We demonstrate the capabilities of DataLev through eight examples and evaluate its performance in terms of reconfigurability and materiality. Our work offers a new approach to data physicalisation, enabling designers to create more dynamic, engaging, and expressive artefacts.",Lei Gao;Pourang Irani;Sriram Subramanian;Gowdham Prabhakar;Diego Martínez Plasencia;Ryuji Hirayama,
CHI,2023,This Watchface Fits with my Tattoos: Investigating Customisation Needs and Preferences in Personal Tracking,10.1145/3544548.3580955,"People engage in self-tracking with diverse data collection and visualisation needs and preferences. Customisable self-tracking tools offer the potential to support individualized preferences by letting people make changes to the aesthetics and functionality of tracker displays. In this paper, we use the customisation options offered by the displays of commercial fitness smartwatches as a lens to investigate when, why and how 386 self-trackers engage in customisations in their daily lives. We find that people largely customise their trackers’ display frequently, multiple times a day, or not at all, with frequent customisations reflecting situational data, aesthetic and personal meaning needs. We discuss implications for the design of tracking tools aiming to support customisation and discuss the utility of customisations towards goal scaffolding and maintaining interest in tracking.",Rúben Gouveia 0001;Daniel A. Epstein,
CHI,2023,AI Shall Have No Dominion: on How to Measure Technology Dominance in AI-supported Human decision-making,10.1145/3544548.3581095,"In this article, we propose a conceptual and methodological framework for measuring the impact of the introduction of AI systems in decision settings, based on the concept of technological dominance, i.e. the influence that an AI system can exert on human judgment and decisions. We distinguish between a negative component of dominance (automation bias) and a positive one (algorithm appreciation) by focusing on and systematizing the patterns of interaction between human judgment and AI support, or reliance patterns, and their associated cognitive effects. We then define statistical approaches for measuring these dimensions of dominance, as well as corresponding qualitative visualizations. By reporting about four medical case studies, we illustrate how the proposed methods can be used to inform assessments of dominance and of related cognitive biases in real-world settings. Our study lays the groundwork for future investigations into the effects of introducing AI support into naturalistic and collaborative decision-making.",Federico Cabitza;Andrea Campagner;Riccardo Angius;Chiara Natali;Carlo Reverberi,
CHI,2023,AutoVis: Enabling Mixed-Immersive Analysis of Automotive User Interface Interaction Studies,10.1145/3544548.3580760,"Automotive user interface (AUI) evaluation becomes increasingly complex due to novel interaction modalities, driving automation, heterogeneous data, and dynamic environmental contexts. Immersive analytics may enable efficient explorations of the resulting multilayered interplay between humans, vehicles, and the environment. However, no such tool exists for the automotive domain. With AutoVis, we address this gap by combining a non-immersive desktop with a virtual reality view enabling mixed-immersive analysis of AUIs. We identify design requirements based on an analysis of AUI research and domain expert interviews (N=5). AutoVis supports analyzing passenger behavior, physiology, spatial interaction, and events in a replicated study environment using avatars, trajectories, and heatmaps. We apply context portals and driving-path events as automotive-specific visualizations. To validate AutoVis against real-world analysis tasks, we implemented a prototype, conducted heuristic walkthroughs using authentic data from a case study and public datasets, and leveraged a real vehicle in the analysis process.",Pascal Jansen;Julian Britten;Alexander Häusele;Thilo Segschneider;Mark Colley;Enrico Rukzio,
CHI,2023,DataDancing: An Exploration of the Design Space For Visualisation View Management for 3D Surfaces and Spaces,10.1145/3544548.3580827,"Recent studies have explored how users of immersive visualisation systems arrange data representations in the space around them. Generally, these have focused on placement centred at eye-level in absolute room coordinates. However, work in HCI exploring full-body interaction has identified zones relative to the user’s body with different roles. We encapsulate the possibilities for visualisation view management into a design space (called “DataDancing”). From this design space we extrapolate a variety of view management prototypes, each demonstrating a different combination of interaction techniques and space use. The prototypes are enabled by a full-body tracking system including novel devices for torso and foot interaction. We explore four of these prototypes, encompassing standard wall and table-style interaction as well as novel foot interaction, in depth through a qualitative user study. Learning from the results, we improve the interaction techniques and propose two hybrid interfaces that demonstrate interaction possibilities of the design space.",Jiazhou Liu;Barrett Ens;Arnaud Prouzeau;Jim Smiley;Isobel Kara Nixon;Sarah Goodwin;Tim Dwyer,
CHI,2023,GestureExplorer: Immersive Visualisation and Exploration of Gesture Data,10.1145/3544548.3580678,"This paper presents the design and evaluation of GestureExplorer, an Immersive Analytics tool that supports the interactive exploration, classification and sensemaking with large sets of 3D temporal gesture data. GestureExplorer features 3D skeletal and trajectory visualisations of gestures combined with abstract visualisations of clustered sets of gestures. By leveraging the large immersive space afforded by a Virtual Reality interface our tool allows free navigation and control of viewing perspective for users to gain a better understanding of gestures. We explored a selection of classification methods to provide an overview of the dataset that was linked to a detailed view of the data that showed different visualisation modalities. We evaluated GestureExplorer with two user studies and collected feedback from participants with diverse visualisation and analytics backgrounds. Our results demonstrated the promising capability of GestureExplorer for providing a useful and engaging experience in exploring and analysing gesture data.",Ang Li 0007;Jiazhou Liu;Maxime Cordeil;Jack Topliss;Thammathip Piumsomboon;Barrett Ens,
CHI,2023,Pearl: Physical Environment based Augmented Reality Lenses for In-Situ Human Movement Analysis,10.1145/3544548.3580715,"This paper presents Pearl, a mixed-reality approach for the analysis of human movement data in situ. As the physical environment shapes human motion and behavior, the analysis of such motion can benefit from the direct inclusion of the environment in the analytical process. We present methods for exploring movement data in relation to surrounding regions of interest, such as objects, furniture, and architectural elements. We introduce concepts for selecting and filtering data through direct interaction with the environment, and a suite of visualizations for revealing aggregated and emergent spatial and temporal relations. More sophisticated analysis is supported through complex queries comprising multiple regions of interest. To illustrate the potential of Pearl, we developed an Augmented Reality-based prototype and conducted expert review sessions and scenario walkthroughs in a simulated exhibition. Our contribution lays the foundation for leveraging the physical environment in the in-situ analysis of movement data.",Weizhou Luo;Zhongyuan Yu;Rufat Rzayev;Marc Satkowski;Stefan Gumhold;Matthew McGinity;Raimund Dachselt,
CHI,2023,ProxSituated Visualization: An Extended Model of Situated Visualization using Proxies for Physical Referents,10.1145/3544548.3580952,"Existing situated visualization models assume the user is able to directly interact with the objects and spaces to which the data refers (known as physical referents). We review a growing body of work exploring scenarios where the user interacts with a proxy representation of the physical referent rather than immediately with the object itself. This introduces a complex mixture of immediate situatedness and proxies of situatedness that goes beyond the expressiveness of current models. We propose an extended model of situated visualization that encompasses Immediate Situated Visualization and ProxSituated (Proxy of Situated) Visualization. Our model describes a set of key entities involved in proxSituated scenarios and important relationships between them. From this model, we derive design dimensions and apply them to existing situated visualization work. The resulting design space allows us to describe and evaluate existing scenarios, as well as to creatively generate new conceptual scenarios.",Kadek Ananta Satriadi;Andrew Cunningham;Ross T. Smith;Tim Dwyer;Adam Drogemuller;Bruce H. Thomas,
CHI,2023,Through Their Eyes and In Their Shoes: Providing Group Awareness During Collaboration Across Virtual Reality and Desktop Platforms,10.1145/3544548.3581093,"Many collaborative data analysis situations benefit from collaborators utilizing different platforms. However, maintaining group awareness between team members using diverging devices is difficult, not least because common ground diminishes. A person using head-mounted VR cannot physically see a user on a desktop computer even while co-located, and the desktop user cannot easily relate to the VR user’s 3D workspace. To address this, we propose the “eyes-and-shoes” principles for group awareness and abstract them into four levels of techniques. Furthermore, we evaluate these principles with a qualitative user study of 6 participant pairs synchronously collaborating across distributed desktop and VR head-mounted devices. In this study, we vary the group awareness techniques between participants and explore two visualization contexts within participants. The results of this study indicate that the more visual metaphors and views of participants diverge, the greater the level of group awareness is needed. A copy of this paper, the study preregistration, and all supplemental materials required to reproduce the study are available on OSF (link).",David Saffo;Andrea Batch;Cody Dunne;Niklas Elmqvist,
CHI,2023,Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning,10.1145/3544548.3581268,"Machine learning models with high accuracy on test data can still produce systematic failures, such as harmful biases and safety issues, when deployed in the real world. To detect and mitigate such failures, practitioners run behavioral evaluation of their models, checking model outputs for specific types of inputs. Behavioral evaluation is important but challenging, requiring that practitioners discover real-world patterns and validate systematic failures. We conducted 18 semi-structured interviews with ML practitioners to better understand the challenges of behavioral evaluation and found that it is a collaborative, use-case-first process that is not adequately supported by existing task- and domain-specific tools. Using these findings, we designed zeno, a general-purpose framework for visualizing and testing AI systems across diverse use cases. In four case studies with participants using zeno on real-world models, we found that practitioners were able to reproduce previous manual analyses and discover new systematic failures.",Ángel Alexander Cabrera;Erica Fu;Donald Bertucci;Kenneth Holstein;Ameet Talwalkar;Jason I. Hong;Adam Perer,
CHI,2023,On the Design of AI-powered Code Assistants for Notebooks,10.1145/3544548.3580940,"AI-powered code assistants, such as Copilot, are quickly becoming a ubiquitous component of contemporary coding contexts. Among these environments, computational notebooks, such as Jupyter, are of particular interest as they provide rich interface affordances that interleave code and output in a manner that allows for both exploratory and presentational work. Despite their popularity, little is known about the appropriate design of code assistants in notebooks. We investigate the potential of code assistants in computational notebooks by creating a design space (reified from a survey of extant tools) and through an interview-design study (with 15 practicing data scientists). Through this work, we identify challenges and opportunities for future systems in this space, such as the value of disambiguation for tasks like data visualization, the potential of tightly scoped domain-specific tools (like linters), and the importance of polite assistants.",Andrew M. McNutt;Chenglong Wang;Robert A. DeLine;Steven Mark Drucker,
CHI,2023,Tutor In-sight: Guiding and Visualizing Students' Attention with Mixed Reality Avatar Presentation Tools,10.1145/3544548.3581069,"Remote conferencing systems are increasingly used to supplement or even replace in-person teaching. However, prevailing conferencing systems restrict the teacher’s representation to a webcam live-stream, hamper the teacher’s use of body-language, and result in students’ decreased sense of co-presence and participation. While Virtual Reality (VR) systems may increase student engagement, the teacher may not have the time or expertise to conduct the lecture in VR. To address this issue and bridge the requirements between students and teachers, we have developed Tutor In-sight, a Mixed Reality (MR) avatar augmented into the student’s workspace based on four design requirements derived from the existing literature, namely: integrated virtual with physical space, improved teacher’s co-presence through avatar, direct attention with auto-generated body language, and usable workflow for teachers. Two user studies were conducted from the perspectives of students and teachers to determine the advantages of Tutor In-sight in comparison to two existing conferencing systems, Zoom (video-based) and Mozilla Hubs (VR-based). The participants of both studies favoured Tutor In-sight. Among others, this main finding indicates that Tutor In-sight satisfied the needs of both teachers and students. In addition, the participants’ feedback was used to empirically determine the four main teacher requirements and the four main student requirements in order to improve the future design of MR educational tools.",Santawat Thanyadit;Matthias Heintz 0001;Effie L.-C. Law,
CHI,2023,Causalvis: Visualizations for Causal Inference,10.1145/3544548.3581236,"Causal inference is a statistical paradigm for quantifying causal effects using observational data. It is a complex process, requiring multiple steps, iterations, and collaborations with domain experts. Analysts often rely on visualizations to evaluate the accuracy of each step. However, existing visualization toolkits are not designed to support the entire causal inference process within computational environments familiar to analysts. In this paper, we address this gap with Causalvis, a Python visualization package for causal inference. Working closely with causal inference experts, we adopted an iterative design process to develop four interactive visualization modules to support causal inference analysis tasks. The modules are then presented back to the experts for feedback and evaluation. We found that Causalvis effectively supported the iterative causal inference process. We discuss the implications of our findings for designing visualizations for causal inference, particularly for tasks of communication and collaboration.",Grace Guo;Ehud Karavani;Alex Endert;Bum Chul Kwon,
CHI,2023,GVQA: Learning to Answer Questions about Graphs with Visualizations via Knowledge Base,10.1145/3544548.3581067,"Graphs are common charts used to represent the topological relationship between nodes. It is a powerful tool for data analysis and information retrieval tasks involve asking questions about graphs. In formative study, we found that questions for graphs are not only about the relationship of nodes but also about the properties of graph elements. We propose a pipeline to answer natural language questions about graph visualizations and generate visual answers. We first extract the data from graphs and convert them into GML format. We design data structures to encode graph information and convert them into an knowledge base. We then extract topic entities from questions. We feed questions, entities and knowledge bases into our question-answer model to obtain the SPARQL queries for textual answers. Finally, we design a module to present the answers visually. A user study demonstrates that these visual and textual answers are useful, credible and and transparent.",Sicheng Song;Juntong Chen;Chenhui Li;Changbo Wang,
CHI,2023,Visual Belief Elicitation Reduces the Incidence of False Discovery,10.1145/3544548.3580808,"Visualization supports exploratory data analysis (EDA), but EDA frequently presents spurious charts, which can mislead people into drawing unwarranted conclusions. We investigate interventions to prevent false discovery from visualized data. We evaluate whether eliciting analyst beliefs helps guard against the over-interpretation of noisy visualizations. In two experiments, we exposed participants to both spurious and ‘true’ scatterplots, and assessed their ability to infer data-generating models that underlie those samples. Participants who underwent prior belief elicitation made 21% more correct inferences along with 12% fewer false discoveries. This benefit was observed across a variety of sample characteristics, suggesting broad utility to the intervention. However, additional interventions to highlight counterevidence and sample uncertainty did not provide significant advantage. Our findings suggest that lightweight, belief-driven interactions can yield a reliable, if moderate, reduction in false discovery. This work also suggests future directions to improve visual inference and reduce bias.",Ratanond Koonchanok;Gauri Yatindra Tawde;Gokul Ragunandhan Narayanasamy;Shalmali Walimbe;Khairi Reda,HM
CHI,2023,Why Combining Text and Visualization Could Improve Bayesian Reasoning: A Cognitive Load Perspective,10.1145/3544548.3581218,"Investigations into using visualization to improve Bayesian reasoning and advance risk communication have produced mixed results, suggesting that cognitive ability might affect how users perform with different presentation formats. Our work examines the cognitive load elicited when solving Bayesian problems using icon arrays, text, and a juxtaposition of text and icon arrays. We used a three-pronged approach to capture a nuanced picture of cognitive demand and measure differences in working memory capacity, performance under divided attention using a dual-task paradigm, and subjective ratings of self-reported effort. We found that individuals with low working memory capacity made fewer errors and experienced less subjective workload when the problem contained an icon array compared to text alone, showing that visualization improves accuracy while exerting less cognitive demand. We believe these findings can considerably impact accessible risk communication, especially for individuals with low working memory capacity.",Melanie Bancilhon;Amanda Wright;Sunwoo Ha;R. Jordan Crouser;Alvitta Ottley,
CHI,2023,FlowAR: How Different Augmented Reality Visualizations of Online Fitness Videos Support Flow for At-Home Yoga Exercises,10.1145/3544548.3580897,"Online fitness video tutorials are an increasingly popular way to stay fit at home without a personal trainer. However, to keep the screen playing the video in view, users typically disrupt their balance and break the motion flow — two main pillars for the correct execution of yoga poses. While past research partially addressed this problem, these approaches supported only a limited view of the instructor and simple movements. To enable the fluid execution of complex full-body yoga exercises, we propose FlowAR, an augmented reality system for home workouts that shows training video tutorials as always-present virtual static and dynamic overlays around the user. We tested different overlay layouts in a study with 16 participants, using motion capture equipment for baseline performance. Then, we iterated the prototype and tested it in a furnished lab simulating home settings with 12 users. Our results highlight the advantages of different visualizations and the system’s general applicability.",Hye-Young Jo;Laurenz Seidel;Michel Pahud;Mike Sinclair;Andrea Bianchi,
CHI,2023,"""You Can See the Connections"": Facilitating Visualization of Care Priorities in People Living with Multiple Chronic Health Conditions",10.1145/3544548.3580908,"Individuals with multiple chronic health conditions (MCC) often face an overwhelming set of self-management work, resulting in a need to set care priorities. Yet, much self-management work is invisible to healthcare providers. This study aimed to understand how to support the development and sharing of connections between personal values and self-management tasks through the facilitated use of an interactive visualization system: Conversation Canvas. We conducted a field study with 13 participants with MCC, 3 caregivers, and 7 primary care providers in Washington State. Analysis of interviews with MCC participants showed that developing visualizations of connections between personal values, self-management tasks, and health conditions helped individuals make sense of connections relevant to their health and wellbeing, recognize a road map of central issues and their impacts, feel respected and understood, share priorities with providers, and support value-aligned changes. These findings demonstrated potential for the guided process and visualization to support priorities-aligned care.",Hyeyoung Ryu;Andrew B. L. Berry;Catherine Y. Lim;Andrea L. Hartzler;Tad Hirsch;Juanita I Trejo;Zoë Abigail Bermet;Brandi Crawford-Gallagher;Vi Tran;Dawn M. Ferguson;David J. Cronkite;Brooks Tiffany;John Weeks;James D. Ralston,
CHI,2023,CrossCode: Multi-level Visualization of Program Execution,10.1145/3544548.3581390,"Program visualizations help to form useful mental models of how programs work, and to reason and debug code. But these visualizations exist at a fixed level of abstraction, e.g., line-by-line. In contrast, programmers switch between many levels of abstraction when inspecting program behavior. Based on results from a formative study of hand-designed program visualizations, we designed CrossCode, a web-based program visualization system for JavaScript that leverages structural cues in syntax, control flow, and data flow to aggregate and navigate program execution across multiple levels of abstraction. In an exploratory qualitative study with experts, we found that CrossCode enabled participants to maintain a strong sense of place in program execution, was conducive to explaining program behavior, and helped track changes and updates to the program state.",Devamardeep Hayatpur;Daniel Wigdor;Haijun Xia,
CHI,2023,VizProg: Identifying Misunderstandings By Visualizing Students' Coding Progress,10.1145/3544548.3581516,"Programming instructors often conduct in-class exercises to help them identify students that are falling behind and surface students’ misconceptions. However, as we found in interviews with programming instructors, monitoring students’ progress during exercises is difficult, particularly for large classes. We present VizProg, a system that allows instructors to monitor and inspect students’ coding progress in real-time during in-class exercises. VizProg represents students’ statuses as a 2D Euclidean spatial map that encodes the students’ problem-solving approaches and progress in real-time. VizProg allows instructors to navigate the temporal and structural evolution of students’ code, understand relationships between code, and determine when to provide feedback. A comparison experiment showed that VizProg helped to identify more students’ problems than a baseline system. VizProg also provides richer and more comprehensive information for identifying important student behavior. By managing students’ activities at scale, this work presents a new paradigm for improving the quality of live learning.",Ashley Ge Zhang;Yan Chen 0033;Steve Oney,
CHI,2023,DataHalo: A Customizable Notification Visualization System for Personalized and Longitudinal Interactions,10.1145/3544548.3580828,"People struggle with the overflow of smartphone notifications but often face two challenges: (1) prioritizing the informative notifications as they wish and (2) retaining the delivered information as long as they want to utilize it. In this paper, we present DataHalo, a customizable notification visualization system that represents notifications as prolonged ambient visualizations on the home screen. DataHalo supports keyword-based filtering and categorization, and draws graphical marks based on time-varying importance model to enable longitudinal interaction with the notifications. We evaluated DataHalo through a usability study (N = 17), from which we improved the interface. We then conducted a three-week deployment study (N = 12) to assess how people use DataHalo in their domestic contexts. Our study revealed that people generated various visualization settings for different kinds of apps. Drawing on both quantitative and qualitative findings, we discussed implications for supporting effective notification management through customizable ambient visualizations.",GuHyun Han;Jaehun Jung;Young-Ho Kim;Jinwook Seo,
CHI,2023,"""What else can I do?"" Examining the Impact of Community Data on Adaptation and Quality of Reflection in an Educational Game",10.1145/3544548.3580664,"Adaptation, or ability and willingness to consider an alternative approach, is a critical component of learning through reflection, especially in educational games, where there are often multiple avenues to success. As a domain, educational games have shown increased interest in using retrospective visualizations to promote and support reflection. Such visualizations, which can facilitate comparison with peer data, may also have an impact on adaptation in educational games. This has, however, not been empirically examined within the domain. In this work, we examine how comparison with other players’ data influenced adaptation, a part of reflection, in the context of a game that teaches parallel programming. Our results indicate that comparison with peers does significantly impact willingness to try a different approach, but suggest that there may also be other ways. We discuss what these results mean for future use of retrospective visualizations in educational games and present opportunities for future work.",Erica Kleinman;Jennifer Villareale;Murtuza N. Shergadwala;Zhaoqing Teng;Andy Bryant;Jichen Zhu;Magy Seif El-Nasr,
CHI,2023,Exploring Co-located Interactions with a Shape-Changing Bar Chart,10.1145/3544548.3581214,"Data-physicalizations encode data and meaning through geometry or material properties, providing a non-planar view of data, offering novel opportunities for interrogation, discovery and presentation. This field has explored how single users interact with complex 3D data, but the challenges in the application of this technology to collaborative situations have not been addressed. We describe a study exploring interactions and preferences among co-located individuals using a dynamic data-physicalization in the form of a shape-changing bar chart, and compare this to previous work with single participants. Results suggest that co-located interactions with physical data prompt non-interactive hand gestures, a mirroring of physicalizations, and novel hand gestures in comparison to single participant studies. We also note that behavioural similarities in participants between interactive tabletop studies and data-physicalizations may be capitalised upon for further development of these dynamic representations. Finally, we consider the implications and challenges for the adoption of these types of platforms.",Miriam Sturdee;Hayat Kara;Jason Alexander,
CHI,2023,Groupnamics: Designing an Interface for Overviewing and Managing Parallel Group Discussions in an Online Classroom,10.1145/3544548.3581322,"Instructors facilitating online classes have a limited ability to see and hear interactions of student groups working in parallel, which prevents them from interacting with students effectively. In this work, we explore interface design for providing an overview of parallel group discussions in online classrooms. We derive design considerations through a participatory design process and instantiate them in our visualization interface, Groupnamics. Groupnamics visualizes recent vocal activities and discussion statuses of each group in a one-page view, facilitating identification of groups where intervention may be needed. Our user study with 16 instructors confirmed that Groupnamics can successfully provide cues for when instructors should join group discussions and improvements on the perceived usefulness and ease of use over the baseline interface representing existing videoconferencing tools. Our qualitative results suggest future research directions in interface design for online parallel group discussions.",Arissa J. Sato;Zefan Sramek;Koji Yatani,
CHI,2023,Soliloquy: Fostering Poetry Comprehension Using an Interactive Think-aloud Visualization,10.1145/3544548.3581374,"Complex texts like poetry are distinct from informative texts, requiring additional subprocesses to decode and interpret. Approaching a poem without knowledge of these cognitive strategies can result in confusion and frustration—rather than comprehension. In this work, we explore how interfaces can surface and demonstrate these cognitive processes to novice readers. We introduce Soliloquy, an interface that visualizes the thoughts of an expert as they read and interpret a poem by using animations of text and pop-up tooltips. We evaluate the interface in a five-condition Mechanical Turk study (n=254) by varying the detail of thoughts, including audio, and substituting a static text control. Our study detected a significant difference in comprehension between the detail of thoughts, but not between the Soliloquy interface and static text control. We further investigate this finding in a think-aloud study (n=13), revealing the impact individual differences, experience, and cognitive load could have on Soliloquy’s effectiveness.",Zak Risha;Deniz Sonmez Unal;Erin Walker,
CHI,2023,DeepLens: Interactive Out-of-distribution Data Detection in NLP Models,10.1145/3544548.3580741,"Machine Learning (ML) has been widely used in Natural Language Processing (NLP) applications. A fundamental assumption in ML is that training data and real-world data should follow a similar distribution. However, a deployed ML model may suffer from out-of-distribution (OOD) issues due to distribution shifts in the real-world data. Though many algorithms have been proposed to detect OOD data from text corpora, there is still a lack of interactive tool support for ML developers. In this work, we propose DeepLens, an interactive system that helps users detect and explore OOD issues in massive text corpora. Users can efficiently explore different OOD types in DeepLens with the help of a text clustering method. Users can also dig into a specific text by inspecting salient words highlighted through neuron activation analysis. In a within-subjects user study with 24 participants, participants using DeepLens were able to find nearly twice more types of OOD issues accurately with 22% more confidence compared with a variant of DeepLens that has no interaction or visualization support.",Da Song;Zhijie Wang;Yuheng Huang;Lei Ma 0003;Tianyi Zhang 0001,
CHI,2023,"Passenger Perceptions, Information Preferences, and Usability of Crowding Visualizations on Public Displays in Transit Stations and Vehicles",10.1145/3544548.3581241,"Large crowds in public transit stations and vehicles introduce obstacles for wayfinding, hygiene, and physical distancing. Public displays that currently provide on-site transit information could also provide critical crowdedness information. Therefore, we examined people’s crowd perceptions and information preferences before and during the pandemic, and designs for visualizing crowdedness to passengers. We first report survey results with public transit users (n = 303), including the usability results of three crowdedness visualization concepts. Then, we present two animated crowd simulations on public displays that we evaluated in a field study (n = 44). We found that passengers react very positively to crowding information, especially before boarding a vehicle. Visualizing the exact physical spaces occupied on transit vehicles was most useful for avoiding crowded areas. However, visualizing the overall fullness of vehicles was the easiest to understand. We discuss design implications for communicating crowding information to support decision-making and promote a sense of safety.",Leah Zhang-Kennedy;Saira Aziz;Oluwafunminitemi (Temi) Oluwadare;Lyndon Pan;Zeyu Wu;Sydney E. C. Lamorea;Soda Li;Michael Sun;Ville Mäkelä,
CHI,2023,"Going, Going, Gone: Exploring Intention Communication for Multi-User Locomotion in Virtual Reality",10.1145/3544548.3581259,"Exploring virtual worlds together with others adds a social component to the Virtual Reality (VR) experience that increases connectedness. In the physical world, joint locomotion comes naturally through implicit intention communication and subsequent adjustments of the movement patterns. In VR, however, discrete locomotion techniques such as point&teleport come without prior intention communication, hampering the collective experience. Related work proposes fixed groups, with a single person controlling the group movement, resulting in the loss of individual movement capabilities. To close the gap and mediate between these two extremes, we introduce three intention communication methods and explore them with two baseline methods. We contribute the results of a controlled experiment (n=20) investigating these methods from the perspective of a leader and a follower in a dyadic locomotion task. Our results suggest shared visualizations support the understanding of movement intentions, increasing the group feeling while maintaining individual freedom of movement.",Julian Rasch;Vladislav Dmitrievic Rusakov;Martin Schmitz;Florian Müller 0003,BP
CHI,2023,Chart Reader: Accessible Visualization Experiences Designed with Screen Reader Users,10.1145/3544548.3581186,"Even though screen readers are a core accessibility tool for blind and low vision individuals (BLVIs), most visualizations are incompatible with screen readers. To improve accessible visualization experiences, we partnered with 10 BLV screen reader users (SRUs) in an iterative co-design study to design and develop accessible visualization experiences that afford SRUs the autonomy to interactively read and understand visualizations and their underlying data. During the five-month study, we explored accessible visualization prototypes with our design partners for three one-hour sessions. Our results provide feedback on the synthesized design concepts we explored, why (or why not) they aid comprehension and exploration for SRUs, and how differing design concepts can fit into cohesive accessible visualization experiences. We contribute both Chart Reader, a web-based accessibility engine resulting from our design iterations, and our distilled study findings—organized by design dimensions—in the creation of comprehensive accessible visualization experiences.",John R. Thompson 0002;Jesse J. Martinez;Alper Sarikaya 0001;Edward Cutrell;Bongshin Lee,
CHI,2023,Data Abstraction Elephants: The Initial Diversity of Data Representations and Mental Models,10.1145/3544548.3580669,"Two people looking at the same dataset will create different mental models, prioritize different attributes, and connect with different visualizations. We seek to understand the space of data abstractions associated with mental models and how well people communicate their mental models when sketching. Data abstractions have a profound influence on the visualization design, yet it’s unclear how universal they may be when not initially influenced by a representation. We conducted a study about how people create their mental models from a dataset. Rather than presenting tabular data, we presented each participant with one of three datasets in paragraph form, to avoid biasing the data abstraction and mental model. We observed various mental models, data abstractions, and depictions from the same dataset, and how these concepts are influenced by communication and purpose-seeking. Our results have implications for visualization design, especially during the discovery and data collection phase.",Katy Williams;Alex Bigelow;Katherine E. Isaacs,
CHI,2023,"Data, Data, Everywhere: Uncovering Everyday Data Experiences for People with Intellectual and Developmental Disabilities",10.1145/3544548.3581204,"Data is everywhere but may not be accessible to everyone. Conventional data visualization tools and guidelines often do not actively consider the specific needs and abilities of people with Intellectual and Developmental Disabilities (IDD), leaving them excluded from data-driven activities and vulnerable to ethical issues. To understand the needs and challenges people with IDD have with data, we conducted 15 semi-structured interviews with individuals with IDD and their caregivers. Our algorithmic interview approach situated data in the lived experiences of people with IDD to uncover otherwise hidden data encounters in their everyday life. Drawing on findings and observations, we characterize how they conceptualize data, when and where they use data, and what barriers exist when they interact with data. We use our results as a lens to reimagine the role of visualization in data accessibility and establish a critical near-term research agenda for cognitively accessible visualization.",Keke Wu;Michelle Ho Tran;Emma Petersen;Varsha Koushik;Danielle Albers Szafir,
CHI,2023,"""Explain What a Treemap is"": Exploratory Investigation of Strategies for Explaining Unfamiliar Chart to Blind and Low Vision Users",10.1145/3544548.3581139,"Visualization designers increasingly use diverse types of visualizations, but assistive technologies and education for blind and low vision people often focus on elementary chart types. We explore textual explanation as a more generalizable solution. We define three dimensions of explanation strategies based on education theories: comparing to a familiar chart type, describing how to draw one, and using a concrete example. We develop a prototype system that automatically generates text explanations from a given chart specification. We conduct an exploratory study with 24 legally blind people to observe both the effectiveness and the perceived effectiveness of the strategies. The findings include: description of visual appearance is overall more effective than instructions for drawing, effective strategies differ by each chart type and by each participant, and the user’s perceived effectiveness does not always lead to better performance. We demonstrate the feasibility of an explanation generation system and compile design considerations.",Gyeongri Kim;Jiho Kim;Yea-Seul Kim,
CHI,2023,Visual Task Performance and Spatial Abilities: An Investigation of Artists and Mathematicians,10.1145/3544548.3580765,"This study builds on past research to present a domain-specific empirical investigation of artists and math & computer scientists on their respective relationships to, perceptions of, and interactions with data visualization. We conducted a three-phase study utilizing mixed-methods to investigate performance on visual and text representations of data between domains. Our findings evidenced how math & computer scientists are proficient utilizing text representations of data while artists benefit more from visual chart representations. Finally, we present perspectives from artists to gain an understanding of their approach to visual and mathematical tasks. Our findings indicate that artists are especially adept at statistical visual tasks and that development of cognitive skills could be fostered by individuals to potentially benefit visualization task performance.",Sara Tandon;Alfie Abdul-Rahman;Rita Borgo,
CHI,2023,We are the Data: Challenges and Opportunities for Creating Demographically Diverse Anthropographics,10.1145/3544548.3581086,"Anthropographics are human-shaped visualizations that aim to emphasize the human importance of datasets and the people behind them. However, current anthropographics tend to employ homogeneous human shapes to encode data about diverse demographic groups. Such anthropographics can obscure important differences between groups and contemporary designs exemplify the lack of inclusive approaches for representing human diversity in visualizations. In response, we explore the creation of demographically diverse anthropographics that communicate the visible diversity of demographically distinct populations. Building on previous anthropographics research, we explore strategies for visualizing datasets about people in ways that explicitly encode diversity—illustrating these approaches with examples in a variety of visual styles. We also critically reflect on strategies for creating diverse anthropographics, identifying social and technical challenges that can result in harmful representations. Finally, we highlight a set of forward-looking research opportunities for advancing the design and understanding of diverse anthropographics.",Priya Dhawka;Helen Ai He;Wesley Willett,
CHI,2023,DataParticles: Block-based and Language-oriented Authoring of Animated Unit Visualizations,10.1145/3544548.3581472,"Unit visualizations have been widely used in data storytelling within interactive articles and videos. However, authoring data stories that contain animated unit visualizations is challenging due to the tedious, time-consuming process of switching back and forth between writing a narrative and configuring the accompanying visualizations and animations. To streamline this process, we present DataParticles, a block-based story editor that leverages the latent connections between text, data, and visualizations to help creators flexibly prototype, explore, and iterate on a story narrative and its corresponding visualizations. To inform the design of DataParticles, we interviewed 6 domain experts and studied a dataset of 44 existing animated unit visualizations to identify the narrative patterns and congruence principles they employed. A user study with 9 experts showed that DataParticles can significantly simplify the process of authoring data stories with animated unit visualizations by encouraging exploration and supporting fast prototyping.",Yining Cao;Jane L. E;Zhutian Chen;Haijun Xia,
CHI,2023,DataPilot: Utilizing Quality and Usage Information for Subset Selection during Visual Data Preparation,10.1145/3544548.3581509,"Selecting relevant data subsets from large, unfamiliar datasets can be difficult. We address this challenge by modeling and visualizing two kinds of auxiliary information: (1) quality – the validity and appropriateness of data required to perform certain analytical tasks; and (2) usage – the historical utilization characteristics of data across multiple users. Through a design study with 14 data workers, we integrate this information into a visual data preparation and analysis tool, DataPilot. DataPilot presents visual cues about “the good, the bad, and the ugly” aspects of data and provides graphical user interface controls as interaction affordances, guiding users to perform subset selection. Through a study with 36 participants, we investigate how DataPilot helps users navigate a large, unfamiliar tabular dataset, prepare a relevant subset, and build a visualization dashboard. We find that users selected smaller, effective subsets with higher quality and usage, and with greater success and confidence.",Arpit Narechania;Fan Du;Atanu R. Sinha;Ryan A. Rossi;Jane Hoffswell;Shunan Guo;Eunyee Koh;Shamkant B. Navathe;Alex Endert,
CHI,2023,Deimos: A Grammar of Dynamic Embodied Immersive Visualisation Morphs and Transitions,10.1145/3544548.3580754,"We present Deimos, a grammar for specifying dynamic embodied immersive visualisation morphs and transitions. A morph is a collection of animated transitions that are dynamically applied to immersive visualisations at runtime and is conceptually modelled as a state machine. It is comprised of state, transition, and signal specifications. States in a morph are used to generate animation keyframes, with transitions connecting two states together. A transition is controlled by signals, which are composable data streams that can be used to enable embodied interaction techniques. Morphs allow immersive representations of data to transform and change shape through user interaction, facilitating the embodied cognition process. We demonstrate the expressivity of Deimos in an example gallery and evaluate its usability in an expert user study of six immersive analytics researchers. Participants found the grammar to be powerful and expressive, and showed interest in drawing upon Deimos’ concepts and ideas in their own research.",Benjamin Lee;Arvind Satyanarayan;Maxime Cordeil;Arnaud Prouzeau;Bernhard Jenny;Tim Dwyer,
CHI,2023,Perceptual Pat: A Virtual Human Visual System for Iterative Visualization Design,10.1145/3544548.3580974,"Designing a visualization is often a process of iterative refinement where the designer improves a chart over time by adding features, improving encodings, and fixing mistakes. However, effective design requires external critique and evaluation. Unfortunately, such critique is not always available on short notice and evaluation can be costly. To address this need, we present Perceptual Pat, an extensible suite of AI and computer vision techniques that forms a virtual human visual system for supporting iterative visualization design. The system analyzes snapshots of a visualization using an extensible set of filters—including gaze maps, text recognition, color analysis, etc—and generates a report summarizing the findings. The web-based Pat Design Lab provides a version tracking system that enables the designer to track improvements over time. We validate Perceptual Pat using a longitudinal qualitative study involving 4 professional visualization designers that used the tool over a few days to design a new visualization.",Sungbok Shin;Sanghyun Hong 0001;Niklas Elmqvist,
CHI,2023,Troubling Collaboration: Matters of Care for Visualization Design Study,10.1145/3544548.3581168,"A common research process in visualization is for visualization researchers to collaborate with domain experts to solve particular applied data problems. While there is existing guidance and expertise around how to structure collaborations to strengthen research contributions, there is comparatively little guidance on how to navigate the implications of, and power produced through the socio-technical entanglements of collaborations. In this paper, we qualitatively analyze reflective interviews of past participants of collaborations from multiple perspectives: visualization graduate students, visualization professors, and domain collaborators. We juxtapose the perspectives of these individuals, revealing tensions about the tools that are built and the relationships that are formed — a complex web of competing motivations. Through the lens of matters of care, we interpret this web, concluding with considerations that both trouble and necessitate reformation of current patterns around collaborative work in visualization design studies to promote more equitable, useful, and care-ful outcomes.",Derya Akbaba;Devin Lange;Michael Correll;Alexander Lex;Miriah Meyer,
CHI,2023,VisLab: Enabling Visualization Designers to Gather Empirically Informed Design Feedback,10.1145/3544548.3581132,"When creating a visualization, designers face various conflicting design choices. They typically rely on their hunches to deal with intricate trade-offs or resort to feedback from their colleagues. On the other hand, researchers have long used empirical methods to derive useful quantitative insights into visualization designs. Taking inspiration from this research tradition, we developed VisLab, an open-source online system to complement the existing qualitative feedback practice and help visualization practitioners run experiments to gather empirically informed design feedback. We surveyed practitioners’ perceptions of quantitative feedback and analyzed the research literature to inform VisLab’s motivation and design. VisLab operationalizes the experiment process using templates and dashboards to make empirical methods amenable for practitioners while supporting sharing and remixing experiments to aid knowledge exchange and validation. We demonstrated the validity of experiments in VisLab and evaluated the usability and potential usefulness of VisLab in visualization design practice.",Jinhan Choi;Changhoon Oh;Yea-Seul Kim;Nam Wook Kim,
CHI,2023,CALVI: Critical Thinking Assessment for Literacy in Visualizations,10.1145/3544548.3581406,"Visualization misinformation is a prevalent problem, and combating it requires understanding people’s ability to read, interpret, and reason about erroneous or potentially misleading visualizations, which lacks a reliable measurement: existing visualization literacy tests focus on well-formed visualizations. We systematically develop an assessment for this ability by: (1) developing a precise definition of misleaders (decisions made in the construction of visualizations that can lead to conclusions not supported by the data), (2) constructing initial test items using a design space of misleaders and chart types, (3) trying out the provisional test on 497 participants, and (4) analyzing the test tryout results and refining the items using Item Response Theory, qualitative analysis, a wrong-due-to-misleader score, and the content validity index. Our final bank of 45 items shows high reliability, and we provide item bank usage recommendations for future tests and different use cases. Related materials are available at: https://osf.io/pv67z/.",Lily W. Ge;Yuan Cui;Matthew Kay 0001,HM
CHI,2023,Misleading Beyond Visual Tricks: How People Actually Lie with Charts,10.1145/3544548.3580910,"Data visualizations can empower an audience to make informed decisions. At the same time, deceptive representations of data can lead to inaccurate interpretations while still providing an illusion of data-driven insights. Existing research on misleading visualizations primarily focuses on examples of charts and techniques previously reported to be deceptive. These approaches do not necessarily describe how charts mislead the general population in practice. We instead present an analysis of data visualizations found in a real-world discourse of a significant global event—Twitter posts with visualizations related to the COVID-19 pandemic. Our work shows that, contrary to conventional wisdom, violations of visualization design guidelines are not the dominant way people mislead with charts. Specifically, they do not disproportionately lead to reasoning errors in posters’ arguments. Through a series of examples, we present common reasoning errors and discuss how even faithfully plotted data visualizations can be used to support misinformation.",Maxim Lisnic;Cole Polychronis;Alexander Lex;Marina Kogan,
CHI,2023,Who Do We Mean When We Talk About Visualization Novices?,10.1145/3544548.3581524,"As more people rely on visualization to inform their personal and collective decisions, researchers have focused on a broader range of audiences, including “novices.” But successfully applying, interrogating, or advancing visualization research for novices demands a clear understanding of what “novice” means in theory and practice. Misinterpreting who a “novice” is could lead to misapplying guidelines and overgeneralizing results. In this paper, we investigated how visualization researchers define novices and how they evaluate visualizations intended for novices. We analyzed 79 visualization papers that used “novice,” “non-expert,” “laypeople,” or “general public” in their titles or abstracts. We found ambiguity within papers and disagreement between papers regarding what defines a novice. Furthermore, we found a mismatch between the broad language describing novices and the narrow population representing them in evaluations (i.e., young people, students, and US residents). We suggest directions for inclusively supporting novices in both theory and practice.",Alyxander Burns;Christiana Lee;Ria Chawla;Evan Peck;Narges Mahyar,BP
CHI,2023,A Review and Collation of Graphical Perception Knowledge for Visualization Recommendation,10.1145/3544548.3581349,"Selecting appropriate visual encodings is critical to designing effective visualization recommendation systems, yet few findings from graphical perception are typically applied within these systems. We observe two significant limitations in translating graphical perception knowledge into actionable visualization recommendation rules/constraints: inconsistent reporting of findings and a lack of shared data across studies. How can we translate the graphical perception literature into a knowledge base for visualization recommendation? We present a review of 59 papers that study user perception and performance across ten visual analysis tasks. Through this study, we contribute a JSON dataset that collates existing theoretical and experimental knowledge and summarizes key study outcomes in graphical perception. We illustrate how this dataset can inform automated encoding decisions with three representative visualization recommendation systems. Based on our findings, we highlight open challenges and opportunities for the community in collating graphical perception knowledge for a range of visualization recommendation scenarios.",Zehua Zeng;Leilani Battle,
CHI,2023,Graphical Perception of Saliency-based Model Explanations,10.1145/3544548.3581320,"In recent years, considerable work has been devoted to explaining predictive, deep learning-based models, and in turn how to evaluate explanations. An important class of evaluation methods are ones that are human-centered, which typically require the communication of explanations through visualizations. And while visualization plays a critical role in perceiving and understanding model explanations, how visualization design impacts human perception of explanations remains poorly understood. In this work, we study the graphical perception of model explanations, specifically, saliency-based explanations for visual recognition models. We propose an experimental design to investigate how human perception is influenced by visualization design, wherein we study the task of alignment assessment, or whether a saliency map aligns with an object in an image. Our findings show that factors related to visualization design decisions, the type of alignment, and qualities of the saliency map all play important roles in how humans perceive saliency-based visual explanations.",Yayan Zhao;Mingwei Li;Matthew Berger,
CHI,2023,How Can Deep Neural Networks Aid Visualization Perception Research? Three Studies on Correlation Judgments in Scatterplots,10.1145/3544548.3581111,"How deep neural networks can aid visualization perception research is a wide-open question. This paper provides insights from three perspectives—prediction, generalization, and interpretation—via training and analyzing deep convolutional neural networks on human correlation judgments in scatterplots across three studies. The first study assesses the accuracy of twenty-nine neural network architectures in predicting human judgments, finding that a subset of the architectures (e.g., VGG-19) has comparable accuracy to the best-performing regression analyses in prior research. The second study shows that the resulting models from the first study display better generalizability than prior models on two other judgment datasets for different scatterplot designs. The third study interprets visual features learned by a convolutional neural network model, providing insights about how the model makes predictions, and identifies potential features that could be investigated in human correlation perception studies. Together, this paper suggests that deep neural networks can serve as a tool for visualization perception researchers in devising potential empirical study designs and hypothesizing about perpetual judgments. The preprint, data, code, and training logs are available at https://doi.org/10.17605/osf.io/exa8m.",Fumeng Yang;Yuxin Ma;Lane Harrison;James Tompkin 0001;David H. Laidlaw,
CHI,2023,Interactive Context-Preserving Color Highlighting for Multiclass Scatterplots,10.1145/3544548.3580734,"Color is one of the main visual channels used for highlighting elements of interest in visualization. However, in multi-class scatterplots, color highlighting often comes at the expense of degraded color discriminability. In this paper, we argue for context-preserving highlighting during the interactive exploration of multi-class scatterplots to achieve desired pop-out effects, while maintaining good perceptual separability among all classes and consistent color mapping schemes under varying points of interest. We do this by first generating two contrastive color mapping schemes with large and small contrasts to the background. Both schemes maintain good perceptual separability among all classes and ensure that when colors from the two palettes are assigned to the same class, they have a high color consistency in color names. We then interactively combine these two schemes to create a dynamic color mapping for highlighting different points of interest. We demonstrate the effectiveness through crowd-sourced experiments and case studies.",Kecheng Lu;Khairi Reda;Oliver Deussen;Yunhai Wang,
CHI,2023,Showing Flow: Comparing Usability of Chord and Sankey Diagrams,10.1145/3544548.3581119,"Chord and Sankey diagrams are two common techniques for visualizing flows. Chord diagrams use a radial layout with a single circular axis, and Sankey diagrams use a left-to-right layout with two vertical axes. Previous work suggests both strengths and weaknesses of the radial approach, but little is known about the usability and interpretability of these two layout styles for showing flow. We carried out a study where participants answered questions using equivalent Chord and Sankey diagrams. We measured completion time, errors, perceived effort, and preference. Our results show that participants took substantially longer to answer questions with Chord diagrams and made more errors; participants also rated Chord as requiring more effort, and strongly preferred Sankey diagrams. Our study identifies and explains limitations of the popular Chord layout, provides new understanding about radial vs. linear layouts that can help guide visualization designers, and identifies possible design improvements for both visualization types.",Carl Gutwin;Aristides Mairena;Venkat Bandi,
CHI,2023,Accessible Data Representation with Natural Sound,10.1145/3544548.3581087,"Sonification translates data into non-speech audio. Such auditory representations can make data visualization accessible to people who are blind or have low vision (BLV). This paper presents a sonification method for translating common data visualization into a blend of natural sounds. We hypothesize that people’s familiarity with sounds drawn from nature, such as birds singing in a forest, and their ability to listen to these sounds in parallel, will enable BLV users to perceive multiple data points being sonified at the same time. Informed by an extensive literature review and a preliminary study with 5 BLV participants, we designed an accessible data representation tool, Susurrus, that combines our sonification method with other accessibility features, such as keyboard interaction and text-to-speech feedback. Finally, we conducted a user study with 12 BLV participants and report the potential and application of natural sounds for sonification compared to existing sonification tools.",Md. Naimul Hoque;Md Ehtesham-Ul-Haque;Niklas Elmqvist;Syed Masum Billah,
CHI,2023,Exploring Chart Question Answering for Blind and Low Vision Users,10.1145/3544548.3581532,"Data visualizations can be complex or involve numerous data points, making them impractical to navigate using screen readers alone. Question answering (QA) systems have the potential to support visualization interpretation and exploration without overwhelming blind and low vision (BLV) users. To investigate if and how QA systems can help BLV users in working with visualizations, we conducted a Wizard of Oz study with 24 BLV people where participants freely posed queries about four visualizations. We collected 979 queries and mapped them to popular analytic task taxonomies. We found that retrieving value and finding extremum were the most common tasks, participants often made complex queries and used visual references, and the data topic notably influenced the queries. We compile a list of design considerations for accessible chart QA systems and make our question corpus publicly available to guide future research and development.",Jiho Kim;Arjun Srinivasan;Nam Wook Kim;Yea-Seul Kim,
CHI,2023,Visualization of Speech Prosody and Emotion in Captions: Accessibility for Deaf and Hard-of-Hearing Users,10.1145/3544548.3581511,"Speech is expressive in ways that caption text does not capture, with emotion or emphasis information not conveyed. We interviewed eight Deaf and Hard-of-Hearing (dhh) individuals to understand if and how captions’ inexpressiveness impacts them in online meetings with hearing peers. Automatically captioned speech, we found, lacks affective depth, lending it a hard-to-parse ambiguity and general dullness. Interviewees regularly feel excluded, which some understand is an inherent quality of these types of meetings rather than a consequence of current caption text design. Next, we developed three novel captioning models that depicted, beyond words, features from prosody, emotions, and a mix of both. In an empirical study, 16 dhh participants compared these models with conventional captions. The emotion-based model outperformed traditional captions in depicting emotions and emphasis, with only a moderate loss in legibility, suggesting its potential as a more inclusive design for captions.",Caluã de Lacerda Pataca;Matthew Watkins;Roshan L. Peiris;Sooyeon Lee;Matt Huenerfauth,
CHI,2023,Angler: Helping Machine Translation Practitioners Prioritize Model Improvements,10.1145/3544548.3580790,"Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal. With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts. Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error’s nature, scope, and impact on users. We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements. In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.",Samantha Robertson;Zijie J. Wang;Dominik Moritz;Mary Beth Kery;Fred Hohman,
CHI,2023,DRAVA: Aligning Human Concepts with Machine Learning Latent Dimensions for the Visual Exploration of Small Multiples,10.1145/3544548.3581127,"Latent vectors extracted by machine learning (ML) are widely used in data exploration (e.g., t-SNE) but suffer from a lack of interpretability. While previous studies employed disentangled representation learning (DRL) to enable more interpretable exploration, they often overlooked the potential mismatches between the concepts of humans and the semantic dimensions learned by DRL. To address this issue, we propose Drava, a visual analytics system that supports users in 1) relating the concepts of humans with the semantic dimensions of DRL and identifying mismatches, 2) providing feedback to minimize the mismatches, and 3) obtaining data insights from concept-driven exploration. Drava provides a set of visualizations and interactions based on visual piles to help users understand and refine concepts and conduct concept-driven exploration. Meanwhile, Drava employs a concept adaptor model to fine-tune the semantic dimensions of DRL based on user refinement. The usefulness of Drava is demonstrated through application scenarios and experimental validation.",Qianwen Wang;Sehi L'Yi;Nils Gehlenborg,
CHI,2023,ESCAPE: Countering Systematic Errors from Machine's Blind Spots via Interactive Visual Analysis,10.1145/3544548.3581373,"Classification models learn to generalize the associations between data samples and their target classes. However, researchers have increasingly observed that machine learning practice easily leads to systematic errors in AI applications, a phenomenon referred to as “AI blindspots.” Such blindspots arise when a model is trained with training samples (e.g., cat/dog classification) where important patterns (e.g., black cats) are missing or periphery/undesirable patterns (e.g., dogs with grass background) are misleading towards a certain class. Even more sophisticated techniques cannot guarantee to capture, reason about, and prevent the spurious associations. In this work, we propose ESCAPE, a visual analytic system that promotes a human-in-the-loop workflow for countering systematic errors. By allowing human users to easily inspect spurious associations, the system facilitates users to spontaneously recognize concepts associated misclassifications and evaluate mitigation strategies that can reduce biased associations. We also propose two statistical approaches, relative concept association to better quantify the associations between a concept and instances, and debias method to mitigate spurious associations. We demonstrate the utility of our proposed ESCAPE system and statistical measures through extensive evaluation including quantitative experiments, usage scenarios, expert interviews, and controlled user experiments.",Yongsu Ahn;Yu-Ru Lin;Panpan Xu;Zeng Dai,
CHI,2023,GAM Coach: Towards Interactive and User-centered Algorithmic Recourse,10.1145/3544548.3580816,"Machine learning (ML) recourse techniques are increasingly used in high-stakes domains, providing end users with actions to alter ML predictions, but they assume ML developers understand what input variables can be changed. However, a recourse plan’s actionability is subjective and unlikely to match developers’ expectations completely. We present GAM Coach, a novel open-source system that adapts integer linear programming to generate customizable counterfactual explanations for Generalized Additive Models (GAMs), and leverages interactive visualizations to enable end users to iteratively generate recourse plans meeting their needs. A quantitative user study with 41 participants shows our tool is usable and useful, and users prefer personalized recourse plans over generic plans. Through a log analysis, we explore how users discover satisfactory recourse plans, and provide empirical evidence that transparency can lead to more opportunities for everyday users to discover counterintuitive patterns in ML models. GAM Coach is available at: https://poloclub.github.io/gam-coach/.",Zijie J. Wang;Jennifer Wortman Vaughan;Rich Caruana;Duen Horng Chau,
CHI,2023,Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data Work,10.1145/3544548.3580819,"Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional. However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when. In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes. We present a rigorous methodology for its creation and discuss its transferability to the visual design process. We operationalize the taxonomy through the development of AutoML Trace a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work. Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team. Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work. Availability of Supplemental Materials: https://osf.io/3nmyj/?view_only=19962103d58b45d289b5c83421f48b36",Jen Rogers;Anamaria Crisan,HM
CHI,2023,Designing Resource Allocation Tools to Promote Fair Allocation: Do Visualization and Information Framing Matter?,10.1145/3544548.3580739,"Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources. However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases. This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness. We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals). In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities. Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs. This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions.",Arnav Verma;Luiz Augusto de Macêdo Morais;Pierre Dragicevic;Fanny Chevalier,
CHI,2023,From Asymptomatics to Zombies: Visualization-Based Education of Disease Modeling for Children,10.1145/3544548.3581573,"Throughout the COVID-19 pandemic, visualizations became commonplace in public communications to help people make sense of the world and the reasons behind government-imposed restrictions. Though the adult population were the main target of these messages, children were affected by restrictions through not being able to see friends and virtual schooling. However, through these daily models and visualizations, the pandemic response provided a way for children to understand what data scientists really do and provided new routes for engagement with STEM subjects. In this paper, we describe the development of an interactive and accessible visualization tool to be used in workshops for children to explain computational modeling of diseases, in particular COVID-19. We detail our design decisions based on approaches evidenced to be effective and engaging such as unplugged activities and interactivity. We share reflections and learnings from delivering these workshops to 140 children and assess their effectiveness.",Graham Mcneill;Max Sondag;Stewart Powell;Phoebe Asplin;Cagatay Turkay;Faron Moller;Daniel Archambault,
CHI,2023,How Data Analysts Use a Visualization Grammar in Practice,10.1145/3544548.3580837,"Visualization grammars, often based on the Grammar of Graphics (GoG), have much potential for augmenting data analysis in a programming environment. However, we do not know how analysts conceptualize grammar abstractions, or how a visualization grammar works with data analysis in practice. Therefore, we qualitatively analyzed how experienced analysts (N = 6) from TidyTuesday, a social data project, wrangled and visualized data using GoG-based ggplot2 without given tasks in R Markdown. Though participants’ analysis and customization needs could mismatch with GoG component design, their analysis processes aligned with the goal of GoG to expedite visualization iteration. We also found a feedback loop and tight coupling between visualization and data transformation code, explaining both participants’ productivity and their errors. From these results, we discuss how future visualization grammars can become more practical for analysts and how visualization grammar and analysis tools can better integrate within a programming (i.e., computational notebook) environment.",Xiaoying Pu;Matthew Kay 0001,
CHI,2023,iBall: Augmenting Basketball Videos with Gaze-moderated Embedded Visualizations,10.1145/3544548.3581266,"We present iBall, a basketball video-watching system that leverages gaze-moderated embedded visualizations to facilitate game understanding and engagement of casual fans. Video broadcasting and online video platforms make watching basketball games increasingly accessible. Yet, for new or casual fans, watching basketball videos is often confusing due to their limited basketball knowledge and the lack of accessible, on-demand information to resolve their confusion. To assist casual fans in watching basketball videos, we compared the game-watching behaviors of casual and die-hard fans in a formative study and developed iBall based on the findings. iBall embeds visualizations into basketball videos using a computer vision pipeline, and automatically adapts the visualizations based on the game context and users’ gaze, helping casual fans appreciate basketball games without being overwhelmed. We confirmed the usefulness, usability, and engagement of iBall in a study with 16 casual fans, and further collected feedback from 8 die-hard fans.",Zhutian Chen;Qisen Yang;Jiarui Shan;Tica Lin;Johanna Beyer;Haijun Xia;Hanspeter Pfister,
CHI,2023,The tactile dimension: a method for physicalizing touch behaviors,10.1145/3544548.3581137,"Traces of touch provide valuable insight into how we interact with the physical world. Measuring touch behavior, however, is expensive and imprecise. Utilizing a fluorescent UV tracer powder, we developed a low-cost analog method to capture persistent, high-contrast touch records on arbitrary objects. We describe our process for selecting a tracer, methods for capturing, enhancing, and aggregating traces, and approaches to examining qualitative aspects of the user experience. Three user studies demonstrate key features of this method. First, we show that it provides clear and durable traces on objects representative of scientific visualization, physicalization, and product design. Second, we demonstrate how this method could be used to study touch perception, by measuring how task and narrative framing elicit different touch behaviors on the same object. Third, we demonstrate how this method can be used to evaluate data physicalizations by observing how participants touch two different physicalizations of COVID-19 time-series data.",Laura J. Perovich;Bernice E. Rogowitz;Victoria Crabb;Jack Vogelsang;Sara Hartleben;Dietmar Offenhuber,
CHI,2023,Working with Forensic Practitioners to Understand the Opportunities and Challenges for Mixed-Reality Digital Autopsy,10.1145/3544548.3580768,"Forensic practitioners analyse intrinsic 3D data daily on 2D screens. We explore novel immersive visualisation techniques that enable digital autopsy through analysis of 3D imagery. We employ a user-centred design process involving four rounds of user feedback: (1) formative interviews eliciting opportunities and requirements for mixed-reality digital autopsies; (2) a larger workshop identifying our prototype’s limitations and further use-cases and interaction ideas; (3+4) two rounds of qualitative user validation of successive prototypes of novel interaction techniques for pathologist sensemaking. Overall, we find MR holds great potential to enable digital autopsy, initially to supplement physical autopsy, but ultimately to replace it. We found that experts were able to use our tool to perform basic virtual autopsy tasks, MR setup promotes exploration and sense making of cause of death, and subject to limitations of current MR technology, the proposed system is a valid option for digital autopsies, according to experts’ feedback. – Warning: This paper contains sensitive images which are 3D visualisation of deceased people.",Vahid Pooryousef;Maxime Cordeil;Lonni Besançon;Christophe Hurter;Tim Dwyer;Richard Bassed,
CHI,2023,A Need-Finding Study with Users of Geospatial Data,10.1145/3544548.3581370,"Geospatial data is playing an increasingly critical role in the work of Earth and climate scientists, social scientists, and data journalists exploring spatiotemporal change in our environment and societies. However, existing software and programming tools for geospatial analysis and visualization are challenging to learn and difficult to use. The aim of this work is to identify the unmet computing needs of the diverse and expanding community of geospatial data users. We conducted a contextual inquiry study (n = 25) with domain experts using geospatial data in their current work. Through a thematic analysis, we found that participants struggled to (1) find and transform geospatial data to satisfy spatiotemporal constraints, (2) understand the behavior of geospatial operators, (3) track geospatial data provenance, and (4) explore the cartographic design space. These findings suggest design opportunities for developers and designers of geospatial analysis and visualization systems.",Parker Ziegler;Sarah E. Chasins,
CHI,2022,AvatAR: An Immersive Analysis Environment for Human Motion Data Combining Interactive 3D Avatars and Trajectories,10.1145/3491102.3517676,"Analysis of human motion data can reveal valuable insights about the utilization of space and interaction of humans with their environment. To support this, we present AvatAR, an immersive analysis environment for the in-situ visualization of human motion data, that combines 3D trajectories with virtual avatars showing people’s detailed movement and posture. Additionally, we describe how visualizations can be embedded directly into the environment, showing what a person looked at or what surfaces they touched, and how the avatar’s body parts can be used to access and manipulate those visualizations. AvatAR combines an AR HMD with a tablet to provide both mid-air and touch interaction for system control, as well as an additional overview device to help users navigate the environment. We implemented a prototype and present several scenarios to show that AvatAR can enhance the analysis of human motion data by making data not only explorable, but experienceable.",Patrick Reipschläger;Frederik Brudy;Raimund Dachselt;Justin Matejka;George W. Fitzmaurice;Fraser Anderson,
CHI,2022,ReLive: Bridging In-Situ and Ex-Situ Visual Analytics for Analyzing Mixed Reality User Studies,10.1145/3491102.3517550,"The nascent field of mixed reality is seeing an ever-increasing need for user studies and field evaluation, which are particularly challenging given device heterogeneity, diversity of use, and mobile deployment. Immersive analytics tools have recently emerged to support such analysis in situ, yet the complexity of the data also warrants an ex-situ analysis using more traditional non-immersive visual analytics setups. To bridge the gap between both approaches, we introduce ReLive: a mixed-immersion visual analytics framework for exploring and analyzing mixed reality user studies. ReLive combines an in-situ virtual reality view with a complementary ex-situ desktop view. While the virtual reality view allows users to relive interactive spatial recordings replicating the original study, the synchronized desktop view provides a familiar interface for analyzing aggregated data. We validated our concepts in a two-step evaluation consisting of a design walkthrough and an empirical expert user study.",Sebastian Hubenschmid;Jonathan Wieland;Daniel Immanuel Fink 0001;Andrea Batch;Johannes Zagermann;Niklas Elmqvist;Harald Reiterer,
CHI,2022,A Design Space For Data Visualisation Transformations Between 2D And 3D In Mixed-Reality Environments,10.1145/3491102.3501859,"As mixed-reality (MR) technologies become more mainstream, the delineation between data visualisations displayed on screens or other surfaces and those floating in space becomes increasingly blurred. Rather than the choice of using either a 2D surface or the 3D space for visualising data being a dichotomy, we argue that users should have the freedom to transform visualisations seamlessly between the two as needed. However, the design space for such transformations is large, and practically uncharted. To explore this, we first establish an overview of the different states that a data visualisation can take in MR, followed by how transformations between these states can facilitate common visualisation tasks. We then describe a design space of how these transformations function, in terms of the different stages throughout the transformation, and the user interactions and input parameters that affect it. This design space is then demonstrated with multiple exemplary techniques based in MR.",Benjamin Lee;Maxime Cordeil;Arnaud Prouzeau;Bernhard Jenny;Tim Dwyer,HM
CHI,2022,HAExplorer: Understanding Interdependent Biomechanical Motions with Interactive Helical Axes,10.1145/3491102.3501841,"The helical axis is a common tool used in biomechanical modeling to parameterize the motion of rigid objects. It encodes an object’s rotation around and translation along a unique axis. Visualizations of helical axes have helped to make kinematic data tangible. However, the analysis process often remains tedious, especially if complex motions are examined. We identify multiple key challenges: the absence of interactive tools for the computation and handling of helical axes, visual clutter in axis representations, and a lack of contextualization. We solve these issues by providing the first generalized framework for kinematic analysis with helical axes. Axis sets can be computed on-demand, interactively filtered, and explored in multiple coordinated views. We iteratively developed and evaluated the HAExplorer with active biomechanics researchers. Our results show that the techniques we introduce open up the possibility to analyze non-planar, compound, and interdependent motion data.",Pepe Eulzer;Robert Rockenfeller;Kai Lawonn,
CHI,2022,Preferences and Effectiveness of Sleep Data Visualizations for Smartwatches and Fitness Bands,10.1145/3491102.3501921,"We present the findings of four studies related to the visualization of sleep data on wearables with two form factors: smartwatches and fitness bands. Our goal was to understand the interests, preferences, and effectiveness of different sleep visualizations by form factor. In a survey, we showed that wearers were mostly interested in weekly sleep duration, and nightly sleep phase data. Visualizations of this data were generally preferred over purely text-based representations, and the preferred chart type for fitness bands, and smartwatches was often the same. In one in-person pilot study, and two crowdsourced studies, we then tested the effectiveness of the most preferred representations for different tasks, and found that participants performed simple tasks effectively on both form factors but more complex tasks benefited from the larger smartwatch size. Lastly, we reflect on our crowdsourced study methodology for testing the effectiveness of visualizations for wearables. Supplementary material is available at https://osf.io/yz8ar/.",Alaul Islam;Ranjini Aravind;Tanja Blascheck;Anastasia Bezerianos;Petra Isenberg,
CHI,2022,Do You See What You Mean? Using Predictive Visualizations to Reduce Optimism in Duration Estimates,10.1145/3491102.3502010,"Making time estimates, such as how long a given task might take, frequently leads to inaccurate predictions because of an optimistic bias. Previous attempts to alleviate this bias, including decomposing the task into smaller components and listing potential surprises, have not shown any major improvement. This article builds on the premise that these procedures may have failed because they involve compound probabilities and mixture distributions which are difficult to compute in one’s head. We hypothesize that predictive visualizations of such distributions would facilitate the estimation of task durations. We conducted a crowdsourced study in which 145 participants provided different estimates of overall and sub-task durations and we used these to generate predictive visualizations of the resulting mixture distributions. We compared participants’ initial estimates with their updated ones and found compelling evidence that predictive visualizations encourage less optimistic estimates.",Morgane Koval;Yvonne Jansen,HM
CHI,2022,Telling Stories from Computational Notebooks: AI-Assisted Presentation Slides Creation for Presenting Data Science Work,10.1145/3491102.3517615,"Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists’ burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users’ input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.",Chengbo Zheng;Dakuo Wang;April Yi Wang;Xiaojuan Ma,
CHI,2022,Supporting the Contact Tracing Process with WiFi Location Data: Opportunities and Challenges,10.1145/3491102.3517703,"Contact tracers assist in containing the spread of highly infectious diseases such as COVID-19 by engaging community members who receive a positive test result in order to identify close contacts. Many contact tracers rely on community member’s recall for those identifications, and face limitations such as unreliable memory. To investigate how technology can alleviate this challenge, we developed a visualization tool using de-identified location data sensed from campus WiFi and provided it to contact tracers during mock contact tracing calls. While the visualization allowed contact tracers to find and address inconsistencies due to gaps in community member’s memory, it also introduced inconsistencies such as false-positive and false-negative reports due to imperfect data, and information sharing hesitancy. We suggest design implications for technologies that can better highlight and inform contact tracers of potential areas of inconsistencies, and further present discussion on using imperfect data in decision making.",Kaely Hall;Dong Whi Yoo;Wenrui Zhang;Mehrab Bin Morshed;Vedant Das Swain;Gregory D. Abowd;Munmun De Choudhury;Alex Endert;John T. Stasko;Jennifer G. Kim,
CHI,2022,Annotating Line Charts for Addressing Deception,10.1145/3491102.3502138,"Deceptive visualizations are visualizations that, whether intentionally or not, lead the reader to an understanding of the data which varies from the actual data. Examples of deceptive visualizations can be found in every digital platform, and, despite their widespread use in the wild, there have been limited efforts to alert laypersons to common deceptive visualization practices. In this paper, we present a tool for annotating line charts in the wild that reads line chart images and outputs text and visual annotations to assess the line charts for distortions and help guide the reader towards an honest understanding of the chart data. We demonstrate the usefulness of our tool through a series of case studies on real-world charts. Finally, we perform a crowdsourced experiment to evaluate the ability of the proposed tool to educate readers about potentially deceptive visualization practices.",Arlen Fan;Yuxin Ma;Michelle Mancenido;Ross Maciejewski,HM
CHI,2022,Making Data Tangible: A Cross-disciplinary Design Space for Data Physicalization,10.1145/3491102.3501939,"Designing a data physicalization requires a myriad of different considerations. Despite the cross-disciplinary nature of these considerations, research currently lacks a synthesis across the different communities data physicalization sits upon, including their approaches, theories, and even terminologies. To bridge these communities synergistically, we present a design space that describes and analyzes physicalizations according to three facets: context (end-user considerations), structure (the physical structure of the artifact), and interactions (interactions with both the artifact and data). We construct this design space through a systematic review of 47 physicalizations and analyze the interrelationships of key factors when designing a physicalization. This design space cross-pollinates knowledge from relevant HCI communities, providing a cohesive overview of what designers should consider when creating a data physicalization while suggesting new design possibilities. We analyze the design decisions present in current physicalizations, discuss emerging trends, and identify underlying open challenges.",S. Sandra Bae;Clement Zheng;Mary Etta West;Ellen Yi-Luen Do;Samuel Huron;Danielle Albers Szafir,
CHI,2022,Put a Label On It! Approaches for Constructing and Contextualizing Bar Chart Physicalizations,10.1145/3491102.3501952,"Physicalizations represent data through their tangible and material properties. In contrast to screen-based visualizations, there is currently very limited understanding of how to label or annotate physicalizations to support people in interpreting the data encoded by the physicalization. Because of its spatiality, contextualization through labeling or annotation is crucial to communicate data across different orientations. In this paper, we study labeling approaches as part of the overall construction process of bar chart physicalizations. We designed a toolkit of physical tokens and paper data labels and asked 16 participants to construct and contextualize their own data physicalizations. We found that (i) the construction and contextualization of physicalizations is a highly intertwined process, (ii) data labels are integrated with physical constructs in the final design, and (iii) these are both influenced by orientation changes. We contribute with an understanding of the role of data labeling in the creation and contextualization of physicalizations.",Kim Sauvé;Argenis Ramirez Gomez;Steven Houben,
CHI,2022,Visualization Accessibility in the Wild: Challenges Faced by Visualization Designers,10.1145/3491102.3517630,"Data visualizations are now widely used across many disciplines. However, many of them are not easily accessible for visually impaired people. In this work, we use three-staged mixed methods to understand the current practice of accessible visualization design for visually impaired people. We analyzed 95 visualizations from various venues to inspect how they are made inaccessible. To understand the rationale and context behind the design choices, we also conducted surveys with 144 practitioners in the U.S. and follow-up interviews with ten selected survey participants. Our findings include the difficulties of handling modern complex and interactive visualizations and the lack of accessibility support from visualization tools in addition to personal and organizational factors making it challenging to perform accessible design practices.",Shakila Cherise S. Joyner;Amalia Riegelhuth;Kathleen Garrity;Yea-Seul Kim;Nam Wook Kim,
CHI,2022,"The Pattern is in the Details: An Evaluation of Interaction Techniques for Locating, Searching, and Contextualizing Details in Multivariate Matrix Visualizations",10.1145/3491102.3517673,"Matrix visualizations are widely used to display large-scale network, tabular, set, or sequential data. They typically only encode a single value per cell, e.g., through color. However, this can greatly limit the visualizations’ utility when exploring multivariate data, where each cell represents a data point with multiple values (referred to as details). Three well-established interaction approaches can be applicable in multivariate matrix visualizations (or MMV): focus+context, pan&zoom, and overview+detail. However, there is little empirical knowledge of how these approaches compare in exploring MMV. We report on two studies comparing them for locating, searching, and contextualizing details in MMV. We first compared four focus+context techniques and found that the fisheye lens overall outperformed the others. We then compared the fisheye lens, to pan&zoom and overview+detail. We found that pan&zoom was faster in locating and searching details, and as good as overview+detail in contextualizing details.",Yalong Yang 0001;Wenyu Xia;Fritz Lekschas;Carolina Nobre;Robert Krüger;Hanspeter Pfister,
CHI,2022,RoleSeer: Understanding Informal Social Role Changes in MMORPGs via Visual Analytics,10.1145/3491102.3517712,"Massively multiplayer online role-playing games create virtual communities that support heterogeneous “social roles” determined by gameplay interaction behaviors under a specific social context. For all social roles, formal roles are pre-defined, obvious, and explicitly ascribed to the people holding the roles, whereas informal roles are not well-defined and unspoken. Identifying the informal roles and understanding their subtle changes are critical to designing sociability mechanisms. However, it is nontrivial to understand the existence and evolution of such roles due to their loosely defined, interconvertible, and dynamic characteristics. We propose a visual analytics system, RoleSeer, to investigate informal roles from the perspectives of behavioral interactions and depict their dynamic interconversions and transitions. Two cases, experts’ feedback, and a user study suggest that RoleSeer helps interpret the identified informal roles and explore the patterns behind role changes. We see our approach’s potential in investigating informal roles in a broader range of social games.",Laixin Xie;Ziming Wu;Peng Xu;Wei Li 0094;Xiaojuan Ma;Quan Li,
CHI,2022,Visualizing Instructions for Physical Training: Exploring Visual Cues to Support Movement Learning from Instructional Videos,10.1145/3491102.3517735,"Instructional videos for physical training have gained popularity in recent years among sport and fitness practitioners, due to the proliferation of affordable and ubiquitous forms of online training. Yet, learning movement this way poses challenges: lack of feedback and personalised instructions, and having to rely on personal imitation capacity to learn movements. We address some of these challenges by exploring visual cues’ potential to help people imitate movements from instructional videos. With a Research through Design approach, focused on strength training, we augmented an instructional video with different sets of visual cues: directional cues, body highlights, and metaphorical visualizations. We tested each set with ten practitioners over three recorded sessions, with follow-up interviews. Through thematic analysis, we derived insights on the effect of each set of cues for supporting movement learning. Finally, we generated design takeaways to inform future HCI work on visual cues for instructional training videos.",Alessandra Semeraro;Laia Turmo Vidal,
CHI,2022,graphiti: Sketch-based Graph Analytics for Images and Videos,10.1145/3491102.3501923,"Graph analytics is currently performed using a combination of code, symbolic algebra, and network visualizations. The analyst has to work with symbolic and abstract forms of data to construct and analyze graphs. We locate unique design opportunities at the intersection of computer vision and graph analytics, by utilizing visual variables extracted from images/videos and some direct manipulation and pen interaction techniques. We also summarize commonly used graph operations and graphical representations (graphs, simplicial complexes, hypergraphs), and map them to a few brushes and direct manipulation actions. The mapping enables us to visually construct and analyze a wide range of graphs on top of images, videos, and sketches. The design framework is implemented as a sketch-based notebook interface to demonstrate the design possibilities. User studies with scientists from various fields reveal innovative use cases for such an embodied interaction paradigm for graph analytics.",Nazmus Saquib;Faria Huq;Syed Arefinul Haque,
CHI,2022,CrossData: Leveraging Text-Data Connections for Authoring Data Documents,10.1145/3491102.3517485,"Data documents play a central role in recording, presenting, and disseminating data. Despite the proliferation of applications and systems designed to support the analysis, visualization, and communication of data, writing data documents remains a laborious process, requiring a constant back-and-forth between data processing and writing tools. Interviews with eight professionals revealed that their workflows contained numerous tedious, repetitive, and error-prone operations. The key issue that we identified is the lack of persistent connection between text and data. Thus, we developed CrossData, a prototype that treats text-data connections as persistent, interactive, first-class objects. By automatically identifying, establishing, and leveraging text-data connections, CrossData enables rich interactions to assist in the authoring of data documents. An expert evaluation with eight users demonstrated the usefulness of CrossData, showing that it not only reduced the manual effort in writing data documents but also opened new possibilities to bridge the gap between data exploration and writing.",Zhutian Chen;Haijun Xia,
CHI,2022,Diff in the Loop: Supporting Data Comparison in Exploratory Data Analysis,10.1145/3491102.3502123,"Data science is characterized by evolution: since data science is exploratory, results evolve from moment to moment; since it can be collaborative, results evolve as the work changes hands. While existing tools help data scientists track changes in code, they provide less support for understanding the iterative changes that the code produces in the data. We explore the idea of visualizing differences in datasets as a core feature of exploratory data analysis, a concept we call Diff in the Loop (DITL). We evaluated DITL in a user study with 16 professional data scientists and found it helped them understand the implications of their actions when manipulating data. We summarize these findings and discuss how the approach can be generalized to different data science workflows.",April Yi Wang;Will Epperson;Robert A. DeLine;Steven Mark Drucker,
CHI,2022,Accessibility for Color Vision Deficiencies: Challenges and Findings of a Large Scale Study on Paper Figures,10.1145/3491102.3502133,"We present an exploratory study on the accessibility of images in publications when viewed with color vision deficiencies (CVDs). The study is based on 1,710 images sampled from a visualization dataset (VIS30K) over five years. We simulated four CVDs on each image. First, four researchers (one with a CVD) identified existing issues and helpful aspects in a subset of the images. Based on the resulting labels, 200 crowdworkers provided 30,000 ratings on present CVD issues in the simulated images. We analyzed this data for correlations, clusters, trends, and free text comments to gain a first overview of paper figure accessibility. Overall, about 60 % of the images were rated accessible. Furthermore, our study indicates that accessibility issues are subjective and hard to detect. On a meta-level, we reflect on our study experience to point out challenges and opportunities of large-scale accessibility studies for future research directions.",Katrin Angerbauer;Nils Rodrigues;René Cutura;Seyda Öney;Nelusa Pathmanathan;Cristina Morariu;Daniel Weiskopf;Michael Sedlmair,
CHI,2022,"Understanding Visual Investigation Patterns Through Digital ""Field"" Observations",10.1145/3491102.3517445,"An extensive body of work in visual analytics has examined how users conduct analyses in scientific and academic settings, identifying and categorizing user goals and the actions they undertake to achieve them. However, most of this work has studied the analysis process in simulated or isolated environments, leading to a gap in connecting these findings to large-scale business (enterprise) contexts, where visual analysis is most needed to make sense of the large amounts of data being generated. In this work, we conducted digital ”field” observations to understand how users conduct visual analyses in an enterprise setting, where they operate within a large ecosystem of systems and people. From these observations, we identified four common objectives, six recurring visual investigation patterns, and five emergent themes. We also performed a quantitative analysis of logs over 2530 user sessions from a second visual analysis product to validate that our patterns were not product-specific.",Irene Rae;Feng Zhou;Martin Bilsing;Philipp Bunge,
CHI,2022,Juvenile Graphical Perception: A Comparison between Children and Adults,10.1145/3491102.3501893,"Data visualization is pervasive in the lives of children as they encounter graphs and charts in early education and online media. In spite of this prevalence, our guidelines and understanding of how children perceive graphs stem primarily from studies conducted with adults. Previous psychology and education research indicates that children’s cognitive abilities are different from adults. Therefore, we conducted a classic graphical perception study on a population of children aged 8–12 enrolled in the Ivy After School Program in Boston, MA and adult computer science students enrolled in Northeastern University to determine how accurately participants judge differences in particular graphical encodings. We record the accuracy of participants’ answers for five encodings most commonly used with quantitative data. The results of our controlled experiment show that children have remarkably similar graphical perception to adults, but are consistently less accurate at interpreting the visual encodings. We found similar effectiveness rankings, relative differences in error between the different encodings, and patterns of bias across encoding types. Based on our findings, we provide design guidelines and recommendations for creating visualizations for children. This paper and all supplemental materials are available at https://osf.io/ygrdv.",Liudas Panavas;Amy E. Worth;Tarik Crnovrsanin;Tejas Sathyamurthi;Sara Cordes;Michelle A. Borkin;Cody Dunne,
CHI,2022,Reflective Spring Cleaning: Using Personal Informatics to Support Infrequent Notification Personalization,10.1145/3491102.3517493,"Distracting mobile notifications are a high-profile problem but previous research suggests notification management tools are underused because of the barriers users face in relation to the perceived benefits. We posit that users might be more motivated to personalize if they could view contextual data for how personalizations would have impacted their recent notifications. We propose the ‘Reflective Spring Cleaning’ approach to support notification management through infrequent personalization with visualization of collected notification data. To simplify and contextualize key trends in a user’s notifications, we framed these visualizations within a novel who-what-when data abstraction. We evaluated it through a four-week longitudinal study: 21 participants logged their notifications before and after a personalization session that included suggestions for notification management contextualized against visualizations of their recent notifications. A debriefing interview described their new experience after two more weeks of logging. Our approach encouraged users to critically reflect on their notifications, which frequently inspired them to personalize and improved the experience of the majority.",Izabelle F. Janzen;Joanna McGrenere,
CHI,2022,Interpolating Happiness: Understanding the Intensity Gradations of Face Emojis Across Cultures,10.1145/3491102.3517661,"We frequently utilize face emojis to express emotions in digital communication. But how wholly and precisely do such pictographs sample the emotional spectrum, and are there gaps to be closed? Our research establishes emoji intensity scales for seven basic emotions: happiness, anger, disgust, sadness, shock, annoyance, and love. In our survey (N = 1195), participants worldwide assigned emotions and intensities to 68 face emojis. According to our results, certain feelings, such as happiness or shock, are visualized by manifold emojis covering a broad spectrum of intensities. Other feelings, such as anger, have limited and only very intense representative visualizations. We further emphasize that the cultural background influences emojis’ perception: for instance, linear-active cultures (e.g., UK, Germany) rate the intensity of such visualizations higher than multi-active (e.g., Brazil, Russia) or reactive cultures (e.g., Indonesia, Singapore). To summarize, our manuscript promotes future research on more expressive, culture-aware emoji design.",Andrey Krekhov;Katharina Emmerich;Johannes Fuchs 0001;Jens Harald Krüger,
CHI,2022,Designing Word Filter Tools for Creator-led Comment Moderation,10.1145/3491102.3517505,"Online social platforms centered around content creators often allow comments on content, where creators can then moderate the comments they receive. As creators can face overwhelming numbers of comments, with some of them harassing or hateful, platforms typically provide tools such as word filters for creators to automate aspects of moderation. From needfinding interviews with 19 creators about how they use existing tools, we found that they struggled with writing good filters as well as organizing and revising their filters, due to the difficulty of determining what the filters actually catch. To address these issues, we present FilterBuddy, a system that supports creators in authoring new filters or building from pre-made ones, as well as organizing their filters and visualizing what comments are captured by them over time. We conducted an early-stage evaluation of FilterBuddy with YouTube creators, finding that participants see FilterBuddy not just as a moderation tool, but also a means to organize their comments to better understand their audiences.",Shagun Jhaver;Quan Ze Chen;Detlef Knauss;Amy X. Zhang,
CHI,2022,Symphony: Composing Interactive Interfaces for Machine Learning,10.1145/3491102.3502102,"Interfaces for machine learning (ML), information and visualizations about models or data, can help practitioners build robust and responsible ML systems. Despite their benefits, recent studies of ML teams and our interviews with practitioners (n=9) showed that ML interfaces have limited adoption in practice. While existing ML interfaces are effective for specific tasks, they are not designed to be reused, explored, and shared by multiple stakeholders in cross-functional teams. To enable analysis and communication between different ML practitioners, we designed and implemented Symphony, a framework for composing interactive ML interfaces with task-specific, data-driven components that can be used across platforms such as computational notebooks and web dashboards. We developed Symphony through participatory design sessions with 10 teams (n=31), and discuss our findings from deploying Symphony to 3 production ML projects at Apple. Symphony helped ML practitioners discover previously unknown issues like data duplicates and blind spots in models while enabling them to share insights with other stakeholders.",Alex Bäuerle;Ángel Alexander Cabrera;Fred Hohman;Megan Maher;David Koski;Xavier Suau;Titus Barik;Dominik Moritz,
CHI,2022,Designing for Knowledge Construction to Facilitate the Uptake of Open Science: Laying out the Design Space,10.1145/3491102.3517450,"The uptake of open science resources needs knowledge construction on the side of the readers/receivers of scientific content. The design of technologies surrounding open science resources can facilitate such knowledge construction, but this has not been investigated yet. To do so, we first conducted a scoping review of literature, from which we draw design heuristics for knowledge construction in digital environments. Subsequently, we grouped the underlying technological functionalities into three design categories: i) structuring and supporting collaboration, ii) supporting the learning process, and iii) structuring, visualising and navigating (learning) content. Finally, we mapped the design categories and associated design heuristics to core components of popular open science platforms. This mapping constitutes a design space (design implications), which informs researchers and designers in the HCI community about suitable functionalities for supporting knowledge construction in existing or new digital open science platforms.",Leonie Disch;Angela Fessl;Viktoria Pammer-Schindler,
CHI,2022,STRAIDE: A Research Platform for Shape-Changing Spatial Displays based on Actuated Strings,10.1145/3491102.3517462,"We present STRAIDE, a string-actuated interactive display environment that allows to explore the promising potential of shape-changing interfaces for casual visualizations. At the core, we envision a platform that spatially levitates elements to create dynamic visual shapes in space. We conceptualize this type of tangible mid-air display and discuss its multifaceted design dimensions. Through a design exploration, we realize a physical research platform with adjustable parameters and modular components. For conveniently designing and implementing novel applications, we provide developer tools ranging from graphical emulators to in-situ augmented reality representations. To demonstrate STRAIDE’s reconfigurability, we further introduce three representative physical setups as a basis for situated applications including ambient notifications, personal smart home controls, and entertainment. They serve as a technical validation, lay the foundations for a discussion with developers that provided valuable insights, and encourage ideas for future usage of this type of appealing interactive installation.",Severin Engert;Konstantin Klamka;Andreas Peetz;Raimund Dachselt,
CHI,2022,Pandemic Displays: Considering Hygiene on Public Touchscreens in the Post-Pandemic Era,10.1145/3491102.3501937,"The COVID-19 pandemic created unprecedented questions for touch-based public displays regarding hygiene, risks, and general awareness. We study how people perceive and consider hygiene on shared touchscreens, and how touchscreens could be improved through hygiene-related functions. First, we report the results from an online survey (n = 286). Second, we present a hygiene concept for touchscreens that visualizes prior touches and provides information about the cleaning of the display and number of prior users. Third, we report the feedback for our hygiene concept from 77 participants. We find that there is demand for improved awareness of public displays’ hygiene status, especially among those with stronger concerns about COVID-19. A particularly desired detail is when the display has been cleaned. For visualizing prior touches, fingerprints worked best. We present further considerations for designing for hygiene on public displays.",Ville Mäkelä;Jonas Winter;Jasmin Schwab;Michael Koch 0001;Florian Alt,
CHI,2022,Investigating Potentials of Shape-Changing Displays for Sound Zones,10.1145/3491102.3517632,"In this paper, we investigate the use of shape-change for interaction with sound zones. A core challenge to designing interaction with sound zone systems is to support users’ understanding of the unique spatial properties of sound zones. Shape-changing interfaces present new opportunities for addressing this. We present a structured investigation into this. We leveraged the knowledge of 12 sound experts to define a set of basic shapes and movements. Then, we constructed a prototype and conducted an elicitation study with 17 novice users, investigating the experience of these shapes and movements. Our findings show that physical visualizations of sound zones can be useful in supporting users’ experience of sound zones. We present a framework of 4 basic pattern categories that prompt different sound zone experiences and outline further research directions for shape-change in supporting sound zone interaction.",Stine S. Johansen;Timothy Merritt 0001;Rune Møberg Jacobsen;Peter Axel Nielsen;Jesper Kjeldskov,
CHI,2022,Do You See What I Hear? - Peripheral Absolute and Relational Visualisation Techniques for Sound Zones,10.1145/3491102.3501938,"Sound zone technology allows multiple simultaneous sound experiences for multiple people in the same room without interference. However, given the inherent invisible and intangible nature of sound zones, it is unclear how to communicate the position and size of sound zones to users. This paper compares two visualisation techniques; absolute visualisation, relational visualisation, as well as a baseline condition without visualisations. In a within-subject experiment (N = 33), we evaluated these techniques for effectiveness and efficiency across four representative tasks. Our findings show that the absolute and relational visualisation techniques increase effectiveness in multi-user tasks but not in single-user tasks. The efficiency for all tasks was improved using visualisations. We discuss the potential of visualisations for sound zones and highlight future research opportunities for sound zone interaction.",Rune Møberg Jacobsen;Niels van Berkel;Mikael B. Skov;Stine S. Johansen;Jesper Kjeldskov,
CHI,2022,'Are They Doing Better In The Clinic Or At Home?': Understanding Clinicians' Needs When Visualizing Wearable Sensor Data Used In Remote Gait Assessments For People With Multiple Sclerosis,10.1145/3491102.3501989,"Walking impairment is a debilitating symptom of Multiple Sclerosis (MS), a disease affecting 2.8 million people worldwide. While clinicians’ in-person observational gait assessments are important, research suggests that data from wearable sensors can indicate early onset of gait impairment, track patients’ responses to treatment, and support remote and longitudinal assessment. We present an inquiry into supporting the transition from research to clinical practice. Co-design by HCI, biomedical, neurology and rehabilitation researchers resulted in a data-rich interface prototype for augmented gait analysis based on visualized sensor data. We used this as a prompt in interviews with ten experienced clinicians from a range of MS rehabilitation roles. We find that clinicians value quantitative sensor data within a whole patient narrative, to help track specific rehabilitation goals, but identify a tension between grasping critical information quickly and more detailed understanding. Based on the findings we make design recommendations for data-rich remote rehabilitation interfaces.",Ayanna Seals;Giuseppina Pilloni;Jin Kim;Raul Sanchez;John-Ross Rizzo;Leigh Charvet;Oded Nov;Graham Dove,
CHI,2022,BikeAR: Understanding Cyclists' Crossing Decision-Making at Uncontrolled Intersections using Augmented Reality,10.1145/3491102.3517560,"Cycling has become increasingly popular as a means of transportation. However, cyclists remain a highly vulnerable group of road users. According to accident reports, one of the most dangerous situations for cyclists are uncontrolled intersections, where cars approach from both directions. To address this issue and assist cyclists in crossing decision-making at uncontrolled intersections, we designed two visualizations that: (1) highlight occluded cars through an X-ray vision and (2) depict the remaining time the intersection is safe to cross via a Countdown. To investigate the efficiency of these visualizations, we proposed an Augmented Reality simulation as a novel evaluation method, in which the above visualizations are represented as AR, and conducted a controlled experiment with 24 participants indoors. We found that the X-ray ensures a fast selection of shorter gaps between cars, while the Countdown facilitates a feeling of safety and provides a better intersection overview.",Andrii Matviienko;Florian Müller 0003;Dominik Schön;Paul Seesemann;Sebastian Günther 0001;Max Mühlhäuser,
CHI,2022,Pretty Princess vs. Successful Leader: Gender Roles in Greeting Card Messages,10.1145/3491102.3502114,"People write personalized greeting cards on various occasions. While prior work has studied gender roles in greeting card messages, systematic analysis at scale and tools for raising the awareness of gender stereotyping remain under-investigated. To this end, we collect a large greeting card message corpus covering three different occasions (birthday, Valentine’s Day and wedding) from three sources (exemplars from greeting message websites, real-life greetings from social media and language model generated ones). We uncover a wide range of gender stereotypes in this corpus via topic modeling, odds ratio and Word Embedding Association Test (WEAT). We further conduct a survey to understand people’s perception of gender roles in messages from this corpus and if gender stereotyping is a concern. The results show that people want to be aware of gender roles in the messages, but remain unconcerned unless the perceived gender roles conflict with the recipient’s true personality. In response, we developed GreetA, an interactive visualization and writing assistant tool to visualize fine-grained topics in greeting card messages drafted by the users and the associated gender perception scores, but without suggesting text changes as an intervention.",Jiao Sun;Tongshuang Wu;Yue Jiang;Ronil Awalegaonkar;Xi Victoria Lin;Diyi Yang,HM
CHI,2022,Smooth as Steel Wool: Effects of Visual Stimuli on the Haptic Perception of Roughness in Virtual Reality,10.1145/3491102.3517454,"Haptic Feedback is essential for lifelike Virtual Reality (VR) experiences. To provide a wide range of matching sensations of being touched or stroked, current approaches typically need large numbers of different physical textures. However, even advanced devices can only accommodate a limited number of textures to remain wearable. Therefore, a better understanding is necessary of how expectations elicited by different visualizations affect haptic perception, to achieve a balance between physical constraints and great variety of matching physical textures. In this work, we conducted an experiment (N=31) assessing how the perception of roughness is affected within VR. We designed a prototype for arm stroking and compared the effects of different visualizations on the perception of physical textures with distinct roughnesses. Additionally, we used the visualizations’ real-world materials, no-haptics and vibrotactile feedback as baselines. As one result, we found that two levels of roughness can be sufficient to convey a realistic illusion.",Sebastian Günther 0001;Julian Rasch;Dominik Schön;Florian Müller 0003;Martin Schmitz;Jan Riemann;Andrii Matviienko;Max Mühlhäuser,
CHI,2022,Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels,10.1145/3491102.3501823,"The confusion matrix, a ubiquitous visualization for helping people evaluate machine learning models, is a tabular layout that compares predicted class labels against actual class labels over all data instances. We conduct formative research with machine learning practitioners at Apple and find that conventional confusion matrices do not support more complex data-structures found in modern-day applications, such as hierarchical and multi-output labels. To express such variations of confusion matrices, we design an algebra that models confusion matrices as probability distributions. Based on this algebra, we develop Neo, a visual analytics system that enables practitioners to flexibly author and interact with hierarchical and multi-output confusion matrices, visualize derived metrics, renormalize confusions, and share matrix specifications. Finally, we demonstrate Neo’s utility with three model evaluation scenarios that help people better understand model performance and reveal hidden confusions.",Jochen Görtler;Fred Hohman;Dominik Moritz;Kanit Wongsuphasawat;Donghao Ren;Rahul Nair;Marc Kirchner;Kayur Patel,BP
CHI,2022,Structure-aware Visualization Retrieval,10.1145/3491102.3502048,"With the wide usage of data visualizations, a huge number of Scalable Vector Graphic (SVG)-based visualizations have been created and shared online. Accordingly, there has been an increasing interest in exploring how to retrieve perceptually similar visualizations from a large corpus, since it can benefit various downstream applications such as visualization recommendation. Existing methods mainly focus on the visual appearance of visualizations by regarding them as bitmap images. However, the structural information intrinsically existing in SVG-based visualizations is ignored. Such structural information can delineate the spatial and hierarchical relationship among visual elements, and characterize visualizations thoroughly from a new perspective. This paper presents a structure-aware method to advance the performance of visualization retrieval by collectively considering both the visual and structural information. We extensively evaluated our approach through quantitative comparisons, a user study and case studies. The results demonstrate the effectiveness of our approach and its advantages over existing methods.",Haotian Li 0001;Yong Wang 0021;Aoyu Wu;Huan Wei;Huamin Qu,HM
CHI,2022,ComputableViz: Mathematical Operators as a Formalism for Visualisation Processing and Analysis,10.1145/3491102.3517618,"Data visualizations are created and shared on the web at an unprecedented speed, raising new needs and questions for processing and analyzing visualizations after they have been generated and digitized. However, existing formalisms focus on operating on a single visualization instead of multiple visualizations, making it challenging to perform analysis tasks such as sorting and clustering visualizations. Through a systematic analysis of previous work, we abstract visualization-related tasks into mathematical operators such as union and propose a design space of visualization operations. We realize the design by developing ComputableViz, a library that supports operations on multiple visualization specifications. To demonstrate its usefulness and extensibility, we present multiple usage scenarios concerning processing and analyzing visualization, such as generating visualization embeddings and automatically making visualizations accessible. We conclude by discussing research opportunities and challenges for managing and exploiting the massive visualizations on the web.",Aoyu Wu;Wai Tong;Haotian Li 0001;Dominik Moritz;Yong Wang 0021;Huamin Qu,
CHI,2022,Recommendations for Visualization Recommendations: Exploring Preferences and Priorities in Public Health,10.1145/3491102.3501891,"The promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. However, little research to date has focused on what analysts value in the design of visualization recommendations. We interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset1 in service of generating visualizations to recommend to others. We also explored how they interacted with a corpus of both automatically- and manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. We find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. We conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.",Calvin S. Bao;Siyao Li;Sarah G. Flores;Michael Correll;Leilani Battle,
CHI,2022,VisGuide: User-Oriented Recommendations for Data Event Extraction,10.1145/3491102.3517648,"Data exploration systems have become popular tools with which data analysts and others can explore raw data and organize their observations. However, users of such systems who are unfamiliar with their datasets face several challenges when trying to extract data events of interest to them. Those challenges include progressively discovering informative charts, organizing them into a logical order to depict a meaningful fact, and arranging one or more facts to illustrate a data event. To alleviate them, we propose VisGuide—a data exploration system that generates personalized recommendations to aid users’ discovery of data events in breadth and depth by incrementally learning their data exploration preferences and recommending meaningful charts tailored to them. As well as user preferences, VisGuide’s recommendations simultaneously consider sequence organization and chart presentation. We conducted two user studies to evaluate 1) the usability of VisGuide and 2) user satisfaction with its recommendation system. The results of those studies indicate that VisGuide can effectively help users create coherent and user-oriented visualization trees that represent meaningful data events.",Yu-Rong Cao;Xiao-Han Li;Jia-Yu Pan;Wen-Chieh Lin,
CHI,2022,Visualizing Urban Accessibility: Investigating Multi-Stakeholder Perspectives through a Map-based Design Probe Study,10.1145/3491102.3517460,"Urban accessibility assessments are challenging: they involve varied stakeholders across decision-making contexts while serving a diverse population of people with disabilities. To better support urban accessibility assessment using data visualizations, we conducted a three-part interview study with 25 participants across five stakeholder groups using map visualization probes. We present a multi-stakeholder analysis of visualization needs and sensemaking processes to explore how interactive visualizations can support stakeholder decision making. In particular, we elaborate how stakeholders’ varying levels of familiarity with accessibility, geospatial analysis, and specific geographic locations influences their sensemaking needs. We then contribute 10 design considerations for geovisual analytic tools for urban accessibility communication, planning, policymaking, and advocacy.",Manaswi Saha;Siddhant Patil;Emily Cho;Evie Yu-Yen Cheng;Chris Horng;Devanshi Chauhan;Rachel Kangas;Richard McGovern;Anthony Li;Jeffrey Heer;Jon E. Froehlich,
CHI,2022,"""I See You!"": A Design Framework for Interface Cues about Agent Visual Perception from a Thematic Analysis of Videogames",10.1145/3491102.3517699,"As artificial agents proliferate, there will be more and more situations in which they must communicate their capabilities to humans, including what they can “see.” Artificial agents have existed for decades in the form of computer-controlled agents in videogames. We analyze videogames in order to not only inspire the design of better agents, but to stop agent designers from replicating research that has already been theorized, designed, and tested in-depth. We present a qualitative thematic analysis of sight cues in videogames and develop a framework to support human-agent interaction design. The framework identifies the different locations and stimulus types – both visualizations and sonifications – available to designers and the types of information they can convey as sight cues. Insights from several other cue properties are also presented. We close with suggestions for implementing such cues with existing technologies to improve the safety, privacy, and efficiency of human-agent interactions.",Matthew Rueben;Matthew Rodney Horrocks;Jennifer Eleanor Martinez;Michelle V. Cormier;Nicolas J. LaLone;Marlena R. Fraune;Z. Toups Dugas,
CHI,2022,Understanding and Designing Avatar Biosignal Visualizations for Social Virtual Reality Entertainment,10.1145/3491102.3517451,"Visualizing biosignals can be important for social Virtual Reality (VR), where avatar non-verbal cues are missing. While several biosignal representations exist, designing effective visualizations and understanding user perceptions within social VR entertainment remains unclear. We adopt a mixed-methods approach to design biosignals for social VR entertainment. Using survey (N=54), context-mapping (N=6), and co-design (N=6) methods, we derive four visualizations. We then ran a within-subjects study (N=32) in a virtual jazz-bar to investigate how heart rate (HR) and breathing rate (BR) visualizations, and signal rate, influence perceived avatar arousal, user distraction, and preferences. Findings show that skeuomorphic visualizations for both biosignals allow differentiable arousal inference; skeuomorphic and particles were least distracting for HR, whereas all were similarly distracting for BR; biosignal perceptions often depend on avatar relations, entertainment type, and emotion inference of avatars versus spaces. We contribute HR and BR visualizations, and considerations for designing social VR entertainment biosignal visualizations.",Sueyoon Lee;Abdallah El Ali;Maarten W. A. Wijntjes;Pablo César,
CHI,2022,Sensitive Pictures: Emotional Interpretation in the Museum,10.1145/3491102.3502080,"Museums are interested in designing emotional visitor experiences to complement traditional interpretations. HCI is interested in the relationship between Affective Computing and Affective Interaction. We describe Sensitive Pictures, an emotional visitor experience co-created with the Munch art museum. Visitors choose emotions, locate associated paintings in the museum, experience an emotional story while viewing them, and self-report their response. A subsequent interview with a portrayal of the artist employs computer vision to estimate emotional responses from facial expressions. Visitors are given a souvenir postcard visualizing their emotional data. A study of 132 members of the public (39 interviewed) illuminates key themes: designing emotional provocations; capturing emotional responses; engaging visitors with their data; a tendency for them to align their views with the system's interpretation; and integrating these elements into emotional trajectories. We consider how Affective Computing can hold up a mirror to our emotions during Affective Interaction",Steve Benford;Anders Sundnes Løvlie;Karin Ryding;Paulina Rajkowska;Edgar Bodiaj;Dimitrios Paris Darzentas;Harriet R. Cameron;Jocelyn Spence;Joy Egede;Bogdan Spanjevic,
CHI,2022,Supporting Accessible Data Visualization Through Audio Data Narratives,10.1145/3491102.3517678,"Online data visualizations play an important role in informing public opinion but are often inaccessible to screen reader users. To address the need for accessible data representations on the web that provide direct, multimodal, and up-to-date access to the data, we investigate audio data narratives –which combine textual descriptions and sonification (the mapping of data to non-speech sounds). We conduct two co-design workshops with screen reader users to define design principles that guide the structure, content, and duration of a data narrative. Based on these principles and relevant auditory processing characteristics, we propose a dynamic programming approach to automatically generate an audio data narrative from a given dataset. We evaluate our approach with 16 screen reader users. Findings show with audio narratives, users gain significantly more insights from the data. Users describe data narratives help them better extract and comprehend the information in both the sonification and description.",Alexa F. Siu;Gene S.-H. Kim;Sile O'Modhrain;Sean Follmer,
CHI,2022,Slide-Tone and Tilt-Tone: 1-DOF Haptic Techniques for Conveying Shape Characteristics of Graphs to Blind Users,10.1145/3491102.3517790,"We increasingly rely on up-to-date, data-driven graphs to understand our environments and make informed decisions. However, many of the methods blind and visually impaired users (BVI) rely on to access data-driven information do not convey important shape-characteristics of graphs, are not refreshable, or are prohibitively expensive. To address these limitations, we introduce two refreshable, 1-DOF audio-haptic interfaces based on haptic cues fundamental to object shape perception. Slide-tone uses finger position with sonification, and Tilt-tone uses fingerpad contact inclination with sonification to provide shape feedback to users. Through formative design workshops (n = 3) and controlled evaluations (n = 8), we found that BVI participants appreciated the additional shape information, versatility, and reinforced understanding these interfaces provide; and that task accuracy was comparable to using interactive tactile graphics or sonification alone. Our research offers insight into the benefits, limitations, and considerations for adopting these haptic cues into a data visualization context.",Danyang Fan;Alexa Fay Siu;Wing-Sum Adrienne Law;Raymond Ruihong Zhen;Sile O'Modhrain;Sean Follmer,
CHI,2022,VoxLens: Making Online Data Visualizations Accessible with an Interactive JavaScript Plug-In,10.1145/3491102.3517431,"JavaScript visualization libraries are widely used to create online data visualizations but provide limited access to their information for screen-reader users. Building on prior findings about the experiences of screen-reader users with online data visualizations, we present VoxLens, an open-source JavaScript plug-in that—with a single line of code—improves the accessibility of online data visualizations for screen-reader users using a multi-modal approach. Specifically, VoxLens enables screen-reader users to obtain a holistic summary of presented information, play sonified versions of the data, and interact with visualizations in a “drill-down” manner using voice-activated commands. Through task-based experiments with 21 screen-reader users, we show that VoxLens improves the accuracy of information extraction and interaction time by 122% and 36%, respectively, over existing conventional interaction with online data visualizations. Our interviews with screen-reader users suggest that VoxLens is a “game-changer” in making online data visualizations accessible to screen-reader users, saving them time and effort.",Ather Sharif;Olivia H. Wang;Alida T. Muongchan;Katharina Reinecke;Jacob O. Wobbrock,
CHI,2022,Infosonics: Accessible Infographics for People who are Blind using Sonification and Voice,10.1145/3491102.3517465,"Data visualisations are increasingly used online to engage readers and enable independent analysis of the data underlying news stories. However, access to such infographics is problematic for readers who are blind or have low vision (BLV). Equitable access to information is a basic human right and essential for independence and inclusion. We introduce infosonics, the audio equivalent of infographics, as a new style of interactive sonification that uses a spoken introduction and annotation, non-speech audio and sound design elements to present data in an understandable and engaging way. A controlled user evaluation with 18 BLV adults found a COVID-19 infosonic enabled a clearer mental image than a traditional sonification. Further, infosonics prove complementary to text descriptions and facilitate independent understanding of the data. Based on our findings, we provide preliminary suggestions for infosonics design, which we hope will enable BLV people to gain equitable access to online news and information.",Leona M. Holloway;Cagatay Goncu;Alon Ilsar;Matthew Butler 0002;Kim Marriott,
CHI,2022,Tangible Globes for Data Visualisation in Augmented Reality,10.1145/3491102.3517715,"Head-mounted augmented reality (AR) displays allow for the seamless integration of virtual visualisation with contextual tangible references, such as physical (tangible) globes. We explore the design of immersive geospatial data visualisation with AR and tangible globes. We investigate the “tangible-virtual interplay” of tangible globes with virtual data visualisation, and propose a conceptual approach for designing immersive geospatial globes. We demonstrate a set of use cases, such as augmenting a tangible globe with virtual overlays, using a physical globe as a tangible input device for interacting with virtual globes and maps, and linking an augmented globe to an abstract data visualisation. We gathered qualitative feedback from experts about our use case visualisations, and compiled a summary of key takeaways as well as ideas for envisioned future improvements. The proposed design space, example visualisations and lessons learned aim to guide the design of tangible globes for data visualisation in AR.",Kadek Ananta Satriadi;Jim Smiley;Barrett Ens;Maxime Cordeil;Tobias Czauderna;Benjamin Lee;Ying Yang;Tim Dwyer;Bernhard Jenny,
CHI,2022,"FluidMeet: Enabling Frictionless Transitions Between In-Group, Between-Group, and Private Conversations During Virtual Breakout Meetings",10.1145/3491102.3517558,"People often form small conversation groups during physical gatherings to have ad-hoc and informal conversations. As these groups are loosely defined, others can often overhear and join the conversation. However, current video-conferencing tools only allow for strict boundaries between small conversation groups, inhibiting fluid group formations and between-group conversations. This isolates small-group conversations from others and leads to inefficient transitions between conversations. We present FluidMeet, a virtual breakout meeting system that employs flexible conversation boundaries and cross-group conversation visualizations to enable fluid conversation group formations and ad-hoc, informal conversations. FluidMeet enables out-group members to overhear group conversations while allowing conversation groups to control their shared level of context. Users within conversation groups can also quickly switch between in-group and private conversations. A study of FluidMeet showed that it encouraged users to break group boundaries, made them feel less isolated in group conversations, and facilitated communication across different groups.",Erzhen Hu;Md. Aashikur Rahman Azim;Seongkook Heo,
CHI,2022,One Week in the Future: Previs Design Futuring for HCI Research,10.1145/3491102.3517584,"We explore the use of cinematic “pre-visualization” (previs) techniques as a rapid ideation and design futuring method for human computer interaction (HCI) research. Previs approaches, which are widely used in animation and film production, use digital design tools to create medium-fidelity videos that capture richer interaction, motion, and context than sketches or static illustrations. When used as a design futuring method, previs can facilitate rapid, iterative discussions that reveal tensions, challenges, and opportunities for new research. We performed eight one-week design futuring sprints, in which individual HCI researchers collaborated with a lead designer to produce concept sketches, storyboards, and videos that examined future applications of their research. From these experiences, we identify recurring themes and challenges and present a One Week Futuring Workbook that other researchers can use to guide their own futuring sprints. We also highlight how variations of our approach could support other speculative design practices.",Alexander Ivanov 0004;Tim Au Yeung;Kathryn Blair;Kurtis Thorvald Danyluk;Georgina Freeman;Marcus Friedel;Carmen Hull;Michael Yuk-Shing Hung;Sydney Pratte;Wesley Willett,
CHI,2022,Paracentral and near-peripheral visualizations: Towards attention-maintaining secondary information presentation on OHMDs during in-person social interactions,10.1145/3491102.3502127,"Optical see-through Head-Mounted Displays (OST HMDs, OHMDs) are known to facilitate situational awareness while accessing secondary information. However, information displayed on OHMDs can cause attention shifts, which distract users from natural social interactions. We hypothesize that information displayed in paracentral and near-peripheral vision can be better perceived while the user is maintaining eye contact during face-to-face conversations. Leveraging this idea, we designed a circular progress bar to provide progress updates in paracentral and near-peripheral vision. We compared it with textual and linear progress bars under two conversation settings: a simulated one with a digital conversation partner and a realistic one with a real partner. Results show that a circular progress bar can effectively reduce notification distractions without losing eye contact and is more preferred by users. Our findings highlight the potential of utilizing the paracentral and near-peripheral vision for secondary information presentation on OHMDs.",Nuwan Janaka;Chloe Haigh;Hyeong Cheol Kim;Shan Zhang;Shengdong Zhao,HM
CHI,2022,i-LaTeX : Manipulating Transitional Representations between LaTeX Code and Generated Documents,10.1145/3491102.3517494,"Document description languages such as LaTeX are used extensively to author scientific and technical documents, but editing them is cumbersome: code-based editors only provide generic features, while WYSIWYG interfaces only support a subset of the language. Our interviews with 11 LaTeX users highlighted their difficulties dealing with textually-encoded abstractions and with the mappings between source code and document output. To address some of these issues, we introduce Transitional Representations for document description languages, which enable the visualisation and manipulation of fragments of code in relation to their generated output. We present i-LaTeX, a LaTeX editor equipped with Transitional Representations of formulae, tables, images, and grid layouts. A 16-participant experiment shows that Transitional Representations let them complete common editing tasks significantly faster, with fewer compilations, and with a lower workload. We discuss how Transitional Representations affect editing strategies and conclude with directions for future work.",Camille Gobert;Michel Beaudouin-Lafon,
CHI,2022,"Classroom Dandelions: Visualising Participant Position, Trajectory and Body Orientation Augments Teachers' Sensemaking",10.1145/3491102.3517736,"Despite the digital revolution, physical space remains the site for teaching and learning embodied knowledge and skills. Both teachers and students must develop spatial competencies to effectively use classroom spaces, enabling fluid verbal and non-verbal interaction. While video permits rich activity capture, it provides no support for quickly seeing activity patterns that can assist learning. In contrast, position tracking systems permit the automated modelling of spatial behaviour, opening new possibilities for feedback. This paper introduces the design rationale for ”Dandelion Diagrams” that integrate participant location, trajectory and body orientation over a variable period. Applied in two authentic teaching contexts (a science laboratory, and a nursing simulation) we show how heatmaps showing only teacher/student location led to misinterpretations that were resolved by overlaying Dandelion Diagrams. Teachers also identified a variety of ways they could aid professional development. We conclude Dandelion Diagrams assisted sensemaking, but discuss the ethical risks of over-interpretation.",Gloria Fernández-Nieto;Pengcheng An;Jian Zhao 0010;Simon Buckingham Shum;Roberto Martínez Maldonado,
CHI,2022,GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information,10.1145/3491102.3502141,"We investigate how multiple sliders with and without feedforward visualizations influence users’ control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (StyleGAN2) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.",Hai Dang;Lukas Mecke;Daniel Buschek,
CHI,2022,'ShishuShurokkha': A Transformative Justice Approach for Combating Child Sexual Abuse in Bangladesh,10.1145/3491102.3517543,"The challenge of designing against child sexual abuse becomes more complicated in conservative societies where talking about sex is tabooed. Our mix-method study, comprised of an online survey, five FGDs, and 20 semi-structured interviews in Bangladesh, investigates the common nature, location, and time of the abuse, post-incident support, and possible combating strategies. Besides revealing important facts, our findings highlight the need of decentering the design from the victims (children and/or guardians) to the community. Hence, building on the theory of transformative justice, we prototyped and evaluated ‘ShishuShurokkha’ – an online tool that involves the whole community by allowing anonymous bystander reporting, visualizing case-maps, connecting with legal, medical, and social support, and raising awareness. The evaluation of ShishuShurokkha shows the promise for such a communal approach toward combating child sexual abuse, and highlights the needs for sincere involvement of the government, NGOs, the legal, educational, and religious services in this.",Sharifa Sultana;Sadia Tasnuva Pritha;Rahnuma Tasnim;Anik Das;Rokeya Akter;Shaid Hasan;S. M. Raihanul Alam;Muhammad Ashad Kabir;Syed Ishtiaque Ahmed,
CHI,2022,Data Every Day: Designing and Living with Personal Situated Visualizations,10.1145/3491102.3517737,"We explore the design and utility of situated manual self-tracking visualizations on dedicated displays that integrate data tracking into existing practices and physical environments. Situating self-tracking tools in relevant locations is a promising approach to enable reflection on and awareness of data without needing to rely on sensorized tracking or personal devices. In both a long-term autobiographical design process and a co-design study with six participants, we rapidly prototyped and deployed 30 situated self-tracking applications over a ten month period. Grounded in the experience of designing and living with these trackers, we contribute findings on logging and data entry, the use of situated displays, and the visual design and customization of trackers. Our results demonstrate the potential of customizable dedicated self-tracking visualizations that are situated in relevant physical spaces, and suggest future research opportunities and new potential applications for situated visualizations.",Nathalie Bressa;Jo Vermeulen;Wesley Willett,
CHI,2022,Supporting Data-Driven Basketball Journalism through Interactive Visualization,10.1145/3491102.3502078,"Basketball writers and journalists report on the sport that millions of fans follow and love. However, the recent emergence of pervasive data about the sport and the growth of new forms of sports analytics is changing writers’ jobs. While these writers seek to leverage the data and analytics to create engaging, data-driven stories, they typically lack the technical background to perform analytics or efficiently explore data. We investigated and analyzed the work and context of basketball writers, interviewed nine stakeholders to understand the challenges from a holistic view. Based on what we learned, we designed and constructed two interactive visualization systems that support rapid and in-depth sports data exploration and sense-making to enhance their articles and reporting. We deployed the systems during the recent NBA playoffs to gather initial feedback. This article describes the visualization design study we conducted, the resulting visualization systems, and what we learned to potentially help basketball writers in the future.",Yu Fu;John T. Stasko,
CHI,2022,Cicero: A Declarative Grammar for Responsive Visualization,10.1145/3491102.3517455,"Designing responsive visualizations can be cast as applying transformations to a source view to render it suitable for a different screen size. However, designing responsive visualizations is often tedious as authors must manually apply and reason about candidate transformations. We present Cicero, a declarative grammar for concisely specifying responsive visualization transformations which paves the way for more intelligent responsive visualization authoring tools. Cicero’s flexible specifier syntax allows authors to select visualization elements to transform, independent of the source view’s structure. Cicero encodes a concise set of actions to encode a diverse set of transformations in both desktop-first and mobile-first design processes. Authors can ultimately reuse design-agnostic transformations across different visualizations. To demonstrate the utility of Cicero, we develop a compiler to an extended version of Vega-Lite, and provide principles for our compiler. We further discuss the incorporation of Cicero into responsive visualization authoring tools, such as a design recommender.",Hyeok Kim;Ryan A. Rossi;Fan Du;Eunyee Koh;Shunan Guo;Jessica Hullman;Jane Hoffswell,
CHI,2021,Data Animator: Authoring Expressive Animated Data Graphics,10.1145/3411764.3445747,"Animation helps viewers follow transitions in data graphics. When authoring animations that incorporate data, designers must carefully coordinate the behaviors of visual objects such as entering, exiting, merging and splitting, and specify the temporal rhythms of transition through staging and staggering. We present Data Animator, a system for authoring animated data graphics without programming. Data Animator leverages the Data Illustrator framework to analyze and match objects between two static visualizations, and generates automated transitions by default. Designers have the flexibility to interpret and adjust the matching results through a visual interface. Data Animator also supports the division of a complex animation into stages through hierarchical keyframes, and uses data attributes to stagger the start time and vary the speed of animating objects through a novel timeline interface. We validate Data Animator’s expressiveness via a gallery of examples, and evaluate its usability in a re-creation study with designers.",John R. Thompson 0002;Zhicheng Liu 0001;John T. Stasko,
CHI,2021,Integrated Visualization Editing via Parameterized Declarative Templates,10.1145/3411764.3445356,"Interfaces for creating visualizations typically embrace one of several common forms. Textual specification enables fine-grained control, shelf building facilitates rapid exploration, while chart choosing promotes immediacy and simplicity. Ideally these approaches could be unified to integrate the user- and usage-dependent benefits found in each modality, yet these forms remain distinct. We propose parameterized declarative templates, a simple abstraction mechanism over JSON-based visualization grammars, as a foundation for multimodal visualization editors. We demonstrate how templates can facilitate organization and reuse by factoring the more than 160 charts that constitute Vega-Lite’s example gallery into approximately 40 templates. We exemplify the pliability of abstracting over charting grammars by implementing—as a template—the functionality of the shelf builder Polestar (a simulacra of Tableau) and a set of templates that emulate the Google Sheets chart chooser. We show how templates support multimodal visualization editing by implementing a prototype and evaluating it through an approachability study.",Andrew M. McNutt;Ravi Chugh,
CHI,2021,Data Prophecy: Exploring the Effects of Belief Elicitation in Visual Analytics,10.1145/3411764.3445798,"Interactive visualizations are widely used in exploratory data analysis, but existing systems provide limited support for confirmatory analysis. We introduce PredictMe, a tool for belief-driven visual analysis, enabling users to draw and test their beliefs against data, as an alternative to data-driven exploration. PredictMe combines belief elicitation with traditional visualization interactions to support mixed analysis styles. In a comparative study, we investigated how these affordances impact participants’ cognition. Results show that PredictMe prompts participants to incorporate their working knowledge more frequently in queries. Participants were more likely to attend to discrepancies between their mental models and the data. However, those same participants were also less likely to engage in interactions associated with exploration, and ultimately inspected fewer visualizations and made fewer discoveries. The results suggest that belief elicitation may moderate exploratory behaviors, instead nudging users to be more deliberate in their analysis. We discuss the implications for visualization design.",Ratanond Koonchanok;Parul Baser;Abhinav Sikharam;Nirmal Kumar Raveendranath;Khairi Reda,
CHI,2021,ConceptScope: Organizing and Visualizing Knowledge in Documents based on Domain Ontology,10.1145/3411764.3445396,"Current text visualization techniques typically provide overviews of document content and structure using intrinsic properties such as term frequencies, co-occurrences, and sentence structures. Such visualizations lack conceptual overviews incorporating domain-relevant knowledge, needed when examining documents such as research articles or technical reports. To address this shortcoming, we present ConceptScope, a technique that utilizes a domain ontology to represent the conceptual relationships in a document in the form of a Bubble Treemap visualization. Multiple coordinated views of document structure and concept hierarchy with text overviews further aid document analysis. ConceptScope facilitates exploration and comparison of single and multiple documents respectively. We demonstrate ConceptScope by visualizing research articles and transcripts of technical presentations in computer science. In a comparative study with DocuBurst, a popular document visualization tool, ConceptScope was found to be more informative in exploring and comparing domain-specific documents, but less so when it came to documents that spanned multiple disciplines.",Xiaoyu Zhang;Senthil K. Chandrasegaran;Kwan-Liu Ma,
CHI,2021,Modeling and Leveraging Analytic Focus During Exploratory Visual Analysis,10.1145/3411764.3445674,"Visual analytics systems enable highly interactive exploratory data analysis. Across a range of fields, these technologies have been successfully employed to help users learn from complex data. However, these same exploratory visualization techniques make it easy for users to discover spurious findings. This paper proposes new methods to monitor a user’s analytic focus during visual analysis of structured datasets and use it to surface relevant articles that contextualize the visualized findings. Motivated by interactive analyses of electronic health data, this paper introduces a formal model of analytic focus, a computational approach to dynamically update the focus model at the time of user interaction, and a prototype application that leverages this model to surface relevant medical publications to users during visual analysis of a large corpus of medical records. Evaluation results with 24 users show that the modeling approach has high levels of accuracy and is able to surface highly relevant medical abstracts.",Zhilan Zhou;Ximing Wen;Yue Wang 0035;David Gotz,
CHI,2021,mTSeer: Interactive Visual Exploration of Models on Multivariate Time-series Forecast,10.1145/3411764.3445083,"Time-series forecasting contributes crucial information to industrial and institutional decision-making with multivariate time-series input. Although various models have been developed to facilitate the forecasting process, they make inconsistent forecasts. Thus, it is critical to select the model appropriately. The existing selection methods based on the error measures fail to reveal deep insights into the model’s performance, such as the identification of salient features and the impact of temporal factors (e.g., periods). This paper introduces mTSeer, an interactive system for the exploration, explanation, and evaluation of multivariate time-series forecasting models. Our system integrates a set of algorithms to steer the process, and rich interactions and visualization designs to help interpret the differences between models in both model and instance level. We demonstrate the effectiveness of mTSeer through three case studies with two domain experts on real-world data, qualitative interviews with the two experts, and quantitative evaluation of the three case studies.",Ke Xu;Jun Yuan;Yifang Wang 0001;Cláudio T. Silva;Enrico Bertini,
CHI,2021,reVISit: Looking Under the Hood of Interactive Visualization Studies,10.1145/3411764.3445382,"Quantifying user performance with metrics such as time and accuracy does not show the whole picture when researchers evaluate complex, interactive visualization tools. In such systems, performance is often influenced by different analysis strategies that statistical analysis methods cannot account for. To remedy this lack of nuance, we propose a novel analysis methodology for evaluating complex interactive visualizations at scale. We implement our analysis methods in reVISit, which enables analysts to explore participant interaction performance metrics and responses in the context of users’ analysis strategies. Replays of participant sessions can aid in identifying usability problems during pilot studies and make individual analysis processes salient. To demonstrate the applicability of reVISit to visualization studies, we analyze participant data from two published crowdsourced studies. Our findings show that reVISit can be used to reveal and describe novel interaction patterns, to analyze performance differences between different analysis strategies, and to validate or challenge design decisions.",Carolina Nobre;Dylan Wootton;Zach Cutler;Lane Harrison;Hanspeter Pfister;Alexander Lex,
CHI,2021,IGScript: An Interaction Grammar for Scientific Data Presentation,10.1145/3411764.3445535,"Most of the existing scientific visualizations toward interpretive grammar aim to enhance customizability in either the computation stage or the rendering stage or both, while few approaches focus on the data presentation stage. Besides, most of these approaches leverage the existing components from the general-purpose programming languages (GPLs) instead of developing a standalone compiler, which pose a great challenge about learning curves for the domain experts who have limited knowledge about programming. In this paper, we propose IGScript, a novel script-based interaction grammar tool, to help build scientific data presentation animations for communication. We design a dual-space interface and a compiler which converts natural language-like grammar statements or scripts into a data story animation to make an interactive customization on script-driven data presentations, and then develop a code generator (decompiler) to translate the interactive data exploration animations back into script codes to achieve statement parameters. IGScript makes the presentation animations editable, e.g., it allows to cut, copy, paste, append, or even delete some animation clips. We demonstrate the usability, customizability, and flexibility of IGScript by a user study, four case studies conducted by using four types of commonly-used scientific data, and performance evaluations.",Richen Liu;Min Gao;Shunlong Ye;Jiang Zhang 0002,
CHI,2021,PriView- Exploring Visualisations to Support Users' Privacy Awareness,10.1145/3411764.3445067,"We present PriView, a concept that allows privacy-invasive devices in the users’ vicinity to be visualised. PriView is motivated by an ever-increasing number of sensors in our environments tracking potentially sensitive data (e.g., audio and video). At the same time, users are oftentimes unaware of this, which violates their privacy. Knowledge about potential recording would enable users to avoid accessing such areas or not to disclose certain information. We built two prototypes: a) a mobile application capable of detecting smart devices in the environment using a thermal camera, and b) VR mockups of six scenarios where PriView might be useful (e.g., a rental apartment). In both, we included several types of visualisation. Results of our lab study (N=24) indicate that users prefer simple, permanent indicators while wishing for detailed visualisations on demand. Our exploration is meant to support future designs of privacy visualisations for varying smart environments.",Sarah Prange;Ahmed Shams;Robin Piening;Yomna Abdelrahman;Florian Alt,
CHI,2021,Soloist: Generating Mixed-Initiative Tutorials from Existing Guitar Instructional Videos Through Audio Processing,10.1145/3411764.3445162,"Learning musical instruments using online instructional videos has become increasingly prevalent. However, pre-recorded videos lack the instantaneous feedback and personal tailoring that human tutors provide. In addition, existing video navigations are not optimized for instrument learning, making the learning experience encumbered. Guided by our formative interviews with guitar players and prior literature, we designed Soloist, a mixed-initiative learning framework that automatically generates customizable curriculums from off-the-shelf guitar video lessons. Soloist takes raw videos as input and leverages deep-learning based audio processing to extract musical information. This back-end processing is used to provide an interactive visualization to support effective video navigation and real-time feedback on the user's performance, creating a guided learning experience. We demonstrate the capabilities and specific use-cases of Soloist within the domain of learning electric guitar solos using instructional YouTube videos. A remote user study, conducted to gather feedback from guitar players, shows encouraging results as the users unanimously preferred learning with Soloist over unconverted instructional videos.",Bryan Wang;Mengyu Yang;Tovi Grossman,
CHI,2021,Falx: Synthesis-Powered Visualization Authoring,10.1145/3411764.3445249,"Modern visualization tools aim to allow data analysts to easily create exploratory visualizations. When the input data layout conforms to the visualization design, users can easily specify visualizations by mapping data columns to visual channels of the design. However, when there is a mismatch between data layout and the design, users need to spend significant effort on data transformation. We propose Falx, a synthesis-powered visualization tool that allows users to specify visualizations in a similarly simple way but without needing to worry about data layout. In Falx, users specify visualizations using examples of how concrete values in the input are mapped to visual channels, and Falx automatically infers the visualization specification and transforms the data to match the design. In a study with 33 data analysts on four visualization tasks involving data transformation, we found that users can effectively adopt Falx to create visualizations they otherwise cannot implement.",Chenglong Wang;Yu Feng 0001;Rastislav Bodík;Isil Dillig;Alvin Cheung;Amy J. Ko,BP
CHI,2021,Locomotion Vault: the Extra Mile in Analyzing VR Locomotion Techniques,10.1145/3411764.3445319,"Numerous techniques have been proposed for locomotion in virtual reality (VR). Several taxonomies consider a large number of attributes (e.g., hardware, accessibility) to characterize these techniques. However, finding the appropriate locomotion technique (LT) and identifying gaps for future designs in the high-dimensional space of attributes can be quite challenging. To aid analysis and innovation, we devised Locomotion Vault (https://locomotionvault.github.io/), a database and visualization of over 100 LTs from academia and industry. We propose similarity between LTs as a metric to aid navigation and visualization. We show that similarity based on attribute values correlates with expert similarity assessments (a method that does not scale). Our analysis also highlights an inherent trade-off between simulation sickness and accessibility across LTs. As such, Locomotion Vault shows to be a tool that unifies information on LTs and enables their standardization and large-scale comparison to help understand the space of possibilities in VR locomotion.",Massimiliano Di Luca;Hasti Seifi;Simon Egan;Mar González-Franco,
CHI,2021,Comparison of Different Types of Augmented Reality Visualizations for Instructions,10.1145/3411764.3445724,"Augmented Reality (AR) is increasingly being used for providing guidance and supporting troubleshooting in industrial settings. While the general application of AR has been shown to provide clear benefits regarding physical tasks, it is important to understand how different visualization types influence user’s performance during the execution of the tasks. Previous studies evaluating AR and user’s performance compared different media types or types of AR hardware as opposed to different types of visualization for the same hardware type. This paper provides details of our comparative study in which we identified the influence of visualization types on the performance of complex machine set-up processes. Although our results show clear advantages to using concrete rather than abstract visualizations, we also find abstract visualizations coupled with videos leads to similar user performance as with concrete visualizations.",Florian Jasche;Sven Hoffmann;Thomas Ludwig 0005;Volker Wulf,
CHI,2021,"Effects of Semantic Segmentation Visualization on Trust, Situation Awareness, and Cognitive Load in Highly Automated Vehicles",10.1145/3411764.3445351,"Autonomous vehicles could improve mobility, safety, and inclusion in traffic. While this technology seems within reach, its successful introduction depends on the intended user’s acceptance. A substantial factor for this acceptance is trust in the autonomous vehicle’s capabilities. Visualizing internal information processed by an autonomous vehicle could calibrate this trust by enabling the perception of the vehicle’s detection capabilities (and its failures) while only inducing a low cognitive load. Additionally, the simultaneously raised situation awareness could benefit potential take-overs. We report the results of two comparative online studies on visualizing semantic segmentation information for the human user of autonomous vehicles. Effects on trust, cognitive load, and situation awareness were measured using a simulation (N=32) and state-of-the-art panoptic segmentation on a pre-recorded real-world video (N=41). Results show that the visualization using Augmented Reality increases situation awareness while remaining low cognitive load.",Mark Colley;Benjamin Eder;Jan Ole Rixen;Enrico Rukzio,
CHI,2021,Effect of Information Presentation on Fairness Perceptions of Machine Learning Predictors,10.1145/3411764.3445365,"The uptake of artificial intelligence-based applications raises concerns about the fairness and transparency of AI behaviour. Consequently, the Computer Science community calls for the involvement of the general public in the design and evaluation of AI systems. Assessing the fairness of individual predictors is an essential step in the development of equitable algorithms. In this study, we evaluate the effect of two common visualisation techniques (text-based and scatterplot) and the display of the outcome information (i.e., ground-truth) on the perceived fairness of predictors. Our results from an online crowdsourcing study (N = 80) show that the chosen visualisation technique significantly alters people’s fairness perception and that the presented scenario, as well as the participant’s gender and past education, influence perceived fairness. Based on these results we draw recommendations for future work that seeks to involve non-experts in AI fairness evaluations.",Niels van Berkel;Jorge Gonçalves 0001;Daniel Russo 0002;Simo Hosio;Mikael B. Skov,
CHI,2021,NBSearch: Semantic Search and Visual Exploration of Computational Notebooks,10.1145/3411764.3445048,"Code search is an important and frequent activity for developers using computational notebooks (e.g., Jupyter). The flexibility of notebooks brings challenges for effective code search, where classic search interfaces for traditional software code may be limited. In this paper, we propose, NBSearch, a novel system that supports semantic code search in notebook collections and interactive visual exploration of search results. NBSearch leverages advanced machine learning models to enable natural language search queries and intuitive visualizations to present complicated intra- and inter-notebook relationships in the returned results. We developed NBSearch through an iterative participatory design process with two experts from a large software company. We evaluated the models with a series of experiments and the whole system with a controlled user study. The results indicate the feasibility of our analytical pipeline and the effectiveness of NBSearch to support code search in large notebook collections.",Xingjun Li;Yuanxin Wang;Hong Wang;Yang Wang;Jian Zhao 0010,
CHI,2021,Understanding Trigger-Action Programs Through Novel Visualizations of Program Differences,10.1145/3411764.3445567,"Trigger-action programming (if-this-then-that rules) empowers non-technical users to automate services and smart devices. As a user’s set of trigger-action programs evolves, the user must reason about behavior differences between similar programs, such as between an original program and several modification candidates, to select programs that meet their goals. To facilitate this process, we co-designed user interfaces and underlying algorithms to highlight differences between trigger-action programs. Our novel approaches leverage formal methods to efficiently identify and visualize differences in program outcomes or abstract properties. We also implemented a traditional interface that shows only syntax differences in the rules themselves. In a between-subjects online experiment with 107 participants, the novel interfaces better enabled participants to select trigger-action programs matching intended goals in complex, yet realistic, situations that proved very difficult when using traditional interfaces showing syntax differences.",Valerie Zhao;Lefan Zhang;Bo Wang;Michael L. Littman;Shan Lu 0001;Blase Ur,HM
CHI,2021,Visualizing Examples of Deep Neural Networks at Scale,10.1145/3411764.3445654,"Many programmers want to use deep learning due to its superior accuracy in many challenging domains. Yet our formative study with ten programmers indicated that, when constructing their own deep neural networks (DNNs), they often had a difficult time choosing appropriate model structures and hyperparameter values. This paper presents ExampleNet—a novel interactive visualization system for exploring common and uncommon design choices in a large collection of open-source DNN projects. ExampleNet provides a holistic view of the distribution over model structures and hyperparameter settings in the corpus of DNNs, so users can easily filter the corpus down to projects tackling similar tasks and compare design choices made by others. We evaluated ExampleNet in a within-subjects study with sixteen participants. Compared with the control condition (i.e., online search), participants using ExampleNet were able to inspect more online examples, make more data-driven design decisions, and make fewer design mistakes.",Litao Yan;Elena L. Glassman;Tianyi Zhang 0001,HM
CHI,2021,GestureMap: Supporting Visual Analytics and Quantitative Analysis of Motion Elicitation Data by Learning 2D Embeddings,10.1145/3411764.3445765,"This paper presents GestureMap, a visual analytics tool for gesture elicitation which directly visualises the space of gestures. Concretely, a Variational Autoencoder embeds gestures recorded as 3D skeletons on an interactive 2D map. GestureMap further integrates three computational capabilities to connect exploration to quantitative measures: Leveraging DTW Barycenter Averaging (DBA), we compute average gestures to 1) represent gesture groups at a glance; 2) compute a new consensus measure (variance around average gesture); and 3) cluster gestures with k-means. We evaluate GestureMap and its concepts with eight experts and an in-depth analysis of published data. Our findings show how GestureMap facilitates exploring large datasets and helps researchers to gain a visual understanding of elicited gesture spaces. It further opens new directions, such as comparing elicitations across studies. We discuss implications for elicitation studies and research, and opportunities to extend our approach to additional tasks in gesture elicitation.",Hai Dang;Daniel Buschek,
CHI,2021,What Players Want: Information Needs of Players on Post-Game Visualizations,10.1145/3411764.3445174,"With the rise of competitive online gaming and esports, players’ ability to review, reflect upon, and improve their in-game performance has become important. Post-play visualizations are key for such improvements. Despite the increased interest in visualizations of gameplay, research specifically informing the design of player-centric visualizations is currently limited. As with all visualizations, their design should, however, be guided by a thorough understanding of the goals to be achieved and which information is important and why. This paper reports on a mixed-methods study exploring the information demands posed by players on post-play visualizations and the goals they pursue with such visualizations. We focused on three genres that enjoy great popularity within the competitive gaming scene. Our results provide useful guideposts on which data to focus on by offering an overview of the relevance of different in-game metrics across genres. Lastly, we outline high-level implications for the design of post-play visualizations.",Günter Wallner;Marnix van Wijland;Regina Bernhaupt;Simone Kriglstein,
CHI,2021,Tele-Immersive Improv: Effects of Immersive Visualisations on Rehearsing and Performing Theatre Online,10.1145/3411764.3445310,"Performers acutely need but lack tools to remotely rehearse and create live theatre, particularly due to global restrictions on social interactions during the Covid-19 pandemic. No studies, however, have heretofore examined how remote video-collaboration affects performance. This paper presents the findings of a field study with 16 domain experts over six weeks investigating how tele-immersion affects the rehearsal and performance of improvisational theatre. To conduct the study, an original media server was developed for co-locating remote performers into shared virtual 3D environments which were accessed through popular video conferencing software. The results of this qualitative study indicate that tele-immersive environments uniquely provide performers with a strong sense of co- presence, feelings of physical connection, and an increased ability to enter the social-flow states required for improvisational theatre. Based on our observations, we put forward design recommendations for video collaboration tools tailored to the unique demands of live performance.",Boyd Branch;Christos Efstratiou;Piotr Mirowski;Kory W. Mathewson;Paul Allain,
CHI,2021,Grand Challenges in Immersive Analytics,10.1145/3411764.3446866,"Immersive Analytics is a quickly evolving field that unites several areas such as visualisation, immersive environments, and human-computer interaction to support human data analysis with emerging technologies. This research has thrived over the past years with multiple workshops, seminars, and a growing body of publications, spanning several conferences. Given the rapid advancement of interaction technologies and novel application domains, this paper aims toward a broader research agenda to enable widespread adoption. We present 17 key research challenges developed over multiple sessions by a diverse group of 24 international experts, initiated from a virtual scientific workshop at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic roadmap of current directions and impending hurdles to facilitate productive and effective applications for Immersive Analytics.",Barrett Ens;Benjamin Bach;Maxime Cordeil;Ulrich Engelke;Marcos Serrano;Wesley Willett;Arnaud Prouzeau;Christoph Anthes;Wolfgang Büschel;Cody Dunne;Tim Dwyer;Jens Grubert;Jason H. Haga;Nurit Kirshenbaum;Dylan Kobayashi;Tica Lin;Monsurat Olaosebikan;Fabian Pointecker;David Saffo;Nazmus Saquib;Dieter Schmalstieg;Danielle Albers Szafir;Matt Whitlock;Yalong Yang 0001,
CHI,2021,Quantitative Data Visualisation on Virtual Globes,10.1145/3411764.3445152,"Geographic data visualisation on virtual globes is intuitive and widespread, but has not been thoroughly investigated. We explore two main design factors for quantitative data visualisation on virtual globes: i) commonly used primitives (2D bar, 3D bar, circle) and ii) the orientation of these primitives (tangential, normal, billboarded). We evaluate five distinctive visualisation idioms in a user study with 50 participants. The results show that aligning primitives tangentially on the globe’s surface decreases the accuracy of area-proportional circle visualisations, while the orientation does not have a significant effect on the accuracy of length-proportional bar visualisations. We also find that tangential primitives induce higher perceived mental load than other orientations. Guided by these results we design a novel globe visualisation idiom, Geoburst, that combines a virtual globe and a radial bar chart. A preliminary evaluation reports potential benefits and drawbacks of the Geoburst visualisation.",Kadek Ananta Satriadi;Barrett Ens;Tobias Czauderna;Maxime Cordeil;Bernhard Jenny,
CHI,2021,Towards an Understanding of Situated AR Visualization for Basketball Free-Throw Training,10.1145/3411764.3445649,"We present an observational study to compare co-located and situated real-time visualizations in basketball free-throw training. Our goal is to understand the advantages and concerns of applying immersive visualization to real-world skill-based sports training and to provide insights for designing AR sports training systems. We design both a situated 3D visualization on a head-mounted display and a 2D visualization on a co-located display to provide immediate visual feedback on a player’s shot performance. Using a within-subject study design with experienced basketball shooters, we characterize user goals, report on qualitative training experiences, and compare the quantitative training results. Our results show that real-time visual feedback helps athletes refine subsequent shots. Shooters in our study achieve greater angle consistency with our visual feedback. Furthermore, AR visualization promotes an increased focus on body form in athletes. Finally, we present suggestions for the design of future sports AR studies.",Tica Lin;Rishi Singh;Yalong Yang 0001;Carolina Nobre;Johanna Beyer;Maurice A. Smith;Hanspeter Pfister,HM
CHI,2021,[email protected]: Fostering Visual Exploration of Personal Data on Smartphones Leveraging Speech and Touch Interaction,10.1145/3411764.3445421,"Most mobile health apps employ data visualization to help people view their health and activity data, but these apps provide limited support for visual data exploration. Furthermore, despite its huge potential benefits, mobile visualization research in the personal data context is sparse. This work aims to empower people to easily navigate and compare their personal health data on smartphones by enabling flexible time manipulation with speech. We designed and developed Data@Hand, a mobile app that leverages the synergy of two complementary modalities: speech and touch. Through an exploratory study with 13 long-term Fitbit users, we examined how multimodal interaction helps participants explore their own health data. Participants successfully adopted multimodal interaction (i.e., speech and touch) for convenient and fluid data exploration. Based on the quantitative and qualitative findings, we discuss design implications and opportunities with multimodal interaction for better supporting visual data exploration on mobile devices.",Young-Ho Kim;Bongshin Lee;Arjun Srinivasan;Eun Kyoung Choe,
CHI,2021,Haptic and Visual Comprehension of a 2D Graph Layout Through Physicalisation,10.1145/3411764.3445704,"Data physicalisations afford people the ability to directly interact with data using their hands, potentially achieving a more comprehensive understanding of a dataset. Due to their complex nature, the representation of graphs and networks could benefit from physicalisation, bringing the dataset from the digital world into the physical one. However, no empirical work exists investigating the effects physicalisations have upon comprehension as they relate to graph representations. In this work, we present initial design considerations for graph physicalisations, as well as an empirical study investigating differences in comprehension between virtual and physical representations. We found that participants perceived themselves as being more accurate via touch and sight (visual-haptic) than the graphical-only modality, and perceived a triangle count task as less difficult in visual-haptic than in the graphical-only modality. Additionally, we found that participants significantly preferred interacting with visual-haptic over other conditions, despite no significant effect on task time or error.",Adam Drogemuller;Andrew Cunningham;James A. Walsh;James Baumeister;Ross T. Smith;Bruce H. Thomas,
CHI,2021,Collecting and Characterizing Natural Language Utterances for Specifying Data Visualizations,10.1145/3411764.3445400,"Natural language interfaces (NLIs) for data visualization are becoming increasingly popular both in academic research and in commercial software. Yet, there is a lack of empirical understanding of how people specify visualizations through natural language. We conducted an online study (N = 102), showing participants a series of visualizations and asking them to provide utterances they would pose to generate the displayed charts. From the responses, we curated a dataset of 893 utterances and characterized the utterances according to (1) their phrasing (e.g., commands, queries, questions) and (2) the information they contained (e.g., chart types, data aggregations). To help guide future research and development, we contribute this utterance dataset and discuss its applications toward the creation and benchmarking of NLIs for visualization.",Arjun Srinivasan;Nikhila Nyapathy;Bongshin Lee;Steven Mark Drucker;John T. Stasko,
CHI,2021,It's a Wrap: Toroidal Wrapping of Network Visualisations Supports Cluster Understanding Tasks,10.1145/3411764.3445439,"We explore network visualisation on a two-dimensional torus topology that continuously wraps when the viewport is panned. That is, links may be “wrapped” across the boundary, allowing additional spreading of node positions to reduce visual clutter. Recent work has investigated such pannable wrapped visualisations, finding them not worse than unwrapped drawings for small networks for path-following tasks. However, they did not evaluate larger networks nor did they consider whether torus-based layout might also better display high-level network structure like clusters. We offer two algorithms for improving toroidal layout that is completely autonomous and automatic panning of the viewport to minimiswe wrapping links. The resulting layouts afford fewer crossings, less stress, and greater cluster separation. In a study of 32 participants comparing performance in cluster understanding tasks, we find that toroidal visualisation offers significant benefits over standard unwrapped visualisation in terms of improvement in error by 62.7% and time by 32.3%.",Kun-Ting Chen;Tim Dwyer;Benjamin Bach;Kim Marriott,
CHI,2021,MARVIS: Combining Mobile Devices and Augmented Reality for Visual Data Analysis,10.1145/3411764.3445593,"We present Marvis, a conceptual framework that combines mobile devices and head-mounted Augmented Reality (AR) for visual data analysis. We propose novel concepts and techniques addressing visualization-specific challenges. By showing additional 2D and 3D information around and above displays, we extend their limited screen space. AR views between displays as well as linking and brushing are also supported, making relationships between separated visualizations plausible. We introduce the design process and rationale for our techniques. To validate Marvis’ concepts and show their versatility and widespread applicability, we describe six implemented example use cases. Finally, we discuss insights from expert hands-on reviews. As a result, we contribute to a better understanding of how the combination of one or more mobile devices with AR can benefit visual data analysis. By exploring this new type of visualization environment, we hope to provide a foundation and inspiration for future mobile data visualizations.",Ricardo Langner;Marc Satkowski;Wolfgang Büschel;Raimund Dachselt,
CHI,2021,STREAM: Exploring the Combination of Spatially-Aware Tablets with Augmented Reality Head-Mounted Displays for Immersive Analytics,10.1145/3411764.3445298,"Recent research in the area of immersive analytics demonstrated the utility of head-mounted augmented reality devices for visual data analysis. However, it can be challenging to use the by default supported mid-air gestures to interact with visualizations in augmented reality (e.g. due to limited precision). Touch-based interaction (e.g. via mobile devices) can compensate for these drawbacks, but is limited to two-dimensional input. In this work we present STREAM: Spatially-aware Tablets combined with Augmented Reality Head-Mounted Displays for the multimodal interaction with 3D visualizations. We developed a novel eyes-free interaction concept for the seamless transition between the tablet and the augmented reality environment. A user study reveals that participants appreciated the novel interaction concept, indicating the potential for spatially-aware tablets in augmented reality. Based on our findings, we provide design insights to foster the application of spatially-aware touch devices in augmented reality and research implications indicating areas that need further investigation.",Sebastian Hubenschmid;Johannes Zagermann;Simon Butscher;Harald Reiterer,
CHI,2021,MIRIA: A Mixed Reality Toolkit for the In-Situ Visualization and Analysis of Spatio-Temporal Interaction Data,10.1145/3411764.3445651,"In this paper, we present MIRIA, a Mixed Reality Interaction Analysis toolkit designed to support the in-situ visual analysis of user interaction in mixed reality and multi-display environments. So far, there are few options to effectively explore and analyze interaction patterns in such novel computing systems. With MIRIA, we address this gap by supporting the analysis of user movement, spatial interaction, and event data by multiple, co-located users directly in the original environment. Based on our own experiences and an analysis of the typical data, tasks, and visualizations used in existing approaches, we identify requirements for our system. We report on the design and prototypical implementation of MIRIA, which is informed by these requirements and offers various visualizations such as 3D movement trajectories, position heatmaps, and scatterplots. To demonstrate the value of MIRIA for real-world analysis tasks, we conducted expert feedback sessions using several use cases with authentic study data.",Wolfgang Büschel;Anke Lehmann;Raimund Dachselt,
CHI,2021,Reconfiguration Strategies with Composite Data Physicalizations,10.1145/3411764.3445746,"Composite data physicalizations allow for the physical reconfiguration of data points, creating new opportunities for interaction and engagement. However, there is a lack of understanding of people’s strategies and behaviors when directly manipulating physical data objects. In this paper, we systematically characterize different reconfiguration strategies using six exemplar physicalizations. We asked 20 participants to reorganize these exemplars with two levels of restriction: changing a single data object versus changing multiple data objects. Our findings show that there were two main reconfiguration strategies used: changes in proximity and changes in atomic orientation. We further characterize these using concrete examples of participant actions in relation to the structure of the physicalizations. We contribute an overview of reconfiguration strategies, which informs the design of future manually reconfigurable and dynamic composite physicalizations.",Kim Sauvé;David Verweij;Jason Alexander;Steven Houben,
CHI,2021,Digital Transformations of Classrooms in Virtual Reality,10.1145/3411764.3445596,"With rapid developments in consumer-level head-mounted displays and computer graphics, immersive VR has the potential to take online and remote learning closer to real-world settings. However, the effects of such digital transformations on learners, particularly for VR, have not been evaluated in depth. This work investigates the interaction-related effects of sitting positions of learners, visualization styles of peer-learners and teachers, and hand-raising behaviors of virtual peer-learners on learners in an immersive VR classroom, using eye tracking data. Our results indicate that learners sitting in the back of the virtual classroom may have difficulties extracting information. Additionally, we find indications that learners engage with lectures more efficiently if virtual avatars are visualized with realistic styles. Lastly, we find different eye movement behaviors towards different performance levels of virtual peer-learners, which should be investigated further. Our findings present an important baseline for design decisions for VR classrooms.",Hong Gao 0008;Efe Bozkir;Lisa Hasenbein;Jens-Uwe Hahn;Richard Göllner;Enkelejda Kasneci,
CHI,2021,Little Road Driving HUD: Heads-Up Display Complexity Influences Drivers' Perceptions of Automated Vehicles,10.1145/3411764.3445575,"Modern vehicles are using AI and increasingly sophisticated sensor suites to improve Advanced Driving Assistance Systems (ADAS) and support automated driving capabilities. Heads-Up-Displays (HUDs) provide an opportunity to visually inform drivers about vehicle perception and interpretation of the driving environment. One approach to HUD design may be to reveal to drivers the vehicle’s full contextual understanding, though it is not clear if the benefits of additional information outweigh the drawbacks of added complexity, or if this balance holds across drivers. We designed and tested an Augmented Reality (AR) HUD in an online study (N = 298), focusing on the influence of HUD visualizations on drivers’ situation awareness and perceptions. Participants viewed two driving scenes with one of three HUD conditions. Results were nuanced: situation awareness declined with increasing driving context complexity, and contrary to expectation, also declined with the presence of a HUD compared to no HUD. Significant differences were found by varying HUD complexity, which led us to explore different characterizations of complexity, including counts of scene items, item categories, and illuminated pixels. Our analysis finds that driving style interacts with driving context and HUD complexity, warranting further study.",Rebecca Currano;So Yeon Park;Dylan James Moore;Kent Lyons;David Sirkin,
CHI,2021,"RCEA-360VR: Real-time, Continuous Emotion Annotation in 360° VR Videos for Collecting Precise Viewport-dependent Ground Truth Labels",10.1145/3411764.3445487,"Precise emotion ground truth labels for 360° virtual reality (VR) video watching are essential for fine-grained predictions under varying viewing behavior. However, current annotation techniques either rely on post-stimulus discrete self-reports, or real-time, continuous emotion annotations (RCEA) but only for desktop/mobile settings. We present RCEA for 360° VR videos (RCEA-360VR), where we evaluate in a controlled study (N=32) the usability of two peripheral visualization techniques: HaloLight and DotSize. We furthermore develop a method that considers head movements when fusing labels. Using physiological, behavioral, and subjective measures, we show that (1) both techniques do not increase users’ workload, sickness, nor break presence (2) our continuous valence and arousal annotations are consistent with discrete within-VR and original stimuli ratings (3) users exhibit high similarity in viewing behavior, where fused ratings perfectly align with intended labels. Our work contributes usable and effective techniques for collecting fine-grained viewport-dependent emotion labels in 360° VR.",Tong Xue;Abdallah El Ali;Tianyi Zhang;Gangyi Ding;Pablo César,
CHI,2021,From Detectables to Inspectables: Understanding Qualitative Analysis of Audiovisual Data,10.1145/3411764.3445458,"Audiovisual recordings of user studies and interviews provide important data in qualitative HCI research. Even when a textual transcription is available, researchers frequently turn to these recordings due to their rich information content. However, the temporal, unstructured nature of audiovisual recordings makes them less efficient to work with than text. Through interviews and a survey, we explored how HCI researchers work with audiovisual recordings. We investigated researchers’ transcription and annotation practice, their overall analysis workflow, and the prevalence of direct analysis of audiovisual recordings. We found that a key task was locating and analyzing inspectables, interesting segments in recordings. Since locating inspectables can be time consuming, participants look for detectables, visual or auditory cues that indicate the presence of an inspectable. Based on our findings, we discuss the potential for automation in locating detectables in qualitative audiovisual analysis.",Krishna Subramanian 0002;Johannes Maas;Jan O. Borchers;James D. Hollan,HM
CHI,2021,Investigating the Impact of Real-World Environments on the Perception of 2D Visualizations in Augmented Reality,10.1145/3411764.3445330,"In this work we report on two comprehensive user studies investigating the perception of Augmented Reality (AR) visualizations influenced by real-world backgrounds. Since AR is an emerging technology, it is important to also consider productive use cases, which is why we chose an exemplary and challenging industry 4.0 environment. Our basic perceptual research focuses on both the visual complexity of backgrounds as well as the influence of a secondary task. In contrast to our expectation, data of our 34 study participants indicate that the background has far less influence on the perception of AR visualizations. Moreover, we observed a mismatch between measured and subjectively reported performance. We discuss the importance of the background and recommendations for visual real-world augmentations. Overall, our results suggest that AR can be used in many visually challenging environments without losing the ability to productively work with the visualizations shown.",Marc Satkowski;Raimund Dachselt,
CHI,2021,"A Review on Strategies for Data Collection, Reflection, and Communication in Eating Disorder Apps",10.1145/3411764.3445670,"Eating disorders (EDs) constitute a mental illness with the highest mortality. Today, mobile health apps provide promising means to ED patients for managing their condition. Apps enable users to monitor their eating habits, thoughts, and feelings, and offer analytic insights for behavior change. However, not only have scholars critiqued the clinical validity of these apps, their underlying design principles are not well understood. Through a review of 34 ED apps, we uncovered 11 different data types ED apps collect, and 9 strategies they employ to support collection and reflection. Drawing upon personal health informatics and visualization frameworks, we found that most apps did not adhere to best practices on what and how data should be collected from and reflected to users, or how data-driven insights should be communicated. Our review offers suggestions for improving the design of ED apps such that they can be useful and meaningful in ED recovery.",Anjali Devakumar;Jay Modh;Bahador Saket;Eric P. S. Baumer;Munmun De Choudhury,
CHI,2021,CakeVR: A Social Virtual Reality (VR) Tool for Co-designing Cakes,10.1145/3411764.3445503,"Cake customization services allow clients to collaboratively personalize cakes with pastry chefs. However, remote (e.g., email) and in-person co-design sessions are prone to miscommunication, due to natural restrictions in visualizing cake size, decoration, and celebration context. This paper presents the design, implementation, and expert evaluation of a social VR application (CakeVR) that allows a client to remotely co-design cakes with a pastry chef, through real-time realistic 3D visualizations. Drawing on expert semi-structured interviews (4 clients, 5 pastry chefs), we distill and incorporate 8 design requirements into our CakeVR prototype. We evaluate CakeVR with 10 experts (6 clients, 4 pastry chefs) using cognitive walkthroughs, and find that it supports ideation and decision making through intuitive size manipulation, color/flavor selection, decoration design, and custom celebration theme fitting. Our findings provide recommendations for enabling co-design in social VR and highlight CakeVR’s potential to transform product design communication through remote interactive and immersive co-design.",Yanni Mei;Jie Li 0064;Huib de Ridder;Pablo César,
CHI,2021,FashionQ: An AI-Driven Creativity Support Tool for Facilitating Ideation in Fashion Design,10.1145/3411764.3445093,"Recent research on creativity support tools (CST) adopts artificial intelligence (AI) that leverages big data and computational capabilities to facilitate creative work. Our work aims to articulate the role of AI in supporting creativity with a case study of an AI-based CST tool in fashion design based on theoretical groundings. We developed AI models by externalizing three cognitive operations (extending, constraining, and blending) that are associated with divergent and convergent thinking. We present FashionQ, an AI-based CST that has three interactive visualization tools (StyleQ, TrendQ, and MergeQ). Through interviews and a user study with 20 fashion design professionals (10 participants for the interviews and 10 for the user study), we demonstrate the effectiveness of FashionQ on facilitating divergent and convergent thinking and identify opportunities and challenges of incorporating AI in the ideation process. Our findings highlight the role and use of AI in each cognitive operation based on professionals’ expertise and suggest future implications of AI-based CST development.",Youngseung Jeon;Seungwan Jin;Patrick C. Shih;Kyungsik Han,
CHI,2021,Design and Analysis of Intelligent Text Entry Systems with Function Structure Models and Envelope Analysis,10.1145/3411764.3445566,"Designing intelligent interactive text entry systems often relies on factors that are difficult to estimate or assess using traditional HCI design and evaluation methods. We introduce a complementary approach by adapting function structure models from engineering design. We extend their use by extracting controllable and uncontrollable parameters from function structure models and visualizing their impact using envelope analysis. Function structure models allow designers to understand a system in terms of its functions and flows between functions and decouple functions from function carriers. Envelope analysis allows the designer to further study how parameters affect variables of interest, for example, accuracy, keystroke savings and other dependent variables. We provide examples of function structure models and illustrate a complete envelope analysis by investigating a parameterized function structure model of predictive text entry. We discuss the implications of this design approach for both text entry system design and for critique of system contributions.",Per Ola Kristensson;Thomas Müllners,
CHI,2021,Fits and Starts: Enterprise Use of AutoML and the Role of Humans in the Loop,10.1145/3411764.3445775,"AutoML systems can speed up routine data science work and make machine learning available to those without expertise in statistics and computer science. These systems have gained traction in enterprise settings where pools of skilled data workers are limited. In this study, we conduct interviews with 29 individuals from organizations of different sizes to characterize how they currently use, or intend to use, AutoML systems in their data science work. Our investigation also captures how data visualization is used in conjunction with AutoML systems. Our findings identify three usage scenarios for AutoML that resulted in a framework summarizing the level of automation desired by data workers with different levels of expertise. We surfaced the tension between speed and human oversight and found that data visualization can do a poor job balancing the two. Our findings have implications for the design and implementation of human-in-the-loop visual analytics approaches.",Anamaria Crisan;Brittany Fiore-Gartland,HM
CHI,2021,Vis Ex Machina: An Analysis of Trust in Human versus Algorithmically Generated Visualization Recommendations,10.1145/3411764.3445195,"More visualization systems are simplifying the data analysis process by automatically suggesting relevant visualizations. However, little work has been done to understand if users trust these automated recommendations. In this paper, we present the results of a crowd-sourced study exploring preferences and perceived quality of recommendations that have been positioned as either human-curated or algorithmically generated. We observe that while participants initially prefer human recommenders, their actions suggest an indifference for recommendation source when evaluating visualization recommendations. The relevance of presented information (e.g., the presence of certain data fields) was the most critical factor, followed by a belief in the recommender’s ability to create accurate visualizations. Our findings suggest a general indifference towards the provenance of recommendations, and point to idiosyncratic definitions of visualization quality and trustworthiness that may not be captured by simple measures. We suggest that recommendation systems should be tailored to the information-foraging strategies of specific users.",Rachael Zehrung;Astha Singhal;Michael Correll;Leilani Battle,
CHI,2021,Understanding Narrative Linearity for Telling Expressive Time-Oriented Stories,10.1145/3411764.3445344,"Creating expressive narrative visualization often requires choosing a well-planned narrative order that invites the audience in. The narrative can either follow the linear order of story events (chronology), or deviate from linearity (anachronies). While evidence exists that anachronies in novels and films can enhance story expressiveness, little is known about how they can be incorporated into narrative visualization. To bridge this gap, this work introduces the idea of narrative linearity to visualization and investigates how different narrative orders affect the expressiveness of time-oriented stories. First, we conducted preliminary interviews with seven experts to clarify the motivations and challenges of manipulating narrative linearity in time-oriented stories. Then, we analyzed a corpus of 80 time-oriented stories and identified six most salient patterns of narrative orders. Next, we conducted a crowdsourcing study with 221 participants. Results indicated that anachronies have the potential to make time-oriented stories more expressive without hindering comprehensibility.",Xingyu Lan;Xinyue Xu;Nan Cao,
CHI,2021,Communicating with Motion: A Design Space for Animated Visual Narratives in Data Videos,10.1145/3411764.3445337,"Data videos are a genre of narrative visualization that communicates stories by combining data visualization and motion graphics. While data videos are increasingly gaining popularity, few systematic reviews or structured analyses exist for their design. In this work, we introduce a design space for animated visual narratives in data videos. The design space combines a dimension for animation techniques that are frequently used to facilitate data communication with one for visual narrative strategies served by such animation techniques to support story presentation. We derived our design space from the analysis of 82 high-quality data videos collected from online sources. We conducted a workshop with 20 participants to evaluate the effectiveness of our design space. Qualitative and quantitative feedback suggested that our design space is inspirational and useful for designing and creating data videos.",Yang Shi 0007;Xingyu Lan;Jingwen Li;Zhaorui Li;Nan Cao 0001,
CHI,2021,Understanding Data Accessibility for People with Intellectual and Developmental Disabilities,10.1145/3411764.3445743,"Using visualization requires people to read abstract visual imagery, estimate statistics, and retain information. However, people with Intellectual and Developmental Disabilities (IDD) often process information differently, which may complicate connecting abstract visual information to real-world quantities. This population has traditionally been excluded from visualization design, and often has limited access to data related to their well being. We explore how visualizations may better serve this population. We identify three visualization design elements that may improve data accessibility: chart type, chart embellishment, and data continuity. We evaluate these elements with populations both with and without IDD, measuring accuracy and efficiency in a web-based online experiment with time series and proportion data. Our study identifies performance patterns and subjective preferences for people with IDD when reading common visualizations. These findings suggest possible solutions that may break the cognitive barriers caused by conventional design guidelines.",Keke Wu;Emma Petersen;Tahmina Ahmad;David Burlinson;Shea Tanis;Danielle Albers Szafir,BP
CHI,2021,Viral Visualizations: How Coronavirus Skeptics Use Orthodox Data Practices to Promote Unorthodox Science Online,10.1145/3411764.3445211,"Controversial understandings of the coronavirus pandemic have turned data visualizations into a battleground. Defying public health officials, coronavirus skeptics on US social media spent much of 2020 creating data visualizations showing that the government’s pandemic response was excessive and that the crisis was over. This paper investigates how pandemic visualizations circulated on social media, and shows that people who mistrust the scientific establishment often deploy the same rhetorics of data-driven decision-making used by experts, but to advocate for radical policy changes. Using a quantitative analysis of how visualizations spread on Twitter and an ethnographic approach to analyzing conversations about COVID data on Facebook, we document an epistemological gap that leads pro- and anti-mask groups to draw drastically different inferences from similar data. Ultimately, we argue that the deployment of COVID data visualizations reflect a deeper sociopolitical rift regarding the place of science in public life.",Crystal Lee;Tanya Yang;Gabrielle D. Inchoco;Graham M. Jones;Arvind Satyanarayan,HM
CHI,2021,Mapping the Landscape of COVID-19 Crisis Visualizations,10.1145/3411764.3445381,"In response to COVID-19, a vast number of visualizations have been created to communicate information to the public. Information exposure in a public health crisis can impact people’s attitudes towards and responses to the crisis and risks, and ultimately the trajectory of a pandemic. As such, there is a need for work that documents, organizes, and investigates what COVID-19 visualizations have been presented to the public. We address this gap through an analysis of 668 COVID-19 visualizations. We present our findings through a conceptual framework derived from our analysis, that examines who, (uses) what data, (to communicate) what messages, in what form, under what circumstances in the context of COVID-19 crisis visualizations. We provide a set of factors to be considered within each component of the framework. We conclude with directions for future crisis visualization research.",Yixuan Zhang 0001;Yifan Sun 0002;Lace M. K. Padilla;Sumit Barua;Enrico Bertini;Andrea G. Parker,
CHI,2021,Does Interaction Improve Bayesian Reasoning with Visualization?,10.1145/3411764.3445176,"Interaction enables users to navigate large amounts of data effectively, supports cognitive processing, and increases data representation methods. However, there have been few attempts to empirically demonstrate whether adding interaction to a static visualization improves its function beyond popular beliefs. In this paper, we address this gap. We use a classic Bayesian reasoning task as a testbed for evaluating whether allowing users to interact with a static visualization can improve their reasoning. Through two crowdsourced studies, we show that adding interaction to a static Bayesian reasoning visualization does not improve participants’ accuracy on a Bayesian reasoning task. In some cases, it can significantly detract from it. Moreover, we demonstrate that underlying visualization design modulates performance and that people with high versus low spatial ability respond differently to different interaction techniques and underlying base visualizations. Our work suggests that interaction is not as unambiguously good as we often believe; a well designed static visualization can be as, if not more, effective than an interactive one.",Abigail Mosca;Alvitta Ottley;Remco Chang,
CHI,2021,Can Anthropographics Promote Prosociality?A Review and Large-Sample Study,10.1145/3411764.3445637,"Visualizations designed to make readers compassionate with the persons whose data is represented have been called anthropographics and are commonly employed by practitioners. Empirical studies have recently examined whether anthropographics indeed promote empathy, compassion, or the likelihood of prosocial behavior, but findings have been inconclusive so far. This work contributes a detailed overview of past experiments, and two new experiments that use large samples and a combination of design strategies to maximize the possibility of finding an effect. We tested an information-rich anthropographic against a simple bar chart, asking participants to allocate hypothetical money in a crowdsourcing study. We found that the anthropographic had, at best, a small effect on money allocation. Such a small effect may be relevant for large-scale donation campaigns, but the large sample sizes required to observe an effect and the noise involved in measuring it make it very difficult to study in more depth. Data and code are available at https://osf.io/xqae2/.",Luiz Augusto de Macêdo Morais;Yvonne Jansen;Nazareno Andrade;Pierre Dragicevic,
CHI,2021,The Public Life of Data: Investigating Reactions to Visualizations on Reddit,10.1145/3411764.3445720,"This research investigates how people engage with data visualizations when commenting on the social platform Reddit. There has been considerable research on collaborative sensemaking with visualizations and the personal relation of people with data. Yet, little is known about how public audiences without specific expertise and shared incentives openly express their thoughts, feelings, and insights in response to data visualizations. Motivated by the extensive social exchange around visualizations in online communities, this research examines characteristics and motivations of people’s reactions to posts featuring visualizations. Following a Grounded Theory approach, we study 475 reactions from the /r/dataisbeautiful community, identify ten distinguishable reaction types, and consider their contribution to the discourse. A follow-up survey with 168 Reddit users clarified their intentions to react. Our results help understand the role of personal perspectives on data and inform future interfaces that integrate audience reactions into visualizations to foster a public discourse about data.",Tobias Kauer;Marian Dörk;Arran L. Ridley;Benjamin Bach,
CHI,2021,Interpreting the Effect of Embellishment on Chart Visualizations,10.1145/3411764.3445739,"Infographics range from minimalism that aims to convey the raw data to elaborately decorated, or embellished, graphics that aim to engage readers by telling a story. Several studies have shown evidence to negative, but also positive, effects on embellishments. We conducted a set of experiments to gauge more precisely how embellishments affect how people relate to infographics and make sense of the conveyed story. By analyzing questionnaires, interviews, and eye-tracking data simplified by bundling, we show that, within bounds, embellishments have a positive effect on how users get engaged in understanding an infographic, with very limited downside. To our knowledge, our work is the first that fuses the aforementioned three information sources to understand infographics. Our findings can help to design more fine-grained studies to quantify the effects of embellishments and also to design infographics that effectively use the embellishments’ positive aspects identified. I think the contribution does not appear well in the abstract. It’s not just that the visual embellishments are positive. We show a methodology that allows us to see what these effects are (in addition to engagement, memorization and recall) at several levels (scales, interviews, eye tracking) which are therefore physiological and emotional. We could include this idea in the abstract?",Tiffany Andry;Christophe Hurter;François Lambotte;Pierre Fastrez;Alexandru C. Telea,
CHI,2021,LaserFactory: A Laser Cutter-based Electromechanical Assembly and Fabrication Platform to Make Functional Devices & Robots,10.1145/3411764.3445692,"LaserFactory is an integrated fabrication process that augments a commercially available fabrication machine to support the manufacture of fully functioning devices without human intervention. In addition to creating 2D and 3D mechanical structures, LaserFactory creates conductive circuit traces with arbitrary geometries, picks-and-places electronic and electromechanical components, and solders them in place. To enable this functionality, we make four contributions. First, we build a hardware add-on to the laser cutter head that can deposit silver circuit traces and assemble components. Second, we develop a new method to cure dispensed silver using a CO2 laser. Third, we build a motion-based signaling method that allows our system to be readily integrated with commercial laser cutters. Finally, we provide a design and visualization tool for making functional devices with LaserFactory. Having described the LaserFactory system, we demonstrate how it is used to fabricate devices such as a fully functioning quadcopter and a sensor-equipped wristband. Our evaluation shows that LaserFactory can assemble a variety of differently sized components (up to 65g), that these can be connected by narrow traces (down to 0.75mm) that become highly conductive after laser soldering (3.2Ω/m), and that our acceleration-based sensing scheme works reliably (to 99.5% accuracy).",Martin Nisser;Christina Chen Liao;Yuchen Chai;Aradhana Adhikari;Steve Hodges 0001;Stefanie Müller 0001,
CHI,2021,Designing CAST: A Computer-Assisted Shadowing Trainer for Self-Regulated Foreign Language Listening Practice,10.1145/3411764.3445190,"Shadowing, i.e., listening to recorded native speech and simultaneously vocalizing the words, is a popular language-learning technique that is known to improve listening skills. However, despite strong evidence for its efficacy as a listening exercise, existing shadowing systems do not adequately support listening-focused practice, especially in self-regulated learning environments with no external feedback. To bridge this gap, we introduce Computer-Assisted Shadowing Trainer (CAST), a shadowing system that makes self-regulation easy and effective through four novel design elements — (i) in-the-moment highlights for tracking and visualizing progress, (ii) contextual blurring for inducing self-reflection on misheard words, (iii) self-listening comparators for post-practice self-evaluation, and (iv) adjustable pause-handles for self-paced practice. We base CAST on a formative user study (N=15) that provides fresh empirical grounds on the needs and challenges of shadowers. We validate our design through a summative evaluation (N=12) that shows learners can successfully self-regulate their shadowing practice with CAST while retaining focus on listening.",Mohi Reza;Dongwook Yoon,
CHI,2021,A Visual Analytics Approach to Facilitate the Proctoring of Online Exams,10.1145/3411764.3445294,"Online exams have become widely used to evaluate students’ performance in mastering knowledge in recent years, especially during the pandemic of COVID-19. However, it is challenging to conduct proctoring for online exams due to the lack of face-to-face interaction. Also, prior research has shown that online exams are more vulnerable to various cheating behaviors, which can damage their credibility. This paper presents a novel visual analytics approach to facilitate the proctoring of online exams by analyzing the exam video records and mouse movement data of each student. Specifically, we detect and visualize suspected head and mouse movements of students in three levels of detail, which provides course instructors and teachers with convenient, efficient and reliable proctoring for online exams. Our extensive evaluations, including usage scenarios, a carefully-designed user study and expert interviews, demonstrate the effectiveness and usability of our approach.",Haotian Li 0001;Min Xu;Yong Wang 0021;Huan Wei;Huamin Qu,
CHI,2020,FDHelper: Assist Unsupervised Fraud Detection Experts with Interactive Feature Selection and Evaluation,10.1145/3313831.3376140,"Online fraud is the well-known dark side of the modern Internet. Unsupervised fraud detection algorithms are widely used to address this problem. However, selecting features, adjusting hyperparameters, evaluating the algorithms, and eliminating false positives all require human expert involvement. In this work, we design and implement an end-to-end interactive visualization system, FDHelper, based on the deep understanding of the mechanism of the black market and fraud detection algorithms. We identify a workflow based on experience from both fraud detection algorithm experts and domain experts. Using a multi-granularity three-layer visualization map embedding an entropy-based distance metric ColDis, analysts can interactively select different feature sets, refine fraud detection algorithms, tune parameters and evaluate the detection result in near real-time. We demonstrate the effectiveness and significance of FDHelper through two case studies with state-of-the-art fraud detection algorithms, interviews with domain experts and algorithm experts, and a user study with eight first-time end users.",Jiao Sun;Yin Li;Charley Chen;Jihae Lee;Xin Liu;Zhongping Zhang;Ling Huang;Lei Shi 0002;Wei Xu 0005,
CHI,2020,From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics,10.1145/3313831.3376148,"Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is naïve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.",Roberto Martínez Maldonado;Vanessa Echeverría;Gloria Fernández-Nieto;Simon Buckingham Shum,
CHI,2020,DataQuilt: Extracting Visual Elements from Images to Craft Pictorial Visualizations,10.1145/3313831.3376172,"Recent years have seen an increasing interest in the authoring and crafting of personal visualizations. Mainstream data analysis and authoring tools lack the flexibility for customization and personalization, whereas tools from the research community either require creativity and drawing skills, or are limited to simple vector graphics. We present DataQuilt, a novel system that enables visualization authors to iteratively design pictorial visualizations as collages. Real images (e.g., paintings, photographs, sketches) act as both inspiration and as a resource of visual elements that can be mapped to data. The creative pipeline involves the semi-guided extraction of relevant elements of an image (arbitrary regions, regular shapes, color palettes, textures) aided by computer vision techniques; the binding of these graphical elements and their features to data in order to create meaningful visualizations; and the iterative refinement of both features and visualizations through direct manipulation. We demonstrate the usability of DataQuilt in a controlled study and its expressiveness through a collection of authored visualizations from a second open-ended study.",Jiayi Eris Zhang;Nicole Sultanum;Anastasia Bezerianos;Fanny Chevalier,
CHI,2020,Understanding and Visualizing Data Iteration in Machine Learning,10.1145/3313831.3376177,"Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply \system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.",Fred Hohman;Kanit Wongsuphasawat;Mary Beth Kery;Kayur Patel,
CHI,2020,DoughNets: Visualising Networks Using Torus Wrapping,10.1145/3313831.3376180,"We investigate visualisations of networks on a 2-dimensional torus topology, like an opened-up and flattened doughnut. That is, the network is drawn on a rectangular area while ""wrapping"" specific links around the border. Previous work on torus drawings of networks has been mostly theoretical, limited to certain classes of networks, and not evaluated by human readability studies. We offer a simple interactive layout approach applicable to general graphs. We use this to find layouts affording better aesthetics in terms of conventional measures like more equal edge length and fewer crossings. In two controlled user studies we find that torus layout with either additional context or interactive panning provided significant performance improvement (in terms of error and time) over torus layout without either of these improvements, to the point that it is comparable to standard non-torus layout.",Kun-Ting Chen;Tim Dwyer;Kim Marriott;Benjamin Bach,
CHI,2020,Addressing Cognitive and Emotional Barriers in Parent-Clinician Communication through Behavioral Visualization Webtools,10.1145/3313831.3376181,"Effective communication between clinicians and parents of young children with developmental delays can decrease parents' anxiety, help them handle bad news, and improve their adherence to proposed interventions. However, parents have reported dissatisfaction regarding their current communication with clinicians, and they face cognitive and emotional challenges when discussing their child's developmental delays. In this paper, we present visualization as a facilitator of parent-clinician communication and how it could address existing communication challenges. Parents and clinicians anticipated visualization webtools would aid their communication by helping parents gain a better understanding of their child, acting as objective evidence, and highlighting the strength of the child as well as important medical concepts. In addition, visualization can act as a longitudinal record, helping parents track, explore, and share their child's developmental progress. Finally, we propose visualization as a tool to guide parents in their transition from feeling emotional and disempowered to advocating with confidence.",Ha Kyung Kong;Karrie Karahalios,
CHI,2020,Move Your Body: Engaging Museum Visitors with Human-Data Interaction,10.1145/3313831.3376186,"Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user (""mode type"") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system.",Milka Trajkova;A'aeshah Alhakamy;Francesco Cafaro;Rashmi Mallappa;Sreekanth R. Kankara,
CHI,2020,Watch+Strap: Extending Smartwatches with Interactive StrapDisplays,10.1145/3313831.3376199,"While smartwatches are widely adopted these days, their input and output space remains fairly limited by their screen size. We present StrapDisplays-interactive watchbands with embedded display and touch technologies-that enhance commodity watches and extend their input and output capabilities. After introducing the physical design space of these StrapDisplays, we explore how to combine a smartwatch and straps in a synergistic Watch+Strap system. Specifically, we propose multiple interface concepts that consider promising content distributions, interaction techniques, usage types, and display roles. For example, the straps can enrich watch apps, display visualizations, provide glanceable feedback, or help avoiding occlusion issues. Further, we provide a modular research platform incorporating three StrapDisplay prototypes and a flexible web-based software architecture, demonstrating the feasibility of our approach. Early brainstorming sessions with 15 participants informed our design process, while later interviews with six experts supported our concepts and provided valuable feedback for future developments.",Konstantin Klamka;Tom Horak;Raimund Dachselt,
CHI,2020,Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning,10.1145/3313831.3376219,"Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.",Harmanpreet Kaur;Harsha Nori;Samuel Jenkins;Rich Caruana;Hanna M. Wallach;Jennifer Wortman Vaughan,HM
CHI,2020,Truncating the Y-Axis: Threat or Menace?,10.1145/3313831.3376222,"Bar charts with y-axes that don't begin at zero can visually exaggerate effect sizes. However, advice for whether or not to truncate the y-axis can be equivocal for other visualization types. In this paper we present examples of visualizations where this y-axis truncation can be beneficial as well as harmful, depending on the communicative and analytic intent. We also present the results of a series of crowd-sourced experiments in which we examine how y-axis truncation impacts subjective effect size across visualization types, and we explore alternative designs that more directly alert viewers to this truncation. We find that the subjective impact of axis truncation is persistent across visualizations designs, even for designs with explicit visual cues that indicate truncation has taken place. We suggest that designers consider the scale of the meaningful effect sizes and variation they intend to communicate, regardless of the visual encoding.",Michael Correll;Enrico Bertini;Steven Franconeri,HM
CHI,2020,Evaluating the Effect of Timeline Shape on Visualization Task Performance,10.1145/3313831.3376237,"Timelines are commonly represented on a horizontal line, which is not necessarily the most effective way to visualize temporal event sequences. However, few experiments have evaluated how timeline shape influences task performance. We present the design and results of a controlled experiment run on Amazon Mechanical Turk (n=192) in which we evaluate how timeline shape affects task completion time, correctness, and user preference. We tested 12 combinations of 4 shapes --- horizontal line, vertical line, circle, and spiral  and 3 data types  recurrent, non-recurrent, and mixed event sequences. We found good evidence that timeline shape meaningfully affects user task completion time but not correctness and that users have a strong shape preference. Building on our results, we present design guidelines for creating effective timeline visualizations based on user task and data types. A free copy of this paper, the evaluation stimuli and data, and code are available https://osf.io/qr5yu/",Sara Di Bartolomeo;Aditeya Pandey;Aristotelis Leventidis;David Saffo;Uzma Haque Syeda;Elín Carstensdóttir;Magy Seif El-Nasr;Michelle A. Borkin;Cody Dunne,
CHI,2020,Cheat Sheets for Data Visualization Techniques,10.1145/3313831.3376271,"This paper introduces the concept of 'cheat sheets' for data visualization techniques, a set of concise graphical explanations and textual annotations inspired by infographics, data comics, and cheat sheets in other domains. Cheat sheets aim to address the increasing need for accessible material that supports a wide audience in understanding data visualization techniques, their use, their fallacies and so forth. We have carried out an iterative design process with practitioners, teachers and students of data science and visualization, resulting six types of cheat sheet (anatomy, construction, visual patterns, pitfalls, false-friends and well-known relatives) for six types of visualization, and formats for presentation. We assess these with a qualitative user study using 11 participants that demonstrates the readability and usefulness of our cheat sheets.",Zezhong Wang 0001;Lovisa Sundin;Dave Murray-Rust;Benjamin Bach,
CHI,2020,MaraVis: Representation and Coordinated Intervention of Medical Encounters in Urban Marathon,10.1145/3313831.3376281,"There is an increased use of Internet-of-Things and wearable sensing devices in the urban marathon to ensure effective response to unforeseen medical needs. However, the massive amount of real-time, heterogeneous movement and psychological data of runners impose great challenges on prompt medical incident analysis and intervention. Conventional approaches compile such data into one dashboard visualization to facilitate rapid data absorption but fail to support joint decision-making and operations in medical encounters. In this paper, we present MaraVis, a real-time urban marathon visualization and coordinated intervention system. It first visually summarizes real-time marathon data to facilitate the detection and exploration of possible anomalous events. Then, it calculates an optimal camera route with an arrangement of shots to guide offline effort to catch these events in time with a smooth view transition. We conduct a within-subjects study with two baseline systems to assess the efficacy of MaraVis.",Quan Li;Huanbin Lin;Xiguang Wei;Yangkun Huang;Lixin Fan;Jian Du;Xiaojuan Ma;Tianjian Chen,
CHI,2020,GoTree: A Grammar of Tree Visualizations,10.1145/3313831.3376297,"We present GoTree, a declarative grammar allowing users to instantiate tree visualizations by specifying three aspects: visual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both ""unit-decomposable"" and ""axis-decomposable"" (terms we define). For tree visualizations within this subset, GoTree gives the user flexible and fine-grained control over the parameters of the techniques, supporting both explicit and implicit tree visualizations. We developed Tree Illustrator, an interactive authoring tool based on GoTree grammar. Tree Illustrator allows users to create a considerable number of tree visualizations, including not only existing techniques but also undiscovered and hybrid visualizations. We demonstrate the expressiveness and generative power of GoTree with a gallery of examples and conduct a qualitative study to validate the usability of Tree Illustrator.",Guozheng Li 0002;Min Tian;Qinmei Xu 0001;Michael J. McGuffin;Xiaoru Yuan,
CHI,2020,A Participatory Simulation of the Accountable Capitalism Act,10.1145/3313831.3376326,"Interactive computing systems increasingly allow for experimental evaluations of fundamental issues in law, government, and society. In this paper, we describe a participatory simulation of the Accountable Capitalism Act, a bill proposed in 2018 by US Senator Elizabeth Warren. We present findings from an empirical study conducted using this system, relating to the impact of 1) interactive visualization and 2) the Accountable Capitalism Act legal framework on the behavior of participants acting as corporate directors. From this study, we draw lessons about research possibilities at the juncture of HCI and legal and policy studies. This study contributes an analysis and evaluation of a design probe used to investigate potential impacts of the Accountable Capitalism Act, experimental evidence from a study conducted using the design probe, and guidance for future participatory simulations that seek to inform the design of social institutions.",Bill Tomlinson;M. Six Silberman;Andrew W. Torrance;Kurt Squire;Paramdeep S. Atwal;Ameya N. Mandalik;Sahil Railkar;Rebecca W. Black,
CHI,2020,MRAT: The Mixed Reality Analytics Toolkit,10.1145/3313831.3376330,"Significant tool support exists for the development of mixed reality (MR) applications; however, there is a lack of tools for analyzing MR experiences. We elicit requirements for future tools through interviews with 8 university research, instructional, and media teams using AR/VR in a variety of domains. While we find a common need for capturing how users perform tasks in MR, the primary differences were in terms of heuristics and metrics relevant to each project. Particularly in the early project stages, teams were uncertain about what data should, and even could, be collected with MR technologies. We designed the Mixed Reality Analytics Toolkit (MRAT) to instrument MR apps via visual editors without programming and enable rapid data collection and filtering for visualizations of MR user sessions. With MRAT, we contribute flexible interaction tracking and task definition concepts, an extensible set of heuristic techniques and metrics to measure task success, and visual inspection tools with in-situ visualizations in MR. Focusing on a multi-user, cross-device MR crisis simulation and triage training app as a case study, we then show the benefits of using MRAT, not only for user testing of MR apps, but also performance tuning throughout the design process.",Michael Nebeling;Maximilian Speicher;Xizi Wang;Shwetha Rajaram;Brian D. Hall;Zijian Xie;Alexander R. E. Raistrick;Michelle Aebersold;Edward G. Happ;Jiayin Wang;Yanan Sun;Lotus Zhang;Leah E. Ramsier;Rhea Kulkarni,BP
CHI,2020,Dear Pictograph: Investigating the Role of Personalization and Immersion for Consuming and Enjoying Visualizations,10.1145/3313831.3376348,"Much of the visualization literature focuses on assessment of visual representations with regard to their effectiveness for understanding data. In the present work, we instead focus on making data visualization experiences more enjoyable, to foster deeper engagement with data. We investigate two strategies to make visualization experiences more enjoyable and engaging: personalization, and immersion. We selected pictographs (composed of multiple data glyphs) as this representation affords creative freedom, allowing people to craft symbolic or whimsical shapes of personal significance to represent data. We present the results of a qualitative study with 12 participants crafting pictographs using a large pen-enabled device and while immersed within a VR environment. Our results indicate that personalization and immersion both have positive impact on making visualizations more enjoyable experiences.",Hugo Romat;Nathalie Henry Riche;Christophe Hurter;Steven Mark Drucker;Fereshteh Amini;Ken Hinckley,
CHI,2020,A Comparison of Geographical Propagation Visualizations,10.1145/3313831.3376350,"Geographical propagation phenomena occur in multiple domains, such as in epidemiology and social media. Propagation dynamics are often complex, and visualizations play a key role in helping subject-matter experts understand and analyze them. However, there is little empirical data about the effectiveness of the various strategies used to visualize geographical propagation. To fill this gap, we conduct an experiment to evaluate the effectiveness of three strategies: an animated map, small-multiple maps, and a single map with glyphs. We compare them under five tasks that vary in one of the following dimensions: propagation scope, direction, speed, peaks, and spatial jumps. Our results show that small-multiple maps perform best overall, but that the effectiveness of each visualization varies depending on the task considered.",Vanessa Peña Araya;Anastasia Bezerianos;Emmanuel Pietriga,
CHI,2020,Du Bois Wrapped Bar Chart: Visualizing Categorical Data with Disproportionate Values,10.1145/3313831.3376365,"We propose a visualization technique, Du Bois wrapped bar chart, inspired by work of W.E.B Du Bois. Du Bois wrapped bar charts enable better large-to-small bar comparison by wrapping large bars over a certain threshold. We first present two crowdsourcing experiments comparing wrapped and standard bar charts to evaluate (1) the benefit of wrapped bars in helping participants identify and compare values; (2) the characteristics of data most suitable for wrapped bars. In the first study (n=98) using real-world datasets, we find that wrapped bar charts lead to higher accuracy in identifying and estimating ratios between bars. In a follow-up study (n=190) with 13 simulated datasets, we find participants were consistently more accurate with wrapped bar charts when certain category values are disproportionate as measured by entropy and H-spread. Finally, in an in-lab study, we investigate participants' experience and strategies, leading to guidelines for when and how to use wrapped bar charts.",Alireza Karduni;Ryan Wesslen;Isaac Cho;Wenwen Dou,
CHI,2020,"Tactile Presentation of Network Data: Text, Matrix or Diagram?",10.1145/3313831.3376367,"Visualisations are commonly used to understand social, biological and other kinds of networks. Currently we do not know how to effectively present network data to people who are blind or have low-vision (BLV). We ran a controlled study with 8 BLV participants comparing four tactile representations: organic node-link diagram, grid node-link diagram, adjacency matrix and braille list. We found that the node-link representations were preferred and more effective for path following and cluster identification while the matrix and list were better for adjacency tasks. This is broadly in line with findings for the corresponding visual representations.",Yalong Yang 0001;Kim Marriott;Matthew Butler 0002;Cagatay Goncu;Leona Holloway,
CHI,2020,Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for Bayesian Analysis,10.1145/3313831.3376377,"Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced withBayesian statistics and asked them for rationales for those priors. We found that participants' experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual mass allocation. We discovered that participants' understanding of the notion of 'weakly informative priors""-a commonly-recommended normative approach to prior setting-manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.",Abhraneel Sarma;Matthew Kay 0001,
CHI,2020,Decipher: An Interactive Visualization Tool for Interpreting Unstructured Design Feedback from Multiple Providers,10.1145/3313831.3376380,"Feedback from diverse audiences can vary in focus, differ in structure, and contradict each other, making it hard to interpret and act on. While prior work has explored generating quality feedback, our work helps a designer interpret that feedback. Through a formative study with professional designers (N=10), we discovered that the interpretation process includes categorizing feedback, identifying valuable feedback, and prioritizing which feedback to incorporate in a revision. We also found that designers leverage feedback topic and sentiment, and the status of the provider to aid interpretation. Based on the findings, we created a new tool (Decipher) that enables designers to visualize and navigate a collection of feedback using its topic and sentiment structure. In a preliminary evaluation (N=20), we found that Decipher helped users feel less overwhelmed during feedback interpretation tasks and better attend to critical issues and conflicting opinions compared to using a typical document-editing tool.",Yu-Chun (Grace) Yen;Joy O. Kim;Brian P. Bailey,
CHI,2020,Evaluating Multivariate Network Visualization Techniques Using a Validated Design and Crowdsourcing Approach,10.1145/3313831.3376381,"Visualizing multivariate networks is challenging because of the trade-offs necessary for effectively encoding network topology and encoding the attributes associated with nodes and edges. A large number of multivariate network visualization techniques exist, yet there is little empirical guidance on their respective strengths and weaknesses. In this paper, we describe a crowdsourced experiment, comparing node-link diagrams with on-node encoding and adjacency matrices with juxtaposed tables. We find that node-link diagrams are best suited for tasks that require close integration between the network topology and a few attributes. Adjacency matrices perform well for tasks related to clusters and when many attributes need to be considered. We also reflect on our method of using validated designs for empirically evaluating complex, interactive visualizations in a crowdsourced setting. We highlight the importance of training, compensation, and provenance tracking.",Carolina Nobre;Dylan Wootton;Lane Harrison;Alexander Lex,
CHI,2020,"See, Feel, Move: Player Behaviour Analysis through Combined Visualization of Gaze, Emotions, and Movement",10.1145/3313831.3376401,"Playtesting of games often relies on a mixed-methods approach to obtain more holistic insights about and, in turn, improve the player experience. However, triangulating the different data sources and visualizing them in an integrated manner such that they contextualize each other still proves challenging. Despite its potential value for gauging player behaviour, this area of research continues to be underexplored. In this paper, we propose a visualization approach that combines commonly tracked movement data with - from a visualization perspective rarely considered - gaze behaviour and emotional responses. We evaluated our approach through a qualitative expert study with five professional game developers. Our results show that both the individual visualization of gaze, emotions, and movement but especially their combination are valuable to understand and form hypotheses about player behaviour. At the same time, our results stress that careful attention needs to be paid to ensure that the visualization remains legible and does not obfuscate information.",Daniel Kepplinger;Günter Wallner;Simone Kriglstein;Michael Lankes,HM
CHI,2020,Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning,10.1145/3313831.3376418,"Like anyone, teachers need feedback to improve. Due to the high cost of human classroom observation, teachers receive infrequent feedback which is often more focused on evaluating performance than on improving practice. To address this critical barrier to teacher learning, we aim to provide teachers with detailed and actionable automated feedback. Towards this end, we developed an approach that enables teachers to easily record high-quality audio from their classes. Using this approach, teachers recorded 142 classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition and machine learning to develop teacher-generalizable computer-scored estimates of key dimensions of teacher discourse. We found that automated models were moderately accurate when compared to human coders and that speech recognition errors did not influence performance. We conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback. Our next step is to incorporate the automatic models into an interactive visualization tool that will provide teachers with objective feedback on the quality of their discourse.",Emily Jensen;Meghan Dale;Patrick J. Donnelly;Cathlyn Stone;Sean Kelly;Amanda Godley;Sidney K. D'Mello,
CHI,2020,Surfacing Visualization Mirages,10.1145/3313831.3376420,"Dirty data and deceptive design practices can undermine, invert, or invalidate the purported messages of charts and graphs. These failures can arise silently: a conclusion derived from a particular visualization may look plausible unless the analyst looks closer and discovers an issue with the backing data, visual specification, or their own assumptions. We term such silent but significant failures . We describe a conceptual model of mirages and show how they can be generated at every stage of the visual analytics process. We adapt a methodology from software testing, , as a way of automatically surfacing potential mirages at the visual encoding stage of analysis through modifications to the underlying data and chart specification. We show that metamorphic testing can reliably identify mirages across a variety of chart types with relatively little prior knowledge of the data or the domain.",Andrew M. McNutt;Gordon L. Kindlmann;Michael Correll,HM
CHI,2020,Augmenting Static Visualizations with PapARVis Designer,10.1145/3313831.3376436,"This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our environment and confirms that participants can create augmented visualizations in an average of 4.63 minutes.",Zhutian Chen;Wai Tong;Qianwen Wang;Benjamin Bach;Huamin Qu,
CHI,2020,Automatic Annotation Synchronizing with Textual Description for Visualization,10.1145/3313831.3376443,"In this paper, we propose a technique for automatically annotating visualizations according to the textual description. In our approach, visual elements in the target visualization, along with their visual properties, are identified and extracted with a Mask R-CNN model. Meanwhile, the description is parsed to generate visual search requests. Based on the identification results and search requests, each descriptive sentence is displayed beside the described focal areas as annotations. Different sentences are presented in various scenes of the generated animation to promote a vivid step-by-step presentation. With a user-customized style, the animation can guide the audience's attention via proper highlighting such as emphasizing specific features or isolating part of the data. We demonstrate the utility and usability of our method through a user study with use cases.",Chufan Lai;Zhixian Lin;Ruike Jiang;Yun Han;Can Liu 0004;Xiaoru Yuan,
CHI,2020,How Visualizing Inferential Uncertainty Can Mislead Readers About Treatment Effects in Scientific Results,10.1145/3313831.3376454,"When presenting visualizations of experimental results, scientists often choose to display either inferential uncertainty (e.g., uncertainty in the estimate of a population mean) or outcome uncertainty (e.g., variation of outcomes around that mean) about their estimates. How does this choice impact readers' beliefs about the size of treatment effects? We investigate this question in two experiments comparing 95% confidence intervals (means and standard errors) to 95% prediction intervals (means and standard deviations). The first experiment finds that participants are willing to pay more for and overestimate the effect of a treatment when shown confidence intervals relative to prediction intervals. The second experiment evaluates how alternative visualizations compare to standard visualizations for different effect sizes. We find that axis rescaling reduces error, but not as well as prediction intervals or animated hypothetical outcome plots (HOPs), and that depicting inferential uncertainty causes participants to underestimate variability in individual outcomes.",Jake M. Hofman;Daniel G. Goldstein;Jessica Hullman,HM
CHI,2020,A Probabilistic Grammar of Graphics,10.1145/3313831.3376466,"Visualizations depicting probabilities and uncertainty are used everywhere from medical risk communication to machine learning, yet these probabilistic visualizations are difficult to specify, prone to error, and their designs are cumbersome to explore. We propose a Probabilistic Grammar of Graphics (PGoG), an extension to Wilkinson's original framework. Inspired by the success of probabilistic programming languages, PGoG makes probability expressions, such as P(A|B), a first-class citizen in the language. PGoG abstractions also reflect the distinction between probability and frequency framing, a concept from the uncertainty communication literature. It is expressive, encompassing product plots, density plots, icon arrays, and dotplots, among other visualizations. Its coherent syntax ensures correctness (that the proportions of visual elements and their spatial placement reflect the underlying probability distribution) and reduces edit distance between probabilistic visualization specifications, potentially supporting more design exploration. We provide a proof-of-concept implementation of PGoG in R.",Xiaoying Pu;Matthew Kay 0001,HM
CHI,2020,"Debugging Database Queries: A Survey of Tools, Techniques, and Users",10.1145/3313831.3376485,"Database management systems (or DBMSs) have been around for decades, and yet are still difficult to use, particularly when trying to identify and fix errors in user programs (or queries). We seek to understand what methods have been proposed to help people debug database queries, and whether these techniques have ultimately been adopted by DBMSs (and users). We conducted an interdisciplinary review of 112 papers and tools from the database, visualisation and HCI communities. To better understand whether academic and industry approaches are meeting the needs of users, we interviewed 20 database users (and some designers), and found surprising results. In particular, there seems to be a wide gulf between users' debugging strategies and the functionality implemented in existing DBMSs, as well as proposed in the literature. In response, we propose new design guidelines to help system designers to build features that more closely match users debugging strategies.",Sneha Gathani;Peter Lim;Leilani Battle,
CHI,2020,Projection Boxes: On-the-fly Reconfigurable Visualization for Live Programming,10.1145/3313831.3376494,"Live programming is a regime in which the programming environment provides continual feedback, most often in the form of runtime values. In this paper, we present Projection Boxes, a novel visualization technique for displaying runtime values of programs. The key idea behind projection boxes is to start with a full semantics of the program, and then use projections to pick a subset of the semantics to display. By varying the projection used, projection boxes can encode both previously known visualization techniques, and also new ones. As such, projection boxes provide an expressive and configurable framework for displaying runtime information. Through a user study we demonstrate that (1) users find projection boxes and their configurability useful (2) users are not distracted by the always-on visualization (3) a key driving force behind the need for a configurable visualization for live programming lies with the wide variation in programmer preferences.",Sorin Lerner,
CHI,2020,"Awareness, Understanding, and Action: A Conceptual Framework of User Experiences and Expectations about Indoor Air Quality Visualizations",10.1145/3313831.3376521,"With the advent of new sensors and technologies, smart devices that monitor the level of indoor air quality (IAQ) are increasingly available to create a healthy home environment. However, little has been studied regarding design principles for effective IAQ visualizations to help better understand and improve IAQ. We analyzed Amazon reviews of IAQ monitors and their design components for IAQ visualizations. Based on our findings, we created a conceptual framework to explain the process of facilitating an effective IAQ visualization with a proposed set of design considerations in each stage. The process includes helping users easily understand what is happing to IAQ (awareness), what it means to them (understanding), and what to do with the information (action), which results in two outcomes, knowledge gain and emotional relief. We hope our framework can help practitioners and researchers in designing eco-feedback system and beyond to advance both research and practice.",Sunyoung Kim;Muyang Li,
CHI,2020,Progression Maps: Conceptualizing Narrative Structure for Interaction Design Support,10.1145/3313831.3376527,"Interactive narratives are frequently designed for learning and training applications, such as social training. In these contexts, designers may be inexperienced in storytelling and interaction design, and it may be difficult to quickly build an effective experience, even for experienced designers. Designers often approach this problem through iterative design. To augment and reduce iteration, we argue for the utility of employing models to reason about, evaluate, and improve designs. While there has been much previous work on interactive narrative models, none of them capture aspects of the interaction design necessary for testing and evaluation. In this paper we propose a new computational model called Progression Maps, which abstracts interaction design elements of the narrative's structure and visualizes its interaction properties. We report on the model, its implementation, and two studies evaluating its use. Our results demonstrate Progression Maps' effectiveness in communicating the underlying design through an easily understandable visualization.",Elín Carstensdóttir;Nathan Partlan;Steven C. Sutherland;Tyler Duke;Erika Ferris;Robin M. Richter;Maria Jose Valladares;Magy Seif El-Nasr,
CHI,2020,"Paths Explored, Paths Omitted, Paths Obscured: Decision Points & Selective Reporting in End-to-End Data Analysis",10.1145/3313831.3376533,"Drawing reliable inferences from data involves many, sometimes arbitrary, decisions across phases of data collection, wrangling, and modeling. As different choices can lead to diverging conclusions, understanding how researchers make analytic decisions is important for supporting robust and replicable analysis. In this study, we pore over nine published research studies and conduct semi-structured interviews with their authors. We observe that researchers often base their decisions on methodological or theoretical concerns, but subject to constraints arising from the data, expertise, or perceived interpretability. We confirm that researchers may experiment with choices in search of desirable results, but also identify other reasons why researchers explore alternatives yet omit findings. In concert with our interviews, we also contribute visualizations for communicating decision processes throughout an analysis. Based on our results, we identify design opportunities for strengthening end-to-end analysis, for instance via tracking and meta-analysis of multiple decision paths.",Yang Liu 0136;Tim Althoff;Jeffrey Heer,
CHI,2020,Evaluation of a Financial Portfolio Visualization using Computer Displays and Mixed Reality Devices with Domain Experts,10.1145/3313831.3376556,"With the advent of mixed reality devices such as the Microsoft HoloLens, developers have been faced with the challenge to utilize the third dimension in information visualization effectively. Research on stereoscopic devices has shown that three-dimensional representation can improve accuracy in specific tasks (e.g., network visualization). Yet, so far the field has remained mute on the underlying mechanism. Our study systematically investigates the differences in user perception between a regular monitor and a mixed reality device. In a real-life within-subject experiment in the field with twenty-eight investment bankers, we assessed subjective and objective task performance with two- and three-dimensional systems, respectively. We tested accuracy with regard to position, size, and color using single and combined tasks. Our results do not show a significant difference in accuracy between mixed-reality and standard 2D monitor visualizations.",Kay Schröder;Batoul Ajdadilish;Alexander P. Henkel;André Calero Valdez,
CHI,2020,"Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces",10.1145/3313831.3376613,"We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.",Maxime Cordeil;Benjamin Bach;Andrew Cunningham;Bastian Montoya;Ross T. Smith;Bruce H. Thomas;Tim Dwyer,
CHI,2020,COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations,10.1145/3313831.3376615,"Interpretable machine learning models trade -off accuracy for simplicity to make explanations more readable and easier to comprehend. Drawing from cognitive psychology theories in graph comprehension, we formalize readability as visual cognitive chunks to measure and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM (COGAM) to generate explanations with desired cognitive load and accuracy by combining the expressive nonlinear generalized additive models (GAM) with simpler sparse linear models. We calibrated visual cognitive chunks with reading time in a user study, characterized the trade-off between cognitive load and accuracy for four datasets in simulation studies, and evaluated COGAM against baselines with users. We found that COGAM can decrease cognitive load without decreasing accuracy and/or increase accuracy without increasing cognitive load. Our framework and empirical measurement instruments for cognitive load will enable more rigorous assessment of the human interpretability of explainable AI.",Ashraf M. Abdul;Christian von der Weth;Mohan S. Kankanhalli;Brian Y. Lim,
CHI,2020,Towards an Understanding of Augmented Reality Extensions for Existing 3D Data Analysis Tools,10.1145/3313831.3376657,"We present an observational study with domain experts to understand how augmented reality (AR) extensions to traditional PC-based data analysis tools can help particle physicists to explore and understand 3D data. Our goal is to allow researchers to integrate stereoscopic AR-based visual representations and interaction techniques into their tools, and thus ultimately to increase the adoption of modern immersive analytics techniques in existing data analysis workflows. We use Microsoft's HoloLens as a lightweight and easily maintainable AR headset and replicate existing visualization and interaction capabilities on both the PC and the AR view. We treat the AR headset as a second yet stereoscopic screen, allowing researchers to study their data in a connected multi-view manner. Our results indicate that our collaborating physicists appreciate a hybrid data exploration setup with an interactive AR extension to improve their understanding of particle collision events.",Xiyao Wang;Lonni Besançon;David Rousseau;Mickaël Sereno;Mehdi Ammi;Tobias Isenberg 0001,
CHI,2020,"Ecology Meets Computer Science: Designing Tools to Reconcile People, Data, and Practices",10.1145/3313831.3376663,"Ecoacoustics draws together computer scientists and ecologists to achieve an understanding of ecosystems and wildlife using acoustic recordings of the environment. Computer scientists are challenged to manage increasingly large datasets while developing analytic and visualisation tools. Ecologists struggle to find and use tools that answer highly heterogeneous research questions. These two fields are naturally drawn together at the tool interface, however, less attention has been paid to how their practices influence tool design and use. We interviewed and collected email correspondence from four computer scientists and eight ecologists to learn how their practices indicate opportunities for reconciling difference through design. We found that different temporal rhythms, relationships to data, and data-driven questions demand tool configuration, data integration, and standardisation. This research outlines interfacing opportunities for new ecological research utilising large acoustic datasets, and also contributes to evolving HCI approaches in areas making use of big data and human-in-the-loop processes.",Kellie Vella;Jessica L. Oliver;Tshering Dema;Margot Brereton;Paul Roe,
CHI,2020,Genie in the Bottle: Anthropomorphized Perceptions of Conversational Agents,10.1145/3313831.3376665,"This paper presents a qualitative multi-phase study seeking to identify patterns in users' anthropomorphized perceptions of conversational agents. Through a comparative analysis of behavioral perceptions and visual conceptions of three agents - Alexa, Google Assistant, and Siri - we first show that the perceptions of an agent's character are structured according to five categories: approachability, sentiment toward a user, professionalism, intelligence, and individuality. We then explore visualizations of the agents' appearance and discuss the specifics assigned to each agent. Finally, we analyze associative explanations for these perceptions. We demonstrate that the anthropomorphized behavioral and visual perceptions of agents yield structural consistency and discuss how these perceptions are linked with each other and system features.",Anastasia Kuzminykh;Jenny Sun;Nivetha Govindaraju;Jeff Avery;Edward Lank,
CHI,2020,Assessing 2D and 3D Heatmaps for Comparative Analysis: An Empirical Study,10.1145/3313831.3376675,"Heatmaps are a popular visualization technique that encode 2D density distributions using color or brightness. Experimental studies have shown though that both of these visual variables are inaccurate when reading and comparing numeric data values. A potential remedy might be to use 3D heatmaps by introducing height as a third dimension to encode the data. Encoding abstract data in 3D, however, poses many problems, too. To better understand this tradeoff, we conducted an empirical study (N=48) to evaluate the user performance of 2D and 3D heatmaps for comparative analysis tasks. We test our conditions on a conventional 2D screen, but also in a virtual reality environment to allow for real stereoscopic vision. Our main results show that 3D heatmaps are superior in terms of error rate when reading and comparing single data items. However, for overview tasks, the well-established 2D heatmap performs better.",Matthias Kraus 0002;Katrin Angerbauer;Juri Buchmüller;Daniel Schweitzer;Daniel A. Keim;Michael Sedlmair;Johannes Fuchs 0001,
CHI,2020,"What's Wrong with Computational Notebooks? Pain Points, Needs, and Design Opportunities",10.1145/3313831.3376729,"Computational notebooks - such as Azure, Databricks, and Jupyter - are a popular, interactive paradigm for data scientists to author code, analyze data, and interleave visualizations, all within a single document. Nevertheless, as data scientists incorporate more of their activities into notebooks, they encounter unexpected difficulties, or pain points, that impact their productivity and disrupt their workflow. Through a systematic, mixed-methods study using semi-structured interviews (n=20) and survey (n=156) with data scientists, we catalog nine pain points when working with notebooks. Our findings suggest that data scientists face numerous pain points throughout the entire workflow - from setting up notebooks to deploying to production - across many notebook environments. Our data scientists report essential notebook requirements, such as supporting data exploration and visualization. The results of our study inform and inspire the design of computational notebooks.",Souti Chattopadhyay;Ishita Prasad;Austin Z. Henley;Anita Sarma;Titus Barik,HM
CHI,2020,Interacting with Literary Style through Computational Tools,10.1145/3313831.3376730,"Style is an important aspect of writing, shaping how audiences interpret and engage with literary works. However, for most people style is difficult to articulate precisely. While users frequently interact with computational word processing tools with well-defined metrics, such as spelling and grammar checkers, style is a significantly more nuanced concept. In this paper, we present a computational technique to help surface style in written text. We collect a dataset of crowdsourced human judgments of style, derive a model of style by training a neural net on this data, and present novel applications for visualizing and browsing style across broad bodies of literature, as well as an interactive text editor with real-time style feedback. We study these interactive style applications with users and discuss implications for enabling this novel approach to style.",Sarah Sterman;Evey Huang;Vivian Liu;Eric Paulos,
CHI,2020,Investigating Collaborative Exploration of Design Alternatives on a Wall-Sized Display,10.1145/3313831.3376736,"Industrial design review is an iterative process which mainly relies on two steps involving many stakeholders: design discussion and CAD data adjustment. We investigate how a wall-sized display could be used to merge these two steps by allowing multidisciplinary collaborators to simultaneously generate and explore design alternatives. We designed ShapeCompare based on the feedback from a usability study. It enables multiple users to compute and distribute CAD data with touch interaction. To assess the benefit of the wall-sized display in such context, we ran a controlled experiment which aims to compare ShapeCompare with a visualization technique suitable for standard screens. The results show that pairs of participants performed a constraint solving task faster and used more deictic instructions with ShapeCompare. From these findings, we draw generic recommendations for collaborative exploration of alternatives.",Yujiro Okuya;Olivier Gladin;Nicolas Ladevèze;Cédric Fleury;Patrick Bourdot,
CHI,2020,Techniques for Flexible Responsive Visualization Design,10.1145/3313831.3376777,"Responsive visualizations adapt to effectively present information based on the device context. Such adaptations are essential for news content that is increasingly consumed on mobile devices. However, existing tools provide little support for responsive visualization design. We analyze a corpus of 231 responsive news visualizations and discuss formative interviews with five journalists about responsive visualization design. These interviews motivate four central design guidelines: enable simultaneous cross-device edits, facilitate device-specific customization, show cross-device previews, and support propagation of edits. Based on these guidelines, we present a prototype system that allows users to preview and edit multiple visualization versions simultaneously. We demonstrate the utility of the system features by recreating four real-world responsive visualizations from our corpus.",Jane Hoffswell;Wilmot Li;Zhicheng Liu 0001,BP
CHI,2020,InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices,10.1145/3313831.3376782,"While tablet devices are a promising platform for data visualization, supporting consistent interactions across different types of visualizations on tablets remains an open challenge. In this paper, we present multimodal interactions that function consistently across different visualizations, supporting common operations during visual data analysis. By considering standard interface elements (e.g., axes, marks) and grounding our design in a set of core concepts including operations, parameters, targets, and instruments, we systematically develop interactions applicable to different visualization types. To exemplify how the proposed interactions collectively facilitate data exploration, we employ them in a tablet-based system, InChorus that supports pen, touch, and speech input. Based on a study with 12 participants performing replication and factchecking tasks with InChorus, we discuss how participants adapted to using multimodal input and highlight considerations for future multimodal visualization systems.",Arjun Srinivasan;Bongshin Lee;Nathalie Henry Riche;Steven Mark Drucker;Ken Hinckley,HM
CHI,2020,Would you do it?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making,10.1145/3313831.3376788,"A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas---the Trolley and the Mad Bomber---influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems.",Evangelos Niforatos;Adam Palma;Roman Gluszny;Athanasios Vourvopoulos;Fotis Liarokapis,
CHI,2020,RunAhead: Exploring Head Scanning based Navigation for Runners,10.1145/3313831.3376828,"Navigation systems for runners commonly provide turn-by-turn directions via voice and/or map-based visualizations. While voice directions require permanent attention, map-based guidance requires regular consultation. Both disrupt the running activity. To address this, we designed RunAhead, a navigation system using head scanning to query for navigation feedback, and we explored its suitability for runners in an outdoor experiment. In our design, we provide the runner with simple and intuitive navigation feedback on the path s/he is looking at through three different feedback modes: haptic, music and audio cues. In our experiment, we compare the resulting three versions of RunAhead with a baseline voice-based navigation system. We find that demand and error are equivalent across all four conditions. However, the head scanning based haptic and music conditions are preferred over the baseline and these preferences are impacted by runners' habits. With this study we contribute insights for designing navigation support for runners.",Danilo Gallo;Shreepriya Shreepriya;Jutta Willamowski,
CHI,2020,"Design Study ""Lite"" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good",10.1145/3313831.3376829,"Design studies are frequently used to conduct problem-driven visualization research by working with real-world domain experts. In visualization pedagogy, design studies are often introduced but rarely practiced due to their large time requirements. This limits students to a classroom curriculum, often involving projects that may not have implications beyond the classroom. Thus we present the Design Study ""Lite"" Methodology, a novel framework for implementing design studies with novice students in 14 weeks. We utilized the Design Study ""Lite"" Methodology in conjunction with Service-Learning to teach five Data Visualization courses and demonstrate that it benefits not only the students but also the community through service to non-profit partners. In this paper, we provide a detailed breakdown of the methodology and how Service-Learning can be incorporated with it. We also include an extensive reflection on the methodology and provide recommendations for future applications of the framework for teaching visualization courses and research.",Uzma Haque Syeda;Prasanth Murali;Lisa Roe;Becca Berkey;Michelle A. Borkin,BP
CHI,2020,Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations,10.1145/3313831.3376842,"We describe a design space of view manipulation interactions for small data-driven contextual visualizations (word-scale visualizations). These interaction techniques support an active reading experience and engage readers through exploration of embedded visualizations whose placement and content connect them to specific terms in a document. A reader could, for example, use our proposed interaction techniques to explore word-scale visualizations of stock market trends for companies listed in a market overview article. When readers wish to engage more deeply with the data, they can collect, arrange, compare, and navigate the document using the embedded word-scale visualizations, permitting more visualization-centric analyses. We support our design space with a concrete implementation, illustrate it with examples from three application domains, and report results from two experiments. The experiments show how view manipulation interactions helped readers examine embedded visualizations more quickly and with less scrolling and yielded qualitative feedback on usability and future opportunities.",Pascal Goffin;Tanja Blascheck;Petra Isenberg;Wesley Willett,
CHI,2020,Unwind: Interactive Fish Straightening,10.1145/3313831.3376846,"The ScanAllFish project is a large-scale effort to scan all the world's 33,100 known species of fishes. It has already generated thousands of volumetric CT scans of fish species which are available on open access platforms such as the Open Science Framework. To achieve a scanning rate required for a project of this magnitude, many specimens are grouped together into a single tube and scanned all at once. The resulting data contain many fish which are often bent and twisted to fit into the scanner. Our system, Unwind, is a novel interactive visualization and processing tool which extracts, unbends, and untwists volumetric images of fish with minimal user interaction. Our approach enables scientists to interactively unwarp these volumes to remove the undesired torque and bending using a piecewise-linear skeleton extracted by averaging isosurfaces of a harmonic function connecting the head and tail of each fish. The result is a volumetric dataset of a individual, straight fish in a canonical pose defined by the marine biologist expert user. We have developed Unwind in collaboration with a team of marine biologists: Our system has been deployed in their labs, and is presently being used for dataset construction, biomechanical analysis, and the generation of figures for scientific publication.",Francis Williams;Alexander Bock 0002;Harish Doraiswamy;Cassandra M. Donatelli;Kayla Hall;Adam Summers;Daniele Panozzo;Cláudio T. Silva,
CHI,2020,"Heatmaps, Shadows, Bubbles, Rays: Comparing Mid-Air Pen Position Visualizations in Handheld AR",10.1145/3313831.3376848,"In Handheld Augmented Reality, users look at AR scenes through the smartphone held in their hand. In this setting, having a mid-air pointing device like a pen in the other hand greatly expands the interaction possibilities. For example, it lets users create 3D sketches and models while on the go. However, perceptual issues in Handheld AR make it difficult to judge the distance of a virtual object, making it hard to align a pen to it. To address this, we designed and compared different visualizations of the pen's position in its virtual environment, measuring pointing precision, task time, activation patterns, and subjective ratings of helpfulness, confidence, and comprehensibility of each visualization. While all visualizations resulted in only minor differences in precision and task time, subjective ratings of perceived helpfulness and confidence favor a 'heatmap' technique that colors the objects in the scene based on their distance to the pen.",Philipp Wacker;Adrian Wagner;Simon Voelker;Jan O. Borchers,
CHI,2020,DFSeer: A Visual Analytics Approach to Facilitate Model Selection for Demand Forecasting,10.1145/3313831.3376866,"Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case studies and interviews with domain experts demonstrate the effectiveness and usability of DFSeer.",Dong Sun 0001;Zezheng Feng;Yuanzhe Chen;Yong Wang 0021;Jia Zeng;Mingxuan Yuan;Ting-Chuen Pong;Huamin Qu,
CHI,2020,Dziban: Balancing Agency & Automation in Visualization Design via Anchored Recommendations,10.1145/3313831.3376880,"Visualization recommender systems attempt to automate design decisions spanning choices of selected data, transformations, and visual encodings. However, across invocations such recommenders may lack the context of prior results, producing unstable outputs that override earlier design choices. To better balance automated suggestions with user intent, we contribute Dziban, a visualization API that supports both ambiguous specification and a novel anchoring mechanism for conveying desired context. Dziban uses the Draco knowledge base to automatically complete partial specifications and suggest appropriate visualizations. In addition, it extends Draco with chart similarity logic, enabling recommendations that also remain perceptually similar to a provided ""anchor"" chart. Existing APIs for exploratory visualization, such as ggplot2 and Vega-Lite, require fully specified chart definitions. In contrast, Dziban provides a more concise and flexible authoring experience through automated design, while preserving predictability and control through anchored recommendations.",Halden Lin;Dominik Moritz;Jeffrey Heer,
CHI,2020,QMaps: Engaging Students in Voluntary Question Generation and Linking,10.1145/3313831.3376882,"Generating multiple-choice questions is known to improve students' critical thinking and deep learning. Visualizing relationships between concepts enhances meaningful learning, students' ability to relate new concepts to previously learned concepts. We designed and deployed a collaborative learning process through which students generate multiple-choice questions and represent the prerequisite knowledge structure between questions as visual links in a shared map, using a variation of Concept Maps that we call ""QMap."" We conducted a four-month study with 19 undergraduate students. Students sustained voluntary contributions, creating 992 good questions, and drawing 1,255 meaningful links between the questions. Through analyzing self-reports, observations, and usage data, we report on the technical and social design features that led students to sustain their motivation.",Iman YeckehZaare;Tirdad Barghi;Paul Resnick,
CHI,2020,Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics,10.1145/3313831.3376887,"Narrative visualization is a popular style of data-driven storytelling. Authors use this medium to engage viewers with complex and sometimes controversial issues. A challenge for authors is to not only deliver new information, but to also overcome people's biases and misconceptions. We study how people adjust their attitudes toward (or away from) a message experienced through a narrative visualization. In a mixed-methods analysis, we investigate whether eliciting participants' prior beliefs, and visualizing those beliefs alongside actual data, can increase narrative persuasiveness. We find that incorporating priors does not significantly affect attitudinal change. However, participants who externalized their beliefs expressed greater surprise at the data. Their comments also indicated a greater likelihood of acquiring new information, despite the minimal change in attitude. Our results also extend prior findings, showing that visualizations are more persuasive than equivalent textual data representations for exposing contentious issues. We discuss the implications and outline future research directions.",Jeremy Heyer;Nirmal Kumar Raveendranath;Khairi Reda,
CHI,2019,"Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Simulation at a Museum",10.1145/3290605.3300237,"Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a ""human in the loop"" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools.",Aditi Mallavarapu;Leilah Lyons;Stephen M. Uzzo;Wren Thompson;Rinat Levy-Cohen;Brian Slattery,
CHI,2019,MindDot: Supporting Effective Cognitive Behaviors in Concept Map-Based Learning Environments,10.1145/3290605.3300258,"While prior research has revealed the promising impact of concept mapping on learning, few have comprehensively modeled different cognitive behaviors during concept mapping. In addition, existing concept mapping tools lack effective feedback to support better learning behaviors. This work presents MindDot, a concept map-based learning environment that facilitates the cognitive process of comparing and integrating related concepts via two forms of support. A hyperlink support and an expert template. Study results suggested that both types of support had positive impact on the development of comparative strategies and that hyperlink support enhanced learning. We further evaluated the cognitive learning progress at a fine-grained level with two forms of visualizations. We then extracted several behavioral patterns that provided insights about the cognitive progress in learning. Lastly, we derive design recommendations that we hope will inspire future intelligent tutoring systems that automatically evaluate students' learning behaviors and foster them in developing effective learning behaviors",Shang Wang 0001;Deniz Sonmez Unal;Erin Walker,
CHI,2019,In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound,10.1145/3290605.3300268,"Collaboration is built on trust, and establishing trust with a creative Artificial Intelligence is difficult when the decision process or internal state driving its behaviour isn't exposed. When human musicians improvise together, a number of extra-musical cues are used to augment musical communication and expose mental or emotional states which affect musical decisions and the effectiveness of the collaboration. We developed a collaborative improvising AI drummer that communicates its confidence through an emoticon-based visualisation. The AI was trained on musical performance data, as well as real-time skin conductance, of musicians improvising with professional drummers, exposing both musical and extra-musical cues to inform its generative process. Uni- and bi-directional extra-musical communication with real and false values were tested by experienced improvising musicians. Each condition was evaluated using the FSS-2 questionnaire, as a proxy for musical engagement. The results show a positive correlation between extra-musical communication of machine internal state and human musical engagement.",Jon McCormack;Toby Gifford;Patrick Hutchings;Maria Teresa Llano Rodriguez;Matthew Yee-King;Mark d'Inverno,
CHI,2019,Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data,10.1145/3290605.3300269,"Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard to replicate online. Team members' embodied, multimodal interaction with each other and artefacts has been studied by researchers, but due to its complexity, has remained opaque to automated analysis. However, the ready availability of sensors makes it increasingly affordable to instrument work spaces to study teamwork and groupwork. The possibility of visualising key aspects of a collaboration has huge potential for both academic and professional learning, but a frontline challenge is the enrichment of quantitative data streams with the qualitative insights needed to make sense of them. In response, we introduce the concept of collaboration translucence, an approach to make visible selected features of group activity. This is grounded both theoretically (in the physical, epistemic, social and affective dimensions of group activity), and contextually (using domain-specific concepts). We illustrate the approach from the automated analysis of healthcare simulations to train nurses, generating four visual proxies that fuse multimodal data into higher order patterns.",Vanessa Echeverría;Roberto Martínez Maldonado;Simon Buckingham Shum,
CHI,2019,Understanding Visual Cues in Visualizations Accompanied by Audio Narrations,10.1145/3290605.3300280,"It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type.",Ha Kyung Kong;Wenjie Zhu;Zhicheng Liu 0001;Karrie Karahalios,
CHI,2019,A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays,10.1145/3290605.3300288,"Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view - meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments.",Julian Petford;Iain Carson;Miguel A. Nacenta;Carl Gutwin,
CHI,2019,Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations,10.1145/3290605.3300298,"Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved.",In Kwon Choi;Taylor Childers;Nirmal Kumar Raveendranath;Swati Mishra 0006;Kyle Harris;Khairi Reda,
CHI,2019,Analyzing Value Discovery in Design Decisions Through Ethicography,10.1145/3290605.3300307,"HCI scholarship is increasingly concerned with the ethical impact of socio-technical systems. Current theoretically driven approaches that engage with ethics generally prescribe only abstract approaches by which designers might consider values in the design process. However, there is little guidance on methods that promote value discovery, which might lead to more specific examples of relevant values in specific design contexts. In this paper, we elaborate a method for value discovery, identifying how values impact the designer's decision making. We demonstrate the use of this method, called Ethicography, in describing value discovery and use throughout the design process. We present analysis of design activity by user experience (UX) design students in two lab protocol conditions, describing specific human values that designers considered for each task, and visualizing the interplay of these values. We identify opportunities for further research, using the Ethicograph method to illustrate value discovery and translation into design solutions.",Shruthi Sai Chivukula;Colin M. Gray;Jason A. Brier,HM
CHI,2019,DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data,10.1145/3290605.3300309,"Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data.",Nam Wook Kim;Hyejin Im;Nathalie Henry Riche;Alicia Wang;Krzysztof Gajos;Hanspeter Pfister,
CHI,2019,A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact,10.1145/3290605.3300312,"Dynamic elements of the drawing process (e.g., order of compilation, speed, length, and pressure of strokes) are considered important because they can reveal the technique, process, and emotions of the artist. To explore how sensing, visualizing, and sharing these aspects of the creative process might shape art making and art viewing experiences, we designed a research probe which unobtrusively tracks and visualizes the movement and pressure of the artist's pencil on an easel. Using our probe, we conducted studies with artists and art viewers, which reveal digital and physical representations of creative process as a means of reflecting on a multitude of factors about the finished artwork, including technique, style, and the emotions of the artists. We conclude by discussing future directions for HCI systems that sense and visualize aspects of the creative process in digitally-mediated arts, as well as the social considerations of sharing and curating intimate process information.",Piyum Fernando;Jennifer Weiler;Stacey Kuznetsov,
CHI,2019,Towards Effective Foraging by Data Scientists to Find Past Analysis Choices,10.1145/3290605.3300322,"Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab.",Mary Beth Kery;Bonnie E. John;Patrick O'Flaherty;Amber Horvath;Brad A. Myers,
CHI,2019,Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing,10.1145/3290605.3300324,"The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust.",Dhruv Jain;Angela Lin;Rose Guttman;Marcus Amalachandran;Aileen Zeng;Leah Findlater;Jon Froehlich,
CHI,2019,DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction,10.1145/3290605.3300335,"Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics.",Nam Wook Kim;Nathalie Henry Riche;Benjamin Bach;Guanpeng Xu;Matthew Brehmer;Ken Hinckley;Michel Pahud;Haijun Xia;Michael J. McGuffin;Hanspeter Pfister,
CHI,2019,Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes,10.1145/3290605.3300353,"The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG.",Alaa Alahmadi;Alan Davies;Jennifer Royle;Markel Vigo;Caroline Jay,
CHI,2019,VizML: A Machine Learning Approach to Visualization Recommendation,10.1145/3290605.3300358,"Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems.",Kevin Zeng Hu;Michiel A. Bakker;Stephen Li;Tim Kraska;César A. Hidalgo 0001,
CHI,2019,Visually Encoding the Lived Experience of Bipolar Disorder,10.1145/3290605.3300363,"Issues of social identity, attitudes towards self-disclosure, and potentially biased approaches to what is considered ""typical"" or ""normal"" are critical factors when designing visualizations for personal informatics systems. This is particularly true when working with vulnerable populations like those who self-track to manage serious mental illnesses like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better understand sense-making challenges related to the representation and interpretation of personal data and 2) probe the benefits, risks, and limitations of participatory approaches to designing personal data visualizations that better reflect their lived experiences. We describe our co-design process, present a series of emergent visual encoding schemas resulting from these activities, and report on the assessment of these speculative designs by participants. We conclude by summarizing important considerations and implications for designing personal data visualizations for (and with) people who self-track to manage serious mental illness.",Jaime Snyder;Elizabeth L. Murnane;Caitlin Lustig;Stephen Voida,
CHI,2019,Communicating Uncertainty in Fertility Prognosis,10.1145/3290605.3300391,"Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects.",Hanna Schneider;Julia Wayrauther;Mariam Hassib;Andreas Butz,
CHI,2019,GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure,10.1145/3290605.3300404,"The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture.",Don Samitha Elvitigala;Denys J. C. Matthies;Löic David;Chamod Weerasinghe;Suranga Nanayakkara,
CHI,2019,Ethical Dimensions of Visualization Research,10.1145/3290605.3300418,"Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations.",Michael Correll,HM
CHI,2019,Ranked-List Visualization: A Graphical Perception Study,10.1145/3290605.3300422,"Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value.",Pranathi Mylavarapu;Adil Yalçin;Xan Gregg;Niklas Elmqvist,
CHI,2019,A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation,10.1145/3290605.3300423,"Designers are often discouraged from creating data visualizations that omit or distort information, because they can easily be misleading. However, the same representations that could be used to deceive can provide benefits when chosen to appropriately align with user tasks. We present an interaction technique, Perceptual Glimpses, which allows for the transparent presentation of so-called 'deceptive' views of information that are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level exaggeration caused by a truncated axis on a bar chart was reduced under some conditions, but users require guidance to avoid errors, and view presentation order may affect trust. When Perceptual Glimpses was extended to display a range of views that might otherwise be deceptive or difficult to understand if shown out of context, users were able to understand and leverage these transformations to perform a range of low-level tasks. Design recommendations and examples suggest extensions of the technique.",Jacob Ritchie;Daniel Wigdor;Fanny Chevalier,
CHI,2019,On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction,10.1145/3290605.3300458,"We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction.",Thammathip Piumsomboon;Gun A. Lee;Andrew Irlitti;Barrett Ens;Bruce H. Thomas;Mark Billinghurst,
CHI,2019,Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania,10.1145/3290605.3300474,"Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the 'data poor'. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/",Evan M. Peck;Sofia E. Ayuso;Omar El-Etr,BP
CHI,2019,Examining and Enhancing the Illusory Touch Perception in Virtual Reality Using Non-Invasive Brain Stimulation,10.1145/3290605.3300477,"Virtual reality (VR) can be immersive to such a degree that users sometimes report feeling tactile sensations based on visualization of the touch, without any actual physical contact. This effect is not only interesting for studies of human perception, but can also be leveraged to improve the quality of VR by evoking tactile sensations without usage of specialized equipment. The aim of this paper is to study brain processing of the illusory touch and its enhancement for purposes of exploitation in VR scene design. To amplify the illusory touch, transcranial direct current stimulation (tDCS) was used. Participants attended two sessions with blinded stimulation and interacted with a virtual ball using tracked hands in VR. The effects were studied using electroencephalography (EEG), that allowed us to examine stimulation-induced changes in processing of the illusory touch in the brain, as well as to identify its neural correlates. Results confirm enhanced processing of the illusory touch after the stimulation, and some of these changes were correlated to subjective rating of its magnitude.",Filip Skola;Fotis Liarokapis,
CHI,2019,Thinking Too Classically: Research Topics in Human-Quantum Computer Interaction,10.1145/3290605.3300486,"Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of ""quantum native"" programmers.",Zahra Ashktorab;Justin D. Weisz;Maryam Ashoori,
CHI,2019,Managing Messes in Computational Notebooks,10.1145/3290605.3300500,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning.",Andrew Head;Fred Hohman;Titus Barik;Steven Mark Drucker;Robert DeLine,BP
CHI,2019,Frequency-Based Design of Smart Textiles,10.1145/3290605.3300524,"Despite the increasing amount of smart textile design practitioners, the methods and tools commonly available have not progressed to the same scale. Most smart textile interaction designs today rely on detecting changes in resistance. The tools and sensors for this are generally limited to DC-voltage-divider based sensors and multimeters. Furthermore, the textiles and the materials used in smart textile design can exhibit behaviour making it difficult to identify even simple interactions using those means. For instance, steel-based textiles exhibit intrinsic semiconductive properties that are difficult to identify with current methods. In this paper, we show an alternative way to measure interaction with smart textiles. By relying on visualisation known as Lissajous-figures and frequency-based signals, we can detect even subtle and varied forms of interaction with smart textiles. We also show an approach to measuring frequency-based signals and present an Arduino-based system called Teksig to support this type of textile practice.",Jussi Mikkonen;Riikka Townsend,
CHI,2019,Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots,10.1145/3290605.3300555,"Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane.",Arnaud Prouzeau;Maxime Cordeil;Clement Robin;Barrett Ens;Bruce H. Thomas;Tim Dwyer,
CHI,2019,Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking,10.1145/3290605.3300561,"In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development.",Julia Deeb-Swihart;Alex Endert;Amy S. Bruckman,
CHI,2019,Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment,10.1145/3290605.3300576,"Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants.",Ha Kyung Kong;Zhicheng Liu 0001;Karrie Karahalios,
CHI,2019,Aggregated Visualization of Playtesting Data,10.1145/3290605.3300593,"Playtesting is a key component in the game development process aimed at improving the quality of games through the collection of gameplay data and identification of design issues. Visualization techniques are currently being employed to help integrate quantitative and qualitative data. Despite that, two existing challenges are to determine the level of detail to be presented to developers based on their needs and to effectively communicate the collected data so that informed design changes can be reached. In this paper, we first propose an aggregated visualization technique that makes use of clustering, territory tessellation, and trajectory aggregation to simultaneously display mixed playtesting data. Secondly, to assess the usefulness of our technique we evaluate it through interviews with professional game developers and compare it to a non-aggregated visualization. The results of this study also provide an important contribution towards identifying areas of improvement in the portrayal of gameplay data.",Günter Wallner;Nour Halabi;Pejman Mirza-Babaei,
CHI,2019,Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity,10.1145/3290605.3300614,"We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation.",Somi Ju;Kyung-Ryong Lee;Subin Kim;Young-Woo Park,
CHI,2019,PicMe: Interactive Visual Guidance for Taking Requested Photo Composition,10.1145/3290605.3300625,"PicMe is a mobile application that provides interactive on-screen guidance that helps the user take pictures of a composition that another person requires. Once the requester captures a picture of the desired composition and delivers it to the user (photographer), a 2.5D guidance system, called the virtual frame, guides the user in real-time by showing a three-dimensional composition of the target image (i.e., size and shape). In addition, according to the matching accuracy rate, we provide a small-sized target image in an inset window as feedback and edge visualization for further alignment of the detail elements. We implemented PicMe to work fully in mobile environments. We then conducted a preliminary user study to evaluate the effectiveness of PicMe compared to traditional 2D guidance methods. The results show that PicMe helps users reach their target images more accurately and quickly by giving participants more confidence in their tasks.",Minju Kim;Jungjin Lee,BP
CHI,2019,Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring,10.1145/3290605.3300686,"Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field.",Maria Shugrina;Wenjia Zhang;Fanny Chevalier;Sanja Fidler;Karan Singh,
CHI,2019,Eye-Write: Gaze Sharing for Collaborative Writing,10.1145/3290605.3300727,"Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner's gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author's activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing.",Grete Helena Kütt;Kevin Lee;Ethan Hardacre;Alexandra Papoutsaki,
CHI,2019,Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology,10.1145/3290605.3300735,"Participatory performance provides methods for exploring social identities and situations in ways that can help people to imagine new ways of being. Digital technologies provide tools that can help people envision these possibilities. We explore this combination through a performance workshop process designed to help stroke survivors imagine new physical and social possibilities by enacting fantasies of ""things they always wanted to do"". This process uses performance methods combined with specially designed real-time movement visualisations to progressively build fantasy narratives that are enacted with and for other workshop participants. Qualitative evaluations suggest this process successfully stimulates participant's embodied imagination and generates a diverse range of fantasies. The interactive and communal aspects of the workshop process appear to be especially important in achieving these effects. This work highlights how the combination of performance methods and interactive tools can bring a rich, prospective and political understanding of people's lived experience to design.",Rosella P. Galindo Esparza;Patrick G. T. Healey;Lois Weaver;Matthew Delbridge,
CHI,2019,Saliency Deficit and Motion Outlier Detection in Animated Scatterplots,10.1145/3290605.3300771,"We report the results of a crowdsourced experiment that measured the accuracy of motion outlier detection in multivariate, animated scatterplots. The targets were outliers either in speed or direction of motion, and were presented with varying levels of saliency in dimensions that are irrelevant to the task of motion outlier detection (e.g., color, size, position). We found that participants had trouble finding the outlier when it lacked irrelevant salient features and that visual channels contribute unevenly to the odds of an outlier being correctly detected. Direction of motion contributes the most to accurate detection of speed outliers, and position contributes the most to accurate detection of direction outliers. We introduce the concept of saliency deficit in which item importance in the data space is not reflected in the visualization due to a lack of saliency. We conclude that motion outlier detection is not well supported in multivariate animated scatterplots.",Rafael Veras;Christopher Collins 0001,HM
CHI,2019,Haptipedia: Accelerating Haptic Device Discovery to Support Interaction & Engineering Design,10.1145/3290605.3300788,"Creating haptic experiences often entails inventing, modifying, or selecting specialized hardware. However, interaction designers are rarely engineers, and 30 years of haptic inventions are buried in a fragmented literature that describes devices mechanically rather than by potential purpose. We conceived of Haptipedia to unlock this trove of examples: Haptipedia presents a device corpus for exploration through metadata that matter to both device and interaction designers. It is a taxonomy of device attributes that go beyond physical description to capture potential utility, applied to a growing database of 105 grounded force-feedback devices, and accessed through a public visualization that links utility to morphology. Haptipedia's design was driven by both systematic review of the haptic device literature and rich input from diverse haptic designers. We describe Haptipedia's reception (including hopes it will redefine device reporting standards) and our plans for its sustainability through community participation.",Hasti Seifi;Farimah Fazlollahi;Michael Oppermann;John Andrew Sastrillo;Jessica Ip;Ashutosh Agrawal;Gunhyuk Park;Katherine J. Kuchenbecker;Karon E. MacLean,
CHI,2019,Card Mapper: Enabling Data-Driven Reflections on Ideation Cards,10.1145/3290605.3300801,"We explore how usage data captured from ideation cards can enable reflection on design. We deployed a deck of ideation cards on a Masters level module over two years, developing the means to capture the students' designs into a digital repository. We created two visualisations to reveal the relative co-occurrences of the cards as concept space and the relative proximity of designs (through cards used in common) as design space. We used these to elicit reflections from the perspectives of students, teachers and card designers. Our findings inspire ideas for extending the data-driven use of ideation cards throughout the design process; informing the redesign of cards, the rules for using them and their live connection to supporting materials and enabling stakeholders to reflect and recognise challenges and opportunities. We also identified the need, and potential ways, to capture a richer design rationale, including annotations, discarded cards and varying card interpretations.",Dimitrios Paris Darzentas;Raphael Velt;Richard Wetzel;Peter J. Craigon;Hanne Gesine Wagner;Lachlan D. Urquhart;Steve Benford,
CHI,2019,Visualizing Uncertainty and Alternatives in Event Sequence Predictions,10.1145/3290605.3300803,"Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions.",Shunan Guo;Fan Du;Sana Malik;Eunyee Koh;Sungchul Kim;Zhicheng Liu 0001;Donghyun Kim 0007;Hongyuan Zha;Nan Cao 0001,
CHI,2019,TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings,10.1145/3290605.3300807,"Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion ""relatedness"" to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content.",Senthil K. Chandrasegaran;Chris Bryan;Hidekazu Shidara;Tung-Yen Chuang;Kwan-Liu Ma,
CHI,2019,Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models,10.1145/3290605.3300809,"Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.",Fred Hohman;Andrew Head;Rich Caruana;Robert DeLine;Steven Mark Drucker,
CHI,2019,Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups,10.1145/3290605.3300846,"We present Vistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework.",Tom Horak;Andreas Mathisen;Clemens Nylandsted Klokmose;Raimund Dachselt;Niklas Elmqvist,
CHI,2019,PeerLens: Peer-inspired Interactive Learning Path Planning in Online Question Pool,10.1145/3290605.3300864,"Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive.",Meng Xia;Mingfei Sun;Huan Wei;Qing Chen 0001;Yong Wang 0021;Lei Shi 0002;Huamin Qu;Xiaojuan Ma,
CHI,2019,VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository,10.1145/3290605.3300892,"Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets.",Kevin Zeng Hu;Snehalkumar (Neil) S. Gaikwad;Madelon Hulsebos;Michiel A. Bakker;Emanuel Zgraggen;César A. Hidalgo 0001;Tim Kraska;Guoliang Li 0001;Arvind Satyanarayan;Çagatay Demiralp,
CHI,2019,"Measuring the Separability of Shape, Size, and Color in Scatterplots",10.1145/3290605.3300899,"Scatterplots commonly use multiple visual channels to encode multivariate datasets. Such visualizations often use size, shape, and color as these dimensions are considered separable--dimensions represented by one channel do not significantly interfere with viewers' abilities to perceive data in another. However, recent work shows the size of marks significantly impacts color difference perceptions, leading to broader questions about the separability of these channels. In this paper, we present a series of crowdsourced experiments measuring how mark shape, size, and color influence data interpretation in multiclass scatterplots. Our results indicate that mark shape significantly influences color and size perception, and that separability among these channels functions asymmetrically: shape more strongly influences size and color perceptions in scatterplots than size and color influence shape. Models constructed from the resulting data can help designers anticipate viewer perceptions to build more effective visualizations.",Stephen Smart;Danielle Albers Szafir,
CHI,2019,Making Sense of Human-Food Interaction,10.1145/3290605.3300908,"Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI.",Ferran Altarriba Bertran;Samvid Niravbhai Jhaveri;Rosa Lutz;Katherine Isbister;Danielle Wilde,
CHI,2019,ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning,10.1145/3290605.3300911,"To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users.",Qianwen Wang;Yao Ming;Zhihua Jin;Qiaomu Shen;Dongyu Liu;Micah J. Smith;Kalyan Veeramachaneni;Huamin Qu,
CHI,2019,A Bayesian Cognition Approach to Improve Data Visualization,10.1145/3290605.3300912,"People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty.",Yea-Seul Kim;Logan A. Walls;Peter M. Krafft;Jessica Hullman,
CHI,2019,Falcon: Balancing Interactive Latency and Resolution Sensitivity for Scalable Linked Visualizations,10.1145/3290605.3300924,"We contribute user-centered prefetching and indexing methods that provide low-latency interactions across linked visualizations, enabling cold-start exploration of billion-record datasets. We implement our methods in Falcon, a web-based system that makes principled trade-offs between latency and resolution to optimize brushing and view switching times. To optimize latency-sensitive brushing actions, Falcon reindexes data upon changes to the active view a user is brushing in. To limit view switching times, Falcon initially loads reduced interactive resolutions, then progressively improves them. Benchmarks show that Falcon sustains real-time interactivity of 50fps for pixel-level brushing and linking across multiple visualizations with no costly precomputation. We show constant brushing performance regardless of data size on datasets ranging from millions of records in the browser to billions when connected to a backing database system.",Dominik Moritz;Bill Howe;Jeffrey Heer,
CHI,2019,Effect of Orientation on Unistroke Touch Gestures,10.1145/3290605.3300928,"As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures.",Sven Mayer;Valentin Schwind;Huy Viet Le;Dominik Weber;Jonas Vogelsang;Johannes Wolf;Niels Henze,
CHI,2019,A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App,10.1145/3290605.3300933,"Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population. Even though it is a treatable condition, people often do not seek treatment. In this paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical professionals and 21 end-users) an OAB mobile health application that aims to increase adherence to self-managed treatment. Our results support previous research that visualizing progress, setting goals, receiving reminders and feedback increases use. We discovered that games could be used successfully as a distraction technique for urge suppression. Contrary to the current research direction, automatically calculated features could be a detriment to app interaction. Regarding evaluation, we found that designers may not want to rely only on questionnaires when assessing the success of a game and its emotional impact on users.",Ana-Maria Salai;Lynne Baillie,
CHI,2018,When David Meets Goliath: Combining Smartwatches with a Large Vertical Display for Visual Data Exploration,10.1145/3173574.3173593,"We explore the combination of smartwatches and a large interactive display to support visual data analysis. These two extremes of interactive surfaces are increasingly popular, but feature different characteristics-display and input modalities, personal/public use, performance, and portability. In this paper, we first identify possible roles for both devices and the interplay between them through an example scenario. We then propose a conceptual framework to enable analysts to explore data items, track interaction histories, and alter visualization configurations through mechanisms using both devices in combination. We validate an implementation of our framework through a formative evaluation and a user study. The results show that this device combination, compared to just a large display, allows users to develop complex insights more fluidly by leveraging the roles of the two devices. Finally, we report on the interaction patterns and interplay between the devices for visual exploration as observed during our study.",Tom Horak;Sriram Karthik Badam;Niklas Elmqvist;Raimund Dachselt,HM
CHI,2018,Flexible and Mindful Self-Tracking: Design Implications from Paper Bullet Journals,10.1145/3173574.3173602,"Digital self-tracking technologies offer many potential benefits over self-tracking with paper notebooks. However, they are often too rigid to support people's practical and emotional needs in everyday settings. To inform the design of more flexible self-tracking tools, we examine bullet journaling: an analogue and customisable approach for logging and reflecting on everyday life. Analysing a corpus of paper bullet journal photos and related conversations on Instagram, we found that individuals extended and adapted bullet journaling systems to their changing practical and emotional needs through: (1) creating and combining personally meaningful visualisations of different types of trackers, such as habit, mood, and symptom trackers; (2) engaging in mindful reflective thinking through design practices and self-reflective strategies; and (3) posting photos of paper journals online to become part of a self-tracking culture of sharing and learning. We outline two interrelated design directions for flexible and mindful self-tracking: digitally extending analogue self-tracking and supporting digital self-tracking as a mindful design practice.",Amid Ayobi;Tobias Sonne;Paul Marshall;Anna L. Cox,
CHI,2018,Exploration and Explanation in Computational Notebooks,10.1145/3173574.3173606,"Computational notebooks combine code, visualizations, and text in a single document. Researchers, data analysts, and even journalists are rapidly adopting this new medium. We present three studies of how they are using notebooks to document and share exploratory data analyses. In the first, we analyzed over 1 million computational notebooks on GitHub, finding that one in four had no explanatory text but consisted entirely of visualizations or code. In a second study, we examined over 200 academic computational notebooks, finding that although the vast majority described methods, only a minority discussed reasoning or results. In a third study, we interviewed 15 academic data analysts, finding that most considered computational notebooks personal, exploratory, and messy. Importantly, they typically used other media to share analyses. These studies demonstrate a tension between exploration and explanation in constructing and sharing computational notebooks. We conclude with opportunities to encourage explanation in computational media without hindering exploration.",Adam Rule;Aurélien Tabard;James D. Hollan,HM
CHI,2018,TopoText: Context-Preserving Text Data Exploration Across Multiple Spatial Scales,10.1145/3173574.3173611,"TopoText is a context-preserving technique for visualizing text data for multi-scale spatial aggregates to gain insight into spatial phenomena. Conventional exploration requires users to navigate across multiple scales but only presents the information related to the current scale. This limitation potentially adds more steps of interaction and cognitive overload to the users. TopoText renders multi-scale aggregates into a single visual display combining novel text-based encoding and layout methods that draw labels along the boundary or filled within the aggregates. The text itself not only summarizes the semantics at each individual scale, but also indicates the spatial coverage of the aggregates and their underlying hierarchical relationships. We validate TopoText with both a user study as well as several application examples.",Jiawei Zhang 0003;Chittayong Surakitbanharn;Niklas Elmqvist;Ross Maciejewski;Zhenyu Cheryl Qian;David S. Ebert,HM
CHI,2018,Design Patterns for Data Comics,10.1145/3173574.3173612,"Data comics for data-driven storytelling are inspired by the visual language of comics and aim to communicate insights in data through visualizations. While comics are widely known, few examples of data comics exist and there has not been any structured analysis nor guidance for their creation. We introduce data-comic design-patterns, each describing a set of panels with a specific narrative purpose, that allow for rapid storyboarding of data comics while showcasing their expressive potential. Our patterns are derived from i) analyzing common patterns in infographics, datavideos, and existing data comics, ii) our experiences creating data comics for different scenarios. Our patterns demonstrate how data comics allow an author to combine the best of both worlds: spatial layout and overview from infographics as well as linearity and narration from videos and presentations.",Benjamin Bach;Zezhong Wang 0001;Matteo Farinella;Dave Murray-Rust;Nathalie Henry Riche,
CHI,2018,"Clusters, Trends, and Outliers: How Immersive Technologies Can Facilitate the Collaborative Analysis of Multidimensional Data",10.1145/3173574.3173664,"Immersive technologies such as augmented reality devices are opening up a new design space for the visual analysis of data. This paper studies the potential of an augmented reality environment for the purpose of collaborative analysis of multidimensional, abstract data. We present ART, a collaborative analysis tool to visualize multidimensional data in augmented reality using an interactive, 3D parallel coordinates visualization. The visualization is anchored to a touch-sensitive tabletop, benefiting from well-established interaction techniques. The results of group-based, expert walkthroughs show that ART can facilitate immersion in the data, a fluid analysis process, and collaboration. Based on the results, we provide a set of guidelines and discuss future research areas to foster the development of immersive technologies as tools for the collaborative analysis of multidimensional data.",Simon Butscher;Sebastian Hubenschmid;Jens Müller 0001;Johannes Fuchs 0001;Harald Reiterer,
CHI,2018,Understanding Older Users' Acceptance of Wearable Interfaces for Sensor-based Fall Risk Assessment,10.1145/3173574.3173693,"Algorithms processing data from wearable sensors promise to more accurately predict risks of falling -- a significant concern for older adults. Substantial engineering work is dedicated to increasing the prediction accuracy of these algorithms; yet fewer efforts are dedicated to better engaging users through interactive visualizations in decision-making using these data. We present an investigation of the acceptance of a sensor-based fall risk assessment wearable device. A participatory design was employed to develop a mobile interface providing visualizations of sensor data and algorithmic assessments of fall risks. We then investigated the acceptance of this interface and its potential to motivate behavioural changes through a field deployment, which suggested that the interface and its belt-mounted wearable sensors are perceived as usable. We also found that providing contextual information for fall risk estimation combined with relevant practical fall prevention instructions may facilitate the acceptance of such technologies, potentially leading to behaviour change.",Alan Yusheng Wu;Cosmin Munteanu,
CHI,2018,Data Illustrator: Augmenting Vector Design Tools with Lazy Data Binding for Expressive Visualization Authoring,10.1145/3173574.3173697,"Building graphical user interfaces for visualization authoring is challenging as one must reconcile the tension between flexible graphics manipulation and procedural visualization generation based on a graphical grammar or declarative languages. To better support designers' workflows and practices, we propose Data Illustrator, a novel visualization framework. In our approach, all visualizations are initially vector graphics; data binding is applied when necessary and only constrains interactive manipulation to that data bound property. The framework augments graphic design tools with new concepts and operators, and describes the structure and generation of a variety of visualizations. Based on the framework, we design and implement a visualization authoring system. The system extends interaction techniques in modern vector design tools for direct manipulation of visualization configurations and parameters. We demonstrate the expressive power of our approach through a variety of examples. A qualitative study shows that designers can use our framework to compose visualizations.",Zhicheng Liu 0001;John Thompson 0002;Alan Wilson 0004;Mira Dontcheva;James Delorey;Sam Grigg;Bernard Kerr;John T. Stasko,BP
CHI,2018,The Effects of Adding Search Functionality to Interactive Visualizations on the Web,10.1145/3173574.3173711,"The widespread use of text-based search in user interfaces has led designers in visualization to occasionally add search functionality to their creations. Yet it remains unclear how search may impact a person's behavior. Given the unstructured context of the web, users may not have explicit information-seeking goals and designers cannot make assumptions about user attention. To bridge this gap, we observed the impact of integrating search with five visualizations across 830 online participants. In an unguided task, we find that (1) the presence of text-based search influences people's information-seeking goals, (2) search can alter the data that people explore and how they engage with it, and (3) the effects of search are amplified in visualizations where people are familiar with the underlying dataset. These results suggest that text-search in web visualizations drives users towards more diverse information seeking goals, and may be valuable in a range of existing visualization designs.",Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison,
CHI,2018,Towards Design Principles for Visual Analytics in Operations Contexts,10.1145/3173574.3173712,"Operations engineering teams interact with complex data systems to make technical decisions that ensure the operational efficacy of their missions. To support these decision-making tasks, which may require elastic prioritization of goals dependent on changing conditions, custom analytics tools are often developed. We were asked to develop such a tool by a team at the NASA Jet Propulsion Laboratory, where rover telecom operators make decisions based on models predicting how much data rovers can transfer from the surface of Mars. Through research, design, implementation, and informal evaluation of our new tool, we developed principles to inform the design of visual analytics systems in operations contexts. We offer these principles as a step towards understanding the complex task of designing these systems. The principles we present are applicable to designers and developers tasked with building analytics systems in domains that face complex operations challenges such as scheduling, routing, and logistics.",Matthew Conlen;Sara Stalla;Chelly Jin;Maggie Hendrie;Hillary Mushkin;Santiago V. Lombeyda;Scott Davidoff,
CHI,2018,Uncertainty Displays Using Quantile Dotplots or CDFs Improve Transit Decision-Making,10.1145/3173574.3173718,"Everyday predictive systems typically present point predictions, making it hard for people to account for uncertainty when making decisions. Evaluations of uncertainty displays for transit prediction have assessed people's ability to extract probabilities, but not the quality of their decisions. In a controlled, incentivized experiment, we had subjects decide when to catch a bus using displays with textual uncertainty, uncertainty visualizations, or no-uncertainty (control). Frequency-based visualizations previously shown to allow people to better extract probabilities (quantile dotplots) yielded better decisions. Decisions with quantile dotplots with 50 outcomes were(1) better on average, having expected payoffs 97% of optimal(95% CI: [95%,98%]), 5 percentage points more than control (95% CI: [2,8]); and (2) more consistent, having within-subject standard deviation of 3 percentage points (95% CI:[2,4]), 4 percentage points less than control (95% CI: [2,6]).Cumulative distribution function plots performed nearly as well, and both outperformed textual uncertainty, which was sensitive to the probability interval communicated. We discuss implications for real time transit predictions and possible generalization to other domains.",Michael Fernandes;Logan Walls;Sean Munson;Jessica Hullman;Matthew Kay 0001,HM
CHI,2018,Self-Reflection and Personal Physicalization Construction,10.1145/3173574.3173728,"Self-reflection is a central goal of personal informatics systems, and constructing visualizations from physical tokens has been found to help people reflect on data. However, so far, constructive physicalization has only been studied in lab environments with provided datasets. Our qualitative study investigates the construction of personal physicalizations in people's domestic environments over 2-4 weeks. It contributes an understanding of (1) the process of creating personal physicalizations, (2) the types of personal insights facilitated, (3) the integration of self-reflection in the physicalization process, and (4) its benefits and challenges for self-reflection. We found that in constructive personal physicalization, data collection, construction and self-reflections are deeply intertwined. This extends previous models of visualization creation and data-driven self-reflection. We outline how benefits such as reflection through manual construction, personalization, and presence in everyday life can be transferred to a wider set of digital and physical systems.",Alice Thudt;Uta Hinrichs;Samuel Huron;Sheelagh Carpendale,
CHI,2018,Tangible Drops: A Visio-Tactile Display Using Actuated Liquid-Metal Droplets,10.1145/3173574.3173751,"We present Tangible Drops, a visio-tactile display that for the first time provides physical visualization and tactile feedback using a planar liquid interface. It presents digital information interactively by tracing dynamic patterns on horizontal flat surfaces using liquid metal drops on a programmable electrode array. It provides tactile feedback with directional information in the 2D vector plane using linear locomotion and/or vibration of the liquid metal drops. We demonstrate move, oscillate, merge, split and dispense-from-reservoir functions of the liquid metal drops by consuming low power (450 mW per electrode) and low voltage (8--15 V). We report on results of our empirical study with 12 participants on tactile feedback using 8 mm diameter drops, which indicate that Tangible Drops can convey tactile sensations such as changing speed, varying direction and controlled oscillation with no visual feedback. We present the design space and demonstrate the applications of Tangible Drops, and conclude by suggesting potential future applications for the technique.",Deepak Ranjan Sahoo;Timothy Neate;Yutaka Tokuda;Jennifer Pearson 0001;Simon Robinson 0001;Sriram Subramanian;Matt Jones 0001,
CHI,2018,Animated Edge Textures in Node-Link Diagrams: a Design Space and Initial Evaluation,10.1145/3173574.3173761,"Network edge data attributes are usually encoded using color, opacity, stroke thickness and stroke pattern, or some combination thereof. In addition to these static variables, it is also possible to animate dynamic particles flowing along the edges. This opens a larger design space of animated edge textures, featuring additional visual encodings that have potential not only in terms of visual mapping capacity but also playfulness and aesthetics. Such animated edge textures have been used in several commercial and design-oriented visualizations, but to our knowledge almost always in a relatively ad hoc manner. We introduce a design space and Web-based framework for generating animated edge textures, and report on an initial evaluation of particle properties - particle speed, pattern and frequency - in terms of visual perception.",Hugo Romat;Caroline Appert;Benjamin Bach;Nathalie Henry Riche;Emmanuel Pietriga,
CHI,2018,vrSocial: Toward Immersive Therapeutic VR Systems for Children with Autism,10.1145/3173574.3173778,"Social communication frequently includes nuanced nonverbal communication cues, including eye contact, gestures, facial expressions, body language, and tone of voice. This type of communication is central to face-to-face interaction, but can be challenging for children and adults with autism. Innovative technologies can provide support by augmenting human-delivered cuing and automated prompting. Specifically, immersive virtual reality (VR) offers an option to generalize social skill interventions by concretizing nonverbal information in real-time social interactions. In this work, we explore the design and evaluation of three nonverbal communication applications in immersive VR. The results of this work indicate that delivering real-time visualizations of proximity, speaker volume, and duration of one's speech is feasible in immersive VR and effective for real-time support for proximity regulation for children with autism. We conclude with design considerations for therapeutic VR systems.",LouAnne E. Boyd;Saumya Gupta;Sagar B. Vikmani;Carlos M. Gutierrez;Junxiang Yang;Erik Linstead;Gillian R. Hayes,
CHI,2018,DataInk: Direct and Creative Data-Oriented Drawing,10.1145/3173574.3173797,"Creating whimsical, personal data visualizations remains a challenge due to a lack of tools that enable for creative visual expression while providing support to bind graphical content to data. Many data analysis and visualization creation tools target the quick generation of visual representations, but lack the functionality necessary for graphics design. Toolkits and charting libraries offer more expressive power, but require expert programming skills to achieve custom designs. In contrast, sketching affords fluid experimentation with visual shapes and layouts in a free-form manner, but requires one to manually draw every single data point. We aim to bridge the gap between these extremes. We propose DataInk, a system supports the creation of expressive data visualizations with rigorous direct manipulation via direct pen and touch input. Leveraging our commonly held skills, coupled with a novel graphical user interface, DataInk enables direct, fluid, and flexible authoring of creative data visualizations.",Haijun Xia;Nathalie Henry Riche;Fanny Chevalier;Bruno Rodrigues De Araújo;Daniel Wigdor,HM
CHI,2018,CrowdLayout: Crowdsourced Design and Evaluation of Biological Network Visualizations,10.1145/3173574.3173806,"Biologists often perform experiments whose results generate large quantities of data, such as interactions between molecules in a cell, that are best represented as networks (graphs). To visualize these networks and communicate them in publications, biologists must manually position the nodes and edges of each network to reflect their real-world physical structure. This process does not scale well, and graph layout algorithms lack the biological underpinnings to offer a viable alternative. In this paper, we present CrowdLayout, a crowdsourcing system that leverages human intelligence and creativity to design layouts of biological network visualizations. CrowdLayout provides design guidelines, abstractions, and editing tools to help novice workers perform like experts. We evaluated CrowdLayout in two experiments with paid crowd workers and real biological network data, finding that crowds could both create and evaluate meaningful, high-quality layouts. We also discuss implications for crowdsourced design and network visualizations in other domains.",Divit P. Singh;Lee Lisle;T. M. Murali 0001;Kurt Luther,
CHI,2018,HomeFinder Revisited: Finding Ideal Homes with Reachability-Centric Multi-Criteria Decision Making,10.1145/3173574.3173821,"Finding an ideal home is a difficult and laborious process. One of the most crucial factors in this process is the reachability between the home location and the concerned points of interest, such as places of work and recreational facilities. However, such importance is unrecognized in the extant real estate systems. By characterizing user requirements and analytical tasks in the context of finding ideal homes, we designed ReACH, a novel visual analytics system that assists people in finding, evaluating, and choosing a home based on multiple criteria, including reachability. In addition, we developed an improved data-driven model for approximating reachability with massive taxi trajectories. This model enables users to interactively integrate their knowledge and preferences to make judicious and informed decisions. We show the improvements in our model by comparing the theoretical complexities with the prior study and demonstrate the usability and effectiveness of the proposed system with task-based evaluation.",Di Weng;Heming Zhu;Jie Bao 0003;Yu Zheng 0004;Yingcai Wu,
CHI,2018,Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay,10.1145/3173574.3173835,"In competitive co-located gameplay, players use their opponents' gaze to make predictions about their plans while simultaneously managing their own gaze to avoid giving away their plans. This socially competitive dimension is lacking in most online games, where players are out of sight of each other. We conducted a lab study using a strategic online game; finding that (1) players are better at discerning their opponent's plans when shown a live visualisation of the opponent's gaze, and (2) players who are aware that their gaze is tracked will manipulate their gaze to keep their intentions hidden. We describe the strategies that players employed, to various degrees of success, to deceive their opponent through their gaze behaviour. This gaze-based deception adds an effortful and challenging aspect to the competition. Lastly, we discuss the various implications of our findings and its applicability for future game design.",Joshua Newn;Fraser Allison;Eduardo Velloso;Frank Vetere,
CHI,2018,SpeechBubbles: Enhancing Captioning Experiences for Deaf and Hard-of-Hearing People in Group Conversations,10.1145/3173574.3173867,"Deaf and hard-of-hearing (DHH) individuals encounter difficulties when engaged in group conversations with hearing individuals, due to factors such as simultaneous utterances from multiple speakers and speakers whom may be potentially out of view. We interviewed and co-designed with eight DHH participants to address the following challenges: 1) associating utterances with speakers, 2) ordering utterances from different speakers, 3) displaying optimal content length, and 4) visualizing utterances from out-of-view speakers. We evaluated multiple designs for each of the four challenges through a user study with twelve DHH participants. Our study results showed that participants significantly preferred speechbubble visualizations over traditional captions. These design preferences guided our development of SpeechBubbles, a real-time speech recognition interface prototype on an augmented reality head-mounted display. From our evaluations, we further demonstrated that DHH participants preferred our prototype over traditional captions for group conversations.",Yi-Hao Peng;Ming-Wei Hsu;Paul Taele;Ting-Yu Lin;Po-En Lai;Leon Hsu;Tzu-Chuan Chen;Te-Yen Wu;Yu-An Chen;Hsien-Hui Tang;Mike Y. Chen,
CHI,2018,What's the Difference?: Evaluating Variations of Multi-Series Bar Charts for Visual Comparison Tasks,10.1145/3173574.3173878,"An increasingly common approach to data analysis involves using information dashboards to visually compare changing data. However, layout constraints coupled with varying levels of visualization literacy among dashboard users make facilitating visual comparison in dashboards a challenging task. In this paper, we evaluate variants of bar charts, one of the most prevalent class of charts used in dashboards. We report an online experiment (N = 74) conducted to evaluate four alternative designs: 1) grouped bar chart, 2) grouped bar chart with difference overlays, 3) bar chart with difference overlays, and 4) difference bar chart. Results show that charts with difference overlays facilitate a wider range of comparison tasks while performing comparably to charts without them on individual tasks. Finally, we discuss the implications of our findings, with a focus on supporting visual comparison in dashboards.",Arjun Srinivasan;Matthew Brehmer;Bongshin Lee;Steven Mark Drucker,
CHI,2018,Methods for Intentional Encoding of High Capacity Human-Designable Visual Markers,10.1145/3173574.3173887,"Previous techniques for human-designable visual markers have focused on small encoding spaces, and assume artists do not need to encode specific bit representations. We present a general framework for human-designable visual markers for artists to encode specific bit representations in large spaces. A three-part study, conducted over three weeks, methodically evaluates the usability of different encoding methods when artists encode specific bit representations. The methods span different shape characteristics suitable for artist encoding (convexity, hollowness, number, size, and distance from centroid) and visualization tools are proposed to aid in this process. We further demonstrate that any of the methods presented may be practically used to encode a URL with the aid of a universally available database like TinyURL (rather than a task-specific database), making human-designable visual markers practical for applications such as advertisements.",Joshua D. A. Jung;Daniel Vogel 0001,
CHI,2018,InfoNice: Easy Creation of Information Graphics,10.1145/3173574.3173909,"Information graphics are widely used to convey messages and present insights in data effectively. However, creating expressive data-driven infographics remains a great challenge for general users without design expertise. We present InfoNice, a visualization design tool that enables users to easily create data-driven infographics. InfoNice allows users to convert unembellished charts into infographics with multiple visual elements through mark customization. We implement InfoNice into Microsoft Power BI to demonstrate the integration of InfoNice into data analysis workflow seamlessly, bridging the gap between data exploration and presentation. We evaluate the usability and usefulness of InfoNice through example infographics, an in-lab user study, and real-world user feedback. Our results show that InfoNice enables users to create a variety of infographics easily for common scenarios.",Yun Wang 0012;Haidong Zhang;He Huang;Xi Chen;Qiufeng Yin;Zhitao Hou;Dongmei Zhang 0001;Qiong Luo 0001;Huamin Qu,
CHI,2018,Physical Keyboards in Virtual Reality: Analysis of Typing Performance and Effects of Avatar Hands,10.1145/3173574.3173919,"Entering text is one of the most common tasks when interacting with computing systems. Virtual Reality (VR) presents a challenge as neither the user's hands nor the physical input devices are directly visible. Hence, conventional desktop peripherals are very slow, imprecise, and cumbersome. We developed a apparatus that tracks the user's hands, and a physical keyboard, and visualize them in VR. In a text input study with 32 participants, we investigated the achievable text entry speed and the effect of hand representations and transparency on typing performance, workload, and presence. With our apparatus, experienced typists benefited from seeing their hands, and reach almost outside-VR performance. Inexperienced typists profited from semi-transparent hands, which enabled them to type just 5.6 WPM slower than with a regular desktop setup. We conclude that optimizing the visualization of hands in VR is important, especially for inexperienced typists, to enable a high typing performance.",Pascal Knierim;Valentin Schwind;Anna Maria Feit;Florian Nieuwenhuizen;Niels Henze,
CHI,2018,An Eye For Design: Gaze Visualizations for Remote Collaborative Work,10.1145/3173574.3173923,"In remote collaboration, gaze visualizations are designed to display where collaborators are looking in a shared visual space. This type of gaze-based intervention can improve coordination, however researchers have yet to fully explore different gaze visualization techniques and develop a deeper understanding of the ways in which features of visualizations may interact with task attributes to influence collaborative performance. There are many ways to visualize characteristics of eye movements, such as a path connecting fixation points or a heat map illustrating fixation duration and coverage. In this study, we designed and evaluated three unique gaze visualizations in a remote search task. Our results suggest that the design of gaze visualizations affects performance, coordination, searching behavior, and perceived utility. Additionally, the degree of task coupling further influences the effect of gaze visualizations on performance and coordination. We then reflect on the value of gaze visualizations for remote work and discuss implications for the design of gaze-based interventions.",Sarah D'Angelo;Darren Gergle,
CHI,2018,Dream Lens: Exploration and Visualization of Large-Scale Generative Design Datasets,10.1145/3173574.3173943,"This paper presents Dream Lens, an interactive visual analysis tool for exploring and visualizing large-scale generative design datasets. Unlike traditional computer aided design, where users create a single model, with generative design, users specify high-level goals and constraints, and the system automatically generates hundreds or thousands of candidates all meeting the design criteria. Once a large collection of design variations is created, the designer is left with the task of finding the design, or set of designs, which best meets their requirements. This is a complicated task which could require analyzing the structural characteristics and visual aesthetics of the designs. Two studies are conducted which demonstrate the usability and usefulness of the Dream Lens system, and a generatively designed dataset of 16,800 designs for a sample design problem is described and publicly released to encourage advancement in this area.",Justin Matejka;Michael Glueck;Erin Bradner;Ali Hashemi 0001;Tovi Grossman;George W. Fitzmaurice,
CHI,2018,ThermoKiosk: Investigating Roles for Digital Surveys of Thermal Experience in Workplace Comfort Management,10.1145/3173574.3173956,"Thermal comfort in shared workplaces is often contested and impacts productivity, wellbeing, and energy use. Yet, subjective and situated comfort experiences are rarely captured and engaged with. In this paper, we explore roles for digital surveys in capturing and visualising subjective experiences of comfort in situ for comfort management. We present findings from a 3-week field trial of our prototype system called ThermoKiosk, which we deployed in an open plan, shared office with a history of thermal comfort complaints. In interviews with occupants and members of facilities management, we find that the data and interactions can play an important role in initiating dialogue to understand and handle tensions, and point to design considerations for more systematically integrating them into workplace comfort practices.",Adrian K. Clear;Samantha Mitchell Finnigan;Patrick Olivier;Rob Comber,
CHI,2018,Using Animation to Alleviate Overdraw in Multiclass Scatterplot Matrices,10.1145/3173574.3173991,"The scatterplot matrix (SPLOM) is a commonly used technique for visualizing multiclass multivariate data. However, multiclass SPLOMs have issues with overdraw (overlapping points), and most existing techniques for alleviating overdraw focus on individual scatterplots with a single class. This paper explores whether animation using flickering points is an effective way to alleviate overdraw in these multiclass SPLOMs. In a user study with 69 participants, we found that users not only performed better at identifying dense regions using animated SPLOMs, but also found them easier to interpret and preferred them to static SPLOMs. These results open up new directions for future work on alleviating overdraw for multiclass SPLOMs, and provide insights for applying animation to alleviate overdraw in other settings.",Helen Chen;Sophie Engle;Alark Joshi;Eric D. Ragan;Beste F. Yuksel;Lane Harrison,
CHI,2018,More Text Please! Understanding and Supporting the Use of Visualization for Clinical Text Overview,10.1145/3173574.3173996,"Clinical practice is heavily reliant on the use of unstructured text to document patient stories due to its expressive and flexible nature. However, a physician's capacity to recover information from text for clinical overview is severely affected when records get longer and time pressure increases. Data visualization strategies have been explored to aid in information retrieval by replacing text with graphical summaries, though often at the cost of omitting important text features. This causes physician mistrust and limits real-world adoption. This work presents our investigation into the role and use of text in clinical practice, and reports on efforts to assess the best of both worlds---text and visualization---to facilitate clinical overview. We report on insights garnered from a field study, and the lessons learned from an iterative design process and evaluation of a text-visualization prototype, MedStory, with 14 medical professionals. The results led to a number of grounded design recommendations to guide visualization design to support clinical text overview.",Nicole Sultanum;Michael Brudno;Daniel Wigdor;Fanny Chevalier,HM
CHI,2018,Frames and Slants in Titles of Visualizations on Controversial Topics,10.1145/3173574.3174012,"Slanted framing in news article titles induce bias and influence recall. While recent studies found that viewers focus extensively on titles when reading visualizations, the impact of titles in visualization remains underexplored. We study frames in visualization titles, and how the slanted framing of titles and the viewer's pre-existing attitude impact recall, perception of bias, and change of attitude. When asked to compose visualization titles, people used five existing news frames, an open-ended frame, and a statistics frame. We found that the slant of the title influenced the perceived main message of a visualization, with viewers deriving opposing messages from the same visualization. The results did not show any significant effect on attitude change. We highlight the danger of subtle statistics frames and viewers' unwarranted conviction of the neutrality of visualizations. Finally, we present a design implication for the generation of visualization titles and one for the viewing of titles.",Ha Kyung Kong;Zhicheng Liu 0001;Karrie Karahalios,
CHI,2018,Investigating the Effect of the Multiple Comparisons Problem in Visual Analysis,10.1145/3173574.3174053,"The goal of a visualization system is to facilitate dataset-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they may arise from noise. We often compare visualizations to a mental image of what we are interested in: a particular trend, distribution or an unusual pattern. As more visualizations are examined and more comparisons are made, the probability of discovering spurious insights increases. This problem is well-known in Statistics as the multiple comparisons problem (MCP) but overlooked in visual analysis. We present a way to evaluate MCP in visualization tools by measuring the accuracy of user reported insights on synthetic datasets with known ground truth labels. In our experiment, over 60% of user insights were false. We show how a confirmatory analysis approach that accounts for all visual comparisons, insights and non-insights, can achieve similar results as one that requires a validation dataset.",Emanuel Zgraggen;Zheguang Zhao;Robert C. Zeleznik;Tim Kraska,
CHI,2018,Experiential Augmentation: Uncovering The Meaning of Qualitative Visualizations when Applied to Augmented Objects,10.1145/3173574.3174064,"As we move toward commercial usage of ubiquitous computing and augmented reality, it is important to think about how computing should communicate with us when it is distributed in our environment. This paper proposes that qualitative indexical visualizations based on learned understanding of physical phenomena (Experiential Augmentation) can enhance our interaction design language and aid digital interfaces in communicating in a real-world context. We present a study that gathers data on how participants interpret such visualizations, and propose a model with which to analyze their responses. Finally, we also give a set of design recommendations for those interested in creating similar augmentations.",Dixon Lo;Dan Lockton;Stacie Rohrbach,
CHI,2018,T-Cal: Understanding Team Conversational Data with Calendar-based Visualization,10.1145/3173574.3174074,"Understanding team communication and collaboration patterns is critical for improving work efficiency in organizations. This paper presents an interactive visualization system, T-Cal, that supports the analysis of conversation data from modern team messaging platforms (e.g., Slack). T-Cal employs a user-familiar visual interface, a calendar, to enable seamless multi-scale browsing of data from different perspectives. T-Cal also incorporates a number of analytical techniques for disentangling interleaving conversations, extracting keywords, and estimating sentiment. The design of T-Cal is based on an iterative user-centered design process including interview studies, requirements gathering, initial prototypes demonstration, and evaluation with domain users. The resulting two case studies indicate the effectiveness and usefulness of T-Cal in real-world applications, including daily conversations within an industry research lab and student group chats in a MOOC.",Siwei Fu;Jian Zhao 0010;Hao Fei Cheng;Haiyi Zhu;Jennifer Marlow,
CHI,2018,Uncertainty Visualization Influences how Humans Aggregate Discrepant Information,10.1145/3173574.3174079,"The number of sensors in our surroundings that provide the same information steadily increases. Since sensing is prone to errors, sensors may disagree. For example, a GPS-based tracker on the phone and a sensor on the bike wheel may provide discrepant estimates on traveled distance. This poses a user dilemma, namely how to reconcile the conflicting information into one estimate. We investigated whether visualizing the uncertainty associated with sensor measurements improves the quality of users' inference. We tested four visualizations with increasingly detailed representation of uncertainty. Our study repeatedly presented two sensor measurements with varying degrees of inconsistency to participants who indicated their best guess of the ""true"" value. We found that uncertainty information improves users' estimates, especially if sensors differ largely in their associated variability. Improvements were larger for information-rich visualizations. Based on our findings, we provide an interactive tool to select the optimal visualization for displaying conflicting information.",Miriam Greis;Aditi Joshi;Ken Singer;Albrecht Schmidt 0001;Tonja Machulla,
CHI,2018,CraftML: 3D Modeling is Web Programming,10.1145/3173574.3174101,"We explore web programming as a new paradigm for programmatic 3D modeling. Most existing approaches subscribe to the imperative programming paradigm. While useful, there exists a gulf of evaluation between procedural steps and the intended structure. We present CraftML, a language providing a declarative syntax where the code is the structure. CraftML offers a rich set of programming features familiar to web developers of all skill levels, such as tags, hyperlinks, document object model, cascade style sheet, JQuery, string interpolation, template engine, data injection, and scalable vector graphics. We develop an online IDE to support CraftML development, with features such as live preview, search, module import, and parameterization. Using examples and case studies, we demonstrate that CraftML offers a low floor for beginners to make simple designs, a high ceiling for experts to build complex computational models, and wide walls to support many application domains such as education, data physicalization, tactile graphics, assistive devices, and mechanical components.",Tom Yeh;Jeeeun Kim,
CHI,2018,Augmenting Code with In Situ Visualizations to Aid Program Understanding,10.1145/3173574.3174106,"Programmers must draw explicit connections between their code and runtime state to properly assess the correctness of their programs. However, debugging tools often decouple the program state from the source code and require explicitly invoked views to bridge the rift between program editing and program understanding. To unobtrusively reveal runtime behavior during both normal execution and debugging, we contribute techniques for visualizing program variables directly within the source code. We describe a design space and placement criteria for embedded visualizations. We evaluate our in situ visualizations in an editor for the Vega visualization grammar. Compared to a baseline development environment, novice Vega users improve their overall task grade by about 2 points when using the in situ visualizations and exhibit significant positive effects on their self-reported speed and accuracy.",Jane Hoffswell;Arvind Satyanarayan;Jeffrey Heer,
CHI,2018,Pictures Worth a Thousand Words: Reflections on Visualizing Personal Blood Glucose Forecasts for Individuals with Type 2 Diabetes,10.1145/3173574.3174112,"Type 2 Diabetes Mellitus (T2DM) is a common chronic condition that requires management of one's lifestyle, including nutrition. Critically, patients often lack a clear understanding of how everyday meals impact their blood glucose. New predictive analytics approaches can provide personalized mealtime blood glucose forecasts. While communicating forecasts can be challenging, effective strategies for doing so remain little explored. In this study, we conducted focus groups with 13 participants to identify approaches to visualizing personalized blood glucose forecasts that can promote diabetes self-management and understand key styles and visual features that resonate with individuals with diabetes. Focus groups demonstrated that individuals rely on simple heuristics and tend to take a reactive approach to their health and nutrition management. Further, the study highlighted the need for simple and explicit, yet information-rich design. Effective visualizations were found to utilize common metaphors alongside words, numbers, and colors to convey a sense of authority and encourage action and learning.",Pooja M. Desai;Matthew E. Levine;David J. Albers;Lena Mamykina,
CHI,2018,What Moves Players?: Visual Data Exploration of Twitter and Gameplay Data,10.1145/3173574.3174134,"In recent years, microblogging platforms have not only become an important communication channel for the game industry to generate and uphold audience interest but also a rich resource for gauging player opinion. In this paper we use data gathered from Twitter to examine which topics matter to players and to identify influential members of a game's community. By triangulating in-game data with Twitter activity we explore how tweets can provide contextual information for understanding fluctuations in in-game activity. To facilitate analysis of the data we introduce a visual data exploration tool and use it to analyze tweets related to the game Destiny. In total, we collected over one million tweets from about 250,000 users over a 14-month period and gameplay data from roughly 3,500 players over a six-month period.",Christian Drescher;Guenter Wallner;Simone Kriglstein;Rafet Sifa;Anders Drachen;Margit Pohl,
CHI,2018,Visualizing API Usage Examples at Scale,10.1145/3173574.3174154,"Using existing APIs properly is a key challenge in programming, given that libraries and APIs are increasing in number and complexity. Programmers often search for online code examples in Q&A forums and read tutorials and blog posts to learn how to use a given API. However, there are often a massive number of related code examples and it is difficult for a user to understand the commonalities and variances among them, while being able to drill down to concrete details. We introduce an interactive visualization for exploring a large collection of code examples mined from open-source repositories at scale. This visualization summarizes hundreds of code examples in one synthetic code skeleton with statistical distributions for canonicalized statements and structures enclosing an API call. We implemented this interactive visualization for a set of Java APIs and found that, in a lab study, it helped users (1) answer significantly more API usage questions correctly and comprehensively and (2) explore how other programmers have used an unfamiliar API.",Elena L. Glassman;Tianyi Zhang 0001;Björn Hartmann;Miryung Kim,
CHI,2018,TopicOnTiles: Tile-Based Spatio-Temporal Event Analytics via Exclusive Topic Modeling on Social Media,10.1145/3173574.3174157,"Detecting anomalous events of a particular area in a timely manner is an important task. Geo-tagged social media data are useful resource for this task; however, the abundance of everyday language in them makes this task still challenging. To address such challenges, we present TopicOnTiles, a visual analytics system that can reveal information relevant to anomalous events in a multi-level tile-based map interface by using social media data. To this end, we adopt and improve a recently proposed topic modeling method that can extract spatio-temporally exclusive topics corresponding to a particular region and a time point. Furthermore, we utilize a tile-based map interface to efficiently handle large-scale data in parallel. Our user interface effectively highlights anomalous tiles using our novel glyph visualization that encodes the degree of anomaly computed by our exclusive topic modeling processes. To show the effectiveness of our system, we present several usage scenarios using real-world datasets as well as comprehensive user study results.",Minsuk Choi;Dear Sungbok Shin;Jinho Choi 0005;Scott Langevin;Christopher Bethune;Philippe Horne;Nathan Kronenfeld;Ramakrishnan Kannan;Barry L. Drake;Haesun Park;Jaegul Choo,
CHI,2018,Beagle: Automated Extraction and Interpretation of Visualizations from the Web,10.1145/3173574.3174168,"""How common is interactive visualization on the web?"" ""What is the most popular visualization design?"" ""How prevalent are pie charts really?"" These questions intimate the role of interactive visualization in the real (online) world. In this paper, we present our approach (and findings) to answering these questions. First, we introduce Beagle, which mines the web for SVG-based visualizations and automatically classifies them by type (i.e., bar, pie, etc.). With Beagle, we extract over 41,000 visualizations across five different tools and repositories, and classify them with 85% accuracy, across 24 visualization types. Given this visualization collection, we study usage across tools. We find that most visualizations fall under four types: bar charts, line charts, scatter charts, and geographic maps. Though controversial, pie charts are relatively rare for the visualization tools that were studied. Our findings also suggest that the total visualization types supported by a given tool could factor into its ease of use. However this effect appears to be mitigated by providing a variety of diverse expert visualization examples to users.",Leilani Battle;Peitong Duan;Zachery Miranda;Dana Mukusheva;Remco Chang;Michael Stonebraker,
CHI,2018,c.light: A Tool for Exploring Light Properties in Early Design Stage,10.1145/3173574.3174176,"Although a light becomes an important design element, there are little techniques available to explore shapes and light effects in early design stages. We present c.light, a design tool that consists of a set of modules and a mobile application for visualizing the light in a physical world. It allows designers to easily fabricate both tangible and intangible properties of a light without a technical barrier. We analyzed how c.light contributes to the ideation process of light design through a workshop. The results showed that c.light largely expands designers' capability to manipulate intangible properties of light and, by doing so, it facilitates collaborative and inverted ideation process in early design stages. It is expected that the results of this study could enhance our understanding of how designers manipulate light in a physical world in early design stages and could be a good stepping stone for future tool development.",Kyeong-Ah Jeong;EunJin Kim;Taesu Kim;Hyeon-Jeong Suk,
CHI,2018,A Visual Interaction Framework for Dimensionality Reduction Based Data Exploration,10.1145/3173574.3174209,"Dimensionality reduction is a common method for analyzing and visualizing high-dimensional data. However, reasoning dynamically about the results of a dimensionality reduction is difficult. Dimensionality-reduction algorithms use complex optimizations to reduce the number of dimensions of a dataset, but these new dimensions often lack a clear relation to the initial data dimensions, thus making them difficult to interpret. Here we propose a visual interaction framework to improve dimensionality-reduction based exploratory data analysis. We introduce two interaction techniques, forward projection and backward projection, for dynamically reasoning about dimensionally reduced data. We also contribute two visualization techniques, prolines and feasibility maps, to facilitate the effective use of the proposed interactions. We apply our framework to PCA and autoencoder-based dimensionality reductions. Through data-exploration examples, we demonstrate how our visual interactions can improve the use of dimensionality reduction in exploratory data analysis.",Marco Cavallo;Çagatay Demiralp,
CHI,2018,Considering Agency and Data Granularity in the Design of Visualization Tools,10.1145/3173574.3174212,"Previous research has identified trade-offs when it comes to designing visualization tools. While constructive ""bottom-up' tools promote a hands-on, user-driven design process that enables a deep understanding and control of the visual mapping, automated tools are more efficient and allow people to rapidly explore complex alternative designs, often at the cost of transparency. We investigate how to design visualization tools that support a user-driven, transparent design process while enabling efficiency and automation, through a series of design workshops that looked at how both visualization experts and novices approach this problem. Participants produced a variety of solutions that range from example-based approaches expanding constructive visualization to solutions in which the visualization tool infers solutions on behalf of the designer, e.g., based on data attributes. On a higher level, these findings highlight agency and granularity as dimensions that can guide the design of visualization tools in this space.",Gonzalo Gabriel Méndez;Miguel A. Nacenta;Uta Hinrichs,
CHI,2017,Understanding Concept Maps: A Closer Look at How People Organise Ideas,10.1145/3025453.3025977,"Research into creating visualisations that organise ideas into concise concept maps often focuses on implicit mathematical and statistical theories which are built around algorithmic efficacy or visual complexity. Although there are multiple techniques which attempt to mathematically optimise this multi-dimensional problem, it is still unknown how to create concept maps that are immediately understandable to people. In this paper, we present an in-depth qualitative study observing the behaviour and discussing the strategy used by non-expert participants to create, interact, update and communicate a concept map that represents a collection of research ideas. Our results show non-expert individuals create concept maps differently to visualisation algorithms. We found that our participants prioritised narrative, landmarks, abstraction, clarity, and simplicity. Finally, we derive design recommendations from our results which we hope will inspire future algorithms that automatically create more usable and compelling concept maps better suited to the natural behaviours and needs of users.",Stefano Padilla;Thomas S. Methven;David A. Robb 0001;Mike J. Chantler,
CHI,2017,"Bottom-up vs. Top-down: Trade-offs in Efficiency, Understanding, Freedom and Creativity with InfoVis Tools",10.1145/3025453.3025942,"The emergence of tools that support fast-and-easy visualization creation by non-experts has made the benefits of InfoVis widely accessible. Key features of these tools include attribute-level operations, automated mappings, and visualization templates. However, these features shield people from lower-level visualization design steps, such as the specific mapping of data points to visuals. In contrast, recent research promotes constructive visualization where individual data units and visuals are directly manipulated. We present a qualitative study comparing people's visualization processes using two visualization tools: one promoting a top-down approach to visualization construction (Tableau Desktop) and one implementing a bottom-up constructive visualization approach (iVoLVER). Our results show how the two approaches influence: 1) the visualization process, 2) decisions on the visualization design, 3) the feeling of control and authorship, and 4) the willingness to explore alternative designs. We discuss the complex trade-offs between the two approaches and outline considerations for designing better visualization tools.",Gonzalo Gabriel Méndez;Uta Hinrichs;Miguel A. Nacenta,
CHI,2017,What Happened in my Home?: An End-User Development Approach for Smart Home Data Visualization,10.1145/3025453.3025485,"Smart home systems change the way we experience the home. While there are established research fields within HCI for visualizing specific use cases of a smart home, studies targeting user demands on visualizations spanning across multiple use cases are rare. Especially, individual data-related demands pose a challenge for usable visualizations. To investigate potentials of an end-user development (EUD) approach for flexibly supporting such demands, we developed a smart home system featuring both pre-defined visualizations and a visualization creation tool. To evaluate our concept, we installed our prototype in 12 households as part of a Living Lab study. Results are based on three interview studies, a design workshop and system log data. We identified eight overarching interests in home data and show how participants used pre-defined visualizations to get an overview and the creation tool to not only address specific use cases but also to answer questions by creating temporary visualizations.",Nico Castelli;Corinna Ogonowski;Timo Jakobi;Martin Stein;Gunnar Stevens;Volker Wulf,
CHI,2017,PathViewer: Visualizing Pathways through Student Data,10.1145/3025453.3025819,"Analysis of student data is critical for improving education. In particular, educators need to understand what approaches their students are taking to solve a problem. However, identifying student strategies and discovering areas of confusion is difficult because an educator may not know what queries to ask or what patterns to look for in the data. In this paper, we present a visualization tool, PathViewer, to model the paths that students follow when solving a problem. PathViewer leverages ideas from flow diagrams and natural language processing to visualize the sequences of intermediate steps that students take. Using PathViewer, we analyzed how several students solved a Python assignment, discovering interesting and unexpected patterns. Our results suggest that PathViewer can allow educators to quickly identify areas of interest, drill down into specific areas, and identify student approaches to the problem as well as misconceptions they may have.",Yiting Wang;Walker M. White;Erik Andersen 0001,
CHI,2017,AVUI: Designing a Toolkit for Audiovisual Interfaces,10.1145/3025453.3026042,"The combined use of sound and image has a rich history, from audiovisual artworks to research exploring the potential of data visualization and sonification. However, we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly for live performance. We propose the AVUI (AudioVisual User Interface), where sound and image are used together in a cohesive way in the interface; and an enabling technology, the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were developed in a three-stage process, together with AV producers: 1) participatory design activities; 2) prototype development; 3) encapsulation of prototype as a plug-in, evaluation, and roll out. Best practices identified include: reconfigurable interfaces and mappings; object-oriented packaging of AV and UI; diverse sound visualization; flexible media manipulation and management. The toolkit and a mobile app developed using it have been released as open-source. Guidelines and toolkit demonstrate the potential of AVUI and offer designers a convenient framework for AV interaction design.",Nuno N. Correia;Atau Tanaka,
CHI,2017,Empirical Analysis of the Subjective Impressions and Objective Measures of Domain Scientists' Visual Analytic Judgments,10.1145/3025453.3025882,"Scientists often use specific data analysis and presentation methods familiar within their domain. But does high familiarity drive better analytical judgment? This question is especially relevant when familiar methods themselves can have shortcomings: many visualizations used conventionally for scientific data analysis and presentation do not follow established best practices. This necessitates new methods that might be unfamiliar yet prove to be more effective. But there is little empirical understanding of the relationships between scientists' subjective impressions about familiar and unfamiliar visualizations and objective measures of their visual analytic judgments. To address this gap and to study these factors, we focus on visualizations used for comparison of climate model performance. We report on a comprehensive survey-based user study with 47 climate scientists and present an analysis of: i) relationships among scientists' familiarity, their perceived levels of comfort, confidence, accuracy, and objective measures of accuracy, and ii) relationships among domain experience, visualization familiarity, and post-study preference.",Aritra Dasgupta;Susannah Burrows;Kyungsik Han;Philip J. Rasch,
CHI,2017,Building with Data: Architectural Models as Inspiration for Data Physicalization,10.1145/3025453.3025850,"In this paper we analyze the role of physical scale models in the architectural design process and apply insights from architecture for the creation and use of data physicalizations. Based on a survey of the architecture literature on model making and ten interviews with practicing architects, we describe the role of physical models as a tool for exploration and communication. From these observations, we identify trends in the use of physical models in architecture, which have the potential to inform the design of data physicalizations. We identify four functions of architectural modeling that can be directly adapted for use in the process of building rich data models. Finally, we discuss how the visualization community can apply observations from architecture to the design of new data physicalizations.",Carmen Hull;Wesley Willett,
CHI,2017,Designing Game-Based Myoelectric Prosthesis Training,10.1145/3025453.3025676,"A myoelectric prosthesis (myo) is a dexterous artificial limb controlled by muscle contractions. Learning to use a myo can be challenging, so extensive training is often required to use a myo prosthesis effectively. Signal visualizations and simple muscle-controlled games are currently used to help patients train their muscles, but are boring and frustrating. Furthermore, current training systems require expensive medical equipment and clinician oversight, restricting training to infrequent clinical visits. To address these limitations, we developed a new game that promotes fun and success, and shows the viability of a low-cost myoelectric input device. We adapted a user-centered design (UCD) process to receive feedback from patients, clinicians, and family members as we iteratively addressed challenges to improve our game. Through this work, we introduce a free and open myo training game, provide new information about the design of myo training games, and reflect on an adapted UCD process for the practical iterative development of therapeutic games.",Aaron Tabor;Scott Bateman;Erik J. Scheme;David R. Flatla;Kathrin Gerling,
CHI,2017,Affective Color in Visualization,10.1145/3025453.3026041,"Communicating the right affect, a feeling, experience or emotion, is critical in creating engaging visual communication. We carried out three studies examining how different color properties (lightness, chroma and hue) and different palette properties (combinations and distribution of colors) contribute to different affective interpretations in information visualization where the numbers of colors is typically smaller than the rich palettes used in design. Our results show how color and palette properties can be manipulated to achieve affective expressiveness even in the small sets of colors used for data encoding in information visualization.",Lyn Bartram;Abhisekh Patra;Maureen C. Stone,
CHI,2017,Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data,10.1145/3025453.3025592,"Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support learning. We present multiple graphically-based techniques for eliciting and incorporating a user's prior knowledge about data into visualization interaction. We use controlled experiments to evaluate how graphically eliciting forms of prior knowledge and presenting feedback on the gap between prior knowledge and the observed data impacts a user's ability to recall and understand the data. We find that participants who are prompted to reflect on their prior knowledge by predicting and self-explaining data outperform a control group in recall and comprehension. These effects persist when participants have moderate or little prior knowledge on the datasets. We discuss how the effects differ based on text versus visual presentations of data. We characterize the design space of graphical prediction and feedback techniques and describe design recommendations.",Yea-Seul Kim;Katharina Reinecke;Jessica Hullman,
CHI,2017,Regression by Eye: Estimating Trends in Bivariate Visualizations,10.1145/3025453.3025922,"Observing trends and predicting future values are common tasks for viewers of bivariate data visualizations. As many charts do not explicitly include trend lines or related statistical summaries, viewers often visually estimate trends directly from a plot. How reliable are the inferences viewers draw when performing such regression by eye? Do particular visualization designs or data features bias trend perception? We present a series of crowdsourced experiments that assess the accuracy of trends estimated using regression by eye across a variety of bivariate visualizations, and examine potential sources of bias in these estimations. We find that viewers accurately estimate trends in many standard visualizations of bivariate data, but that both visual features (e.g., ""within-the-bar"" bias) and data features (e.g., the presence of outliers) can result in visual estimates that systematically diverge from standard least-squares regression models.",Michael Correll;Jeffrey Heer,
CHI,2017,Evaluating Perceptually Complementary Views for Network Exploration Tasks,10.1145/3025453.3026024,"We explore the relative merits of matrix, node-link and combined side-by-side views for the visualisation of weighted networks with three controlled studies: (1) finding the most effective visual encoding for weighted edges in matrix representations; (2) comparing matrix, node-link and combined views for static weighted networks; and (3) comparing MatrixWave, Sankey and combined views of both for event-sequence data. Our studies underline that node-link and matrix views are suited to different analysis tasks. For the combined view, our studies show that there is a perceptually complementary effect in terms of improved accuracy for some tasks, but that there is a cost in terms of longer completion time than the faster of the two techniques alone. Eye-movement data shows that for many tasks participants strongly favour one of the two views, after trying both in the training phase.",Chunlei Chang;Benjamin Bach;Tim Dwyer;Kim Marriott,
CHI,2017,The Catch(es) with Smart Home: Experiences of a Living Lab Field Study,10.1145/3025453.3025799,"Smart home systems are becoming an integral feature of the emerging home IT market. Under this general term, products mainly address issues of security, energy savings and comfort. Comprehensive systems that cover several use cases are typically operated and managed via a unified dashboard. Unfortunately, research targeting user experience (UX) design for smart home interaction that spans several use cases or covering the entire system is scarce. Furthermore, existing comprehensive and user-centered longterm studies on challenges and needs throughout phases of information collection, installation and operation of smart home systems are technologically outdated. Our 18-month Living Lab study covering 14 households equipped with smart home technology provides insights on how to design for improving smart home appropriation. This includes a stronger sensibility for household practices during setup and configuration, flexible visualizations for evolving demands and an extension of smart home beyond the location.",Timo Jakobi;Corinna Ogonowski;Nico Castelli;Gunnar Stevens;Volker Wulf,
CHI,2017,Pressure-Based Gain Factor Control for Mobile 3D Interaction using Locally-Coupled Devices,10.1145/3025453.3025890,"We present the design and evaluation of pressure-based interactive control of 3D navigation precision. Specifically, we examine the control of gain factors in tangible 3D interactions using locally-coupled mobile devices. By focusing on pressure as a separate input channel we can adjust gain factors independently from other input modalities used in 3D navigation, in particular for the exploration of 3D visualisations. We present two experiments. First, we determined that people strongly preferred higher pressures to be mapped to higher gain factors. Using this mapping, we compared pressure with rate control, velocity control, and slider-based control in a second study. Our results show that pressure-based gain control allows people to be more precise in the same amount of time compared to established input modalities. Pressure-based control was also clearly preferred by our participants. In summary, we demonstrate that pressure facilitates effective and efficient precision control for mobile 3D navigation.",Lonni Besançon;Mehdi Ammi;Tobias Isenberg 0001,
CHI,2017,Scalable Annotation of Fine-Grained Categories Without Experts,10.1145/3025453.3025930,"We present a crowdsourcing workflow to collect image annotations for visually similar synthetic categories without requiring experts. In animals, there is a direct link between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar to other collies (e.g. smooth collie) than a greyhound (another type of dog). However, in synthetic categories such as cars, objects with similar taxonomy can have very different appearance: e.g. a 2011 Ford F-150 Supercrew-HD looks the same as a 2011 Ford F-150 Supercrew-LL but very different from a 2011 Ford F-150 Supercrew-SVT. We introduce a graph based crowdsourcing algorithm to automatically group visually indistinguishable objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon Mechanical Turk workers; resulting in the largest fine-grained visual dataset reported to date with 2,657 categories of cars annotated at 1/20th the cost of hiring experts.",Timnit Gebru;Jonathan Krause;Jia Deng 0001;Li Fei-Fei 0001,
CHI,2017,Live Physiological Sensing and Visualization Ecosystems: An Activity Theory Analysis,10.1145/3025453.3025987,"Wearable sensing poses new opportunities to enhance personal connections to learning and authentic scientific inquiry experiences. In our work, we leverage the body and physical action as an engaging platform for learning through live physiological sensing and visualization (LPSV). Prior research suggests the potential of this approach, but was limited to single-session evaluations in informal environments. In this paper, we examine LPSV tools in a classroom environment during a four-day deployment. To highlight the complex interconnections between space, teachers, curriculum, and tool use, we analyze our data through the lens of Activity Theory. Our findings show the importance of integrating model-based representations for supporting exploration and analytic representations for scaffolding scientific inquiry. Activity Theory highlights leveraging life-relevant connections available within a physical space and considering policies and norms related to learners' physical bodies.",Tamara L. Clegg;Leyla Norooz;Seokbin Kang;Virginia Byrne;Monica Katzen;Rafael Valez;Angelisa C. Plane;Vanessa Oguamanam;Thomas Outing;Jason C. Yip 0001;Elizabeth M. Bonsignore;Jon Froehlich,
CHI,2017,GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing,10.1145/3025453.3025866,"We present GraphScape, a directed graph model of the vi- sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep- resent edits that transform one chart to another. We weight edges with an estimated cost of the difficulty of interpreting a target visualization given a source visualization. We con- tribute (1) a method for deriving transition costs via a partial ordering of edit operations and the solution of a resulting lin- ear program, and (2) a global weighting term that rewards consistency across transition subsequences. In a controlled experiment, subjects rated visualization sequences covering a taxonomy of common transition types. In all but one case, GraphScape's highest-ranked suggestion aligns with subjects' top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically sequence visualization presen- tations, elaborate transition paths between visualizations, and recommend design alternatives (e.g., to improve scalability while minimizing design changes).",Younghoon Kim;Kanit Wongsuphasawat;Jessica Hullman;Jeffrey Heer,
CHI,2017,GIAnT: Visualizing Group Interaction at Large Wall Displays,10.1145/3025453.3026006,"Large interactive displays are increasingly important and a relevant research topic, and several studies have focused on wall interaction. However, in many cases, thorough user studies currently require time-consuming video analysis and coding. We present the Group Interaction Analysis Toolkit GIAnT, which provides a rich set of visualizations supporting investigation of multi-user interaction at large display walls. GIAnT focuses on visualizing time periods, making it possible to gain overview-level insights quickly. The toolkit is designed to be extensible and features several carefully crafted visualizations: A novel timeline visualization shows movement in front of the wall over time, a wall visualization shows interactions on the wall and gaze data, and a floor visualization displays user positions. In addition, GIAnT shows the captured video stream along with basic statistics. We validate our tool by analyzing how it supports investigating major research topics and by practical use in evaluating a cooperative game.",Ulrich von Zadow;Raimund Dachselt,
CHI,2017,Voyager 2: Augmenting Visual Analysis with Partial View Specifications,10.1145/3025453.3025768,"Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders can encourage broad coverage, but irrelevant suggestions may distract users once they commit to specific questions. We present Voyager 2, a mixed-initiative system that blends manual and automated chart specification to help analysts engage in both open-ended exploration and targeted question answering. We contribute two partial specification interfaces: wildcards let users specify multiple charts in parallel, while related views suggest visualizations relevant to the currently specified chart. We present our interface design and applications of the CompassQL visualization query language to enable these interfaces. In a controlled study we find that Voyager 2 leads to increased data field coverage compared to a traditional specification tool, while still allowing analysts to flexibly drill-down and answer specific questions.",Kanit Wongsuphasawat;Zening Qu;Dominik Moritz;Riley Chang;Felix Ouk;Anushka Anand;Jock D. Mackinlay;Bill Howe;Jeffrey Heer,
CHI,2017,TouchPivot: Blending WIMP & Post-WIMP Interfaces for Data Exploration on Tablet Devices,10.1145/3025453.3025752,"Recent advancements in tablet technology pose a great opportunity for information visualization to expand its horizons beyond desktops. In this paper, we present TouchPivot, a novel interface that assists visual data exploration on tablet devices. With novices in mind, TouchPivot supports data transformations, such as pivoting and filtering, with simple pen and touch interactions, and facilitates understanding of the transformations through tight coupling between a data table and visualization. We bring in WIMP interfaces to TouchPivot, leveraging their familiarity and accessibility to novices. We report on a user study conducted to compare TouchPivot with two commercial interfaces, Tableau and Microsoft Excel's PivotTable. Our results show that novices not only answered data-driven questions faster, but also created a larger number of meaningful charts during freeform exploration with TouchPivot than others. Finally, we discuss the main hurdles novices encountered during our study and possible remedies for them.",Jaemin Jo;Sehi L'Yi;Bongshin Lee;Jinwook Seo,
CHI,2017,Supporting Community Health Workers in India through Voice- and Web-Based Feedback,10.1145/3025453.3025514,"Our research aims to support community health workers (CHWs) in low-resource settings by providing them with personalized information regarding their work. This information is delivered through a combination of voice- and web-based feedback that is derived from data already collected by CHWs. We describe the in situ participatory design approach used to create usable and appropriate feedback for low-literate CHWs and present usage data from a 12-month study with 71 CHWs in India. We show how the system supported and motivated CHWs, and how they used both the web- and voice-based systems, and each of the visualizations, for different reasons. We also show that the comparative feedback provided by the system introduced elements of competition that discouraged some CHWs while motivating others. Taken together, our findings suggest that providing personalized voice- and web-based feedback could be an effective way to support and motivate CHWs in low-resource settings.",Brian DeRenzi;Nicola Dell;Jeremy Wacksman;Scott Lee;Neal Lesh,
CHI,2017,"Trust, but Verify: Optimistic Visualizations of Approximate Queries for Exploring Big Data",10.1145/3025453.3025456,"Analysts need interactive speed for exploratory analysis, but big data systems are often slow. With sampling, data systems can produce approximate answers fast enough for exploratory visualization, at the cost of accuracy and trust. We propose optimistic visualization, which approaches these issues from a user experience perspective. This method lets analysts explore approximate results interactively, and provides a way to detect and recover from errors later. Pangloss implements these ideas. We discuss design issues raised by optimistic visualization systems. We test this concept with five expert visualizers in a laboratory study and three case studies at Microsoft. Analysts reported that they felt more confident in their results, and used optimistic visualization to check that their preliminary results were correct.",Dominik Moritz;Danyel Fisher;Bolin Ding;Chi Wang 0001,
CHI,2017,iSphere: Focus+Context Sphere Visualization for Interactive Large Graph Exploration,10.1145/3025453.3025628,"Interactive exploration plays a critical role in large graph visualization. Existing techniques, such as zoom-and-pan on a 2D plane and hyperbolic browser facilitate large graph exploration by showing both the details of a focal area and its surrounding context that guides the exploration process. However, existing techniques for large graph exploration are limited in either providing too little context or presenting graphs with too much distortion. In this paper, we propose a novel focus+context technique, iSphere, to address the limitation. iSphere maps a large graph onto a Riemann Sphere that better preserves graph structures and shows greater context information. We conduct extensive experiment studies on different graph exploration tasks under various conditions. The results show that iSphere performs the best in task completion time compared to the baseline techniques in link and path exploration tasks. This research also contributes to understanding large graph exploration on small screens.",Fan Du;Nan Cao 0001;Yu-Ru Lin;Panpan Xu;Hanghang Tong,
CHI,2017,Supporting Making Fixations and the Effect on Gaze Gesture Performance,10.1145/3025453.3025920,"Gaze gestures are deliberate patterns of eye movements that can be used to invoke commands. These are less reliant on accurate measurement and calibration than other gaze-based interaction techniques. These may be used with wearable displays fitted with eye tracking capability, or as part of an assistive technology. The visual stimuli in the information on the display that can act as fixation targets may or may not be sparse and will vary over time. The paper describes an experiment to investigate how the amount of information provided on a display to assist making fixations affects gaze gesture performance. The impact of providing visualization guides and small fixation targets on the time to complete gestures and error rates is presented. The number and durations of fixations made during gesture completion is used to explain differences in performance as a result of practice and direction of eye movement.",Howell O. Istance;Aulikki I. Hyrskykari,
CHI,2017,PersaLog: Personalization of News Article Content,10.1145/3025453.3025631,"Content personalization automatically modifying text and multimedia features within articles based on the reader's individual features'is evolving as a new form of journalism. Informed by constraints articulated through a survey of journalists, we have implemented PersaLog, a novel system for creating personalized content (e.g., text and interactive visualizations). Because crafting, and validating, personalized content can be challenging to scale across articles (unlike feed personalization), we offer a simple Domain Specific Language (DSL), and editing environment, to support this task. PersaLog is particularly designed to support the personalization of existing text and visualizations. Our work provides guidelines for personalization as well as a system that allows for both subtle and dramatic personalization-driven content changes. We validate PersaLog using case and lab studies.",Eytan Adar;Carolyn Gearig;Ayshwarya Balasubramanian;Jessica Hullman,
CHI,2017,Effects of Sharing Physiological States of Players in a Collaborative Virtual Reality Gameplay,10.1145/3025453.3026028,"Interfaces for collaborative tasks, such as multiplayer games can enable more effective and enjoyable collaboration. However, in these systems, the emotional states of the users are often not communicated properly due to their remoteness from one another. In this paper, we investigate the effects of showing emotional states of one collaborator to the other during an immersive Virtual Reality (VR) gameplay experience. We created two collaborative immersive VR games that display the real-time heart-rate of one player to the other. The two different games elicited different emotions, one joyous and the other scary. We tested the effects of visualizing heart-rate feedback in comparison with conditions where such a feedback was absent. The games had significant main effects on the overall emotional experience.",Arindam Dey 0001;Thammathip Piumsomboon;Youngho Lee;Mark Billinghurst,
CHI,2017,"Is Two Enough?: ! Studying Benefits, Barriers, and Biases of Multi-Tablet Use for Collaborative Visualization",10.1145/3025453.3025537,"A sizable part of HCI research on cross-device interaction is driven by the vision of users conducting complex knowledge work seamlessly across multiple mobile devices. This is based on the Weiserian assumption that people will be inclined to distribute their work across multiple ``pads' if such are available. We observed that this is not the reality today, even when devices were in abundance. We present a study with 24 participants in 12 dyads completing a collaborative visualization task with up to six tablets. They could choose between three different visualization types to answer questions about economic data. Tasks were designed to afford simultaneous use of tablets, either with linked or independent views. We found that users typically utilized only one tablet per user. A quantitative and qualitative analysis revealed a ``legacy bias' that introduced barriers for using more tablets and reduced the overall benefit of multi-device visualization.",Thomas Plank;Hans-Christian Jetter;Roman Rädle;Clemens Nylandsted Klokmose;Thomas Luger;Harald Reiterer,
CHI,2017,Has Instagram Fundamentally Altered the 'Family Snapshot'?,10.1145/3025453.3025928,"This paper considers how parents use the social media platform Instagram to facilitate the capture, curation and sharing of 'family snapshots'. Our work draws upon established cross-disciplinary literature relating to film photography and the composition of family albums in order to establish whether social media has changed the way parents visually present their families. We conducted a qualitative visual analysis of a sample of 4,000 photographs collected from Instagram using hashtags relating to children and parenting. We show that the style and composition of snapshots featuring children remains fundamentally unchanged and continues to be dominated by rather bland and idealised images of the happy family and the cute child. In addition, we find that the frequent taking and sharing of photographs via Instagram has inevitably resulted in a more mundane visual catalogue of daily life. We note a tension in the desire to use social media as a means to evidence good parenting, while trying to effectively manage the social identity of the child and finally, we note the reluctance of parents to use their own snapshots to portray family tension or disharmony, but their willingness to use externally generated content for this purpose.",Effie Le Moignan;Shaun W. Lawson;Duncan A. Rowland;Jamie Mahoney;Pam Briggs,
CHI,2017,Showing People Behind Data: Does Anthropomorphizing Visualizations Elicit More Empathy for Human Rights Data?,10.1145/3025453.3025512,"We investigate the impact of using anthropomorphized data graphics over standard charts on viewers' empathy for, and prosocial behavior toward suffering populations, in the context of human rights narratives. We present a series of experiments conducted on Amazon Mechanical Turk, in which we compare various forms of anthropomorphized data graphics-ranging from a single human figure that ""fills up"" to show proportional data, to separated groups of individual human beings-with a standard chart baseline. Each experiment uses two carefully crafted human rights data-driven stories to present the graphics. Contrary to our expectations, we consistently find that anthropomorphized data graphics and standard charts have very similar effects on empathy and prosocial behavior.",Jeremy Boy;Anshul Vikram Pandey;John Emerson;Margaret Satterthwaite;Oded Nov;Enrico Bertini,
CHI,2017,Narratives in Crowdsourced Evaluation of Visualizations: A Double-Edged Sword?,10.1145/3025453.3025870,"We explore the effects of providing task context when evaluating visualization tools using crowdsourcing. We gave crowdsource workers i) abstract information visualization tasks without any context, ii) tasks where we added semantics to the dataset, and iii) tasks with two types of backstory narratives: an analytic narrative and a decision-making narrative. Contrary to our expectations, we did not find evidence that adding data semantics increases accuracy, and further found that our backstory narratives can even decrease accuracy. Adding dataset semantics can however increase attention and provide subjective benefits in terms of confidence, perceived easiness, task enjoyability and perceived usefulness of the visualization. Nevertheless, our backstory narratives did not appear to provide additional subjective benefits. These preliminary findings suggest that narratives may have complex and unanticipated effects, calling for more studies in this area.",Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic,
CHI,2017,Visualization Literacy at Elementary School,10.1145/3025453.3025877,"This work advances our understanding of children's visualization literacy, and aims to improve it through a novel approach for teaching visualization at elementary school. We first contribute an analysis of data graphics and activities employed in grade K to 4 educational materials, and the results of a survey conducted with 16 elementary school teachers. We find that visualization education could benefit from integrating pedagogical strategies for teaching abstract concepts with established interactive visualization techniques. Building on these insights, we develop and study design principles for novel interactive teaching material aimed at increasing children's visualization literacy. We specifically contribute C'est La Vis, an online platform for teachers and students to respectively teach and learn about pictographs and bar charts, and report on our initial observations of its use in grades K and 2.",Basak Alper;Nathalie Henry Riche;Fanny Chevalier;Jeremy Boy;T. Metin Sezgin,
CHI,2017,"Group Spinner: Recognizing and Visualizing Learning in the Classroom for Reflection, Communication, and Planning",10.1145/3025453.3025679,"Group Spinner is a digital visual tool intended to help teachers observe and reflect on children's collaborative technology-enhanced learning activities in the classroom. We describe the design of Group Spinner, which was informed by activity theory, previous work and teachers' focus group feedback. Based on a radar chart and a set of indicators, Group Spinner allows teachers to record in-class observations as to different aspects of group learning and learning behaviors, beyond the limited knowledge acquisition measures. Our exploratory study involved 6 teachers who used the tool for a total of 23 classes in subjects ranging from Maths and Geography to Sociology and Art. Semi-structured interviews with these teachers revealed a number of different uses of the tool. Depending on their experience and pedagogy, teachers considered Group Spinner to be a valuable tool to support awareness, reflection, communication, and/or planning.",Ahmed Kharrufa;Sally Rix;Timur Osadchiy;Anne Preston;Patrick Olivier,
CHI,2017,Where No One Has Gone Before: A Meta-Dataset of the World's Largest Fanfiction Repository,10.1145/3025453.3025720,"With its roots dating to popular television shows of the 1960s such as Star Trek, fanfiction has blossomed into an extremely widespread form of creative expression. The transition from printed zines to online fanfiction repositories has facilitated this growth in popularity, with millions of fans writing stories and adding daily to sites such as Archive Of Our Own, Fanfiction.net, FIMfiction.net, and many others. Enthusiasts are sharing their writing, reading stories written by others, and helping each other to grow as writers. Yet, this domain is often undervalued by society and understudied by researchers. To facilitate the study of this large but often marginalized community, we present a fully anonymized data release (via differential privacy) of the metadata from a large fanfiction site (to protect author privacy, story, profile, and review text is excluded, and only metadata is provided). We use visual analytics techniques to draw several intriguing insights from the data and show the potential for future research. We hope other researchers can use this data to explore further questions related to online fanfiction communities.",Kodlee Yin;Cecilia R. Aragon;Sarah Evans;Katie Davis 0001,
CHI,2017,Improving Communication Between Pair Programmers Using Shared Gaze Awareness,10.1145/3025453.3025573,"Remote collaboration can be more difficult than collocated collaboration for a number of reasons, including the inability to easily determine what your collaborator is looking at. This impedes a pair's ability to efficiently communicate about on-screen locations and makes synchronous coordination difficult. We designed a novel gaze visualization for remote pair programmers which shows where in the code their partner is currently looking, and changes color when they are looking at the same thing. Our design is unobtrusive, and transparently depicts the imprecision inherent in eye tracking technology. We evaluated our design with an experiment in which pair programmers worked remotely on code refactoring tasks. Our results show that with the visualization, pairs spent a greater proportion of their time concurrently looking at the same code locations. Pairs communicated using a larger ratio of implicit to explicit references, and were faster and more successful at responding to those references.",Sarah D'Angelo;Andrew Begel,
CHI,2016,I Know Where You Live: Inferring Details of People's Lives by Visualizing Publicly Shared Location Data,10.1145/2858036.2858272,"This research measures human performance in inferring the functional types (i.e., home, work, leisure and transport) of locations in geo-location data using different visual representations of the data (textual, static and animated visualizations) along with different amounts of data (1, 3 or 5 day(s)). We first collected real life geo-location data from tweets. We then asked the data owners to tag their location points, resulting in ground truth data. Using this dataset we conducted an empirical study involving 45 participants to analyze how accurately they could infer the functional location of the original data owners under different conditions, i.e., three data representations, three data densities and four location types. The study results indicate that while visual techniques perform better than textual ones, the functional locations of human activities can be inferred with a relatively high accuracy even using only textual representations and a low density of location points. Workplace was more easily inferred than home while transport was the functional location with the highest accuracy. Our results also showed that it was easier to infer functional locations from data exhibiting more stable and consistent mobility patterns, which are thus more vulnerable to privacy disclosures. We discuss the implications of our findings in the context of privacy preservation and provide guidelines to users and companies to help preserve and safeguard people's privacy.",Ilaria Liccardi;Alfie Abdul-Rahman;Min Chen 0001,
CHI,2016,Unsupervised Clickstream Clustering for User Behavior Analysis,10.1145/2858036.2858107,"Online services are increasingly dependent on user participation. Whether it's online social networks or crowdsourcing services, understanding user behavior is important yet challenging. In this paper, we build an unsupervised system to capture dominating user behaviors from clickstream data (traces of users' click events), and visualize the detected behaviors in an intuitive manner. Our system identifies ""clusters"" of similar users by partitioning a similarity graph (nodes are users; edges are weighted by clickstream similarity). The partitioning process leverages iterative feature pruning to capture the natural hierarchy within user clusters and produce intuitive features for visualizing and understanding captured user behaviors. For evaluation, we present case studies on two large-scale clickstream traces (142 million events) from real social networks. Our system effectively identifies previously unknown behaviors, e.g., dormant users, hostile chatters. Also, our user study shows people can easily interpret identified behaviors using our visualization tool.",Gang Wang 0011;Xinyi Zhang;Shiliang Tang;Haitao Zheng 0001;Ben Y. Zhao,
CHI,2016,"Fast, Cheap, and Good: Why Animated GIFs Engage Us",10.1145/2858036.2858532,"Animated GIFs have been around since 1987 and recently gained more popularity on social networking sites. Tumblr, a large social networking and micro blogging platform, is a popular venue to share animated GIFs. Tumblr users follow blogs, generating a feed or posts, and choose to ""like' or to ""reblog' favored posts. In this paper, we use these actions as signals to analyze the engagement of over 3.9 million posts, and conclude that animated GIFs are significantly more engaging than other kinds of media. We follow this finding with deeper visual analysis of nearly 100k animated GIFs and pair our results with interviews with 13 Tumblr users to find out what makes animated GIFs engaging. We found that the animation, lack of sound, immediacy of consumption, low bandwidth and minimal time demands, the storytelling capabilities and utility for expressing emotions were significant factors in making GIFs the most engaging content on Tumblr. We also found that engaging GIFs contained faces and had higher motion energy, uniformity, resolution and frame rate. Our findings connect to media theories and have implications in design of effective content dashboards, video summarization tools and ranking algorithms to enhance engagement.",Saeideh Bakhshi;David A. Shamma;Lyndon Kennedy;Yale Song;Paloma de Juan;Joseph Jofish Kaye,
CHI,2016,"Taking 5: Work-Breaks, Productivity, and Opportunities for Personal Informatics for Knowledge Workers",10.1145/2858036.2858066,"Taking breaks from work is an essential and universal practice. In this paper, we extend current research on productivity in the workplace to consider the break habits of knowledge workers and explore opportunities of break logging for personal informatics. We report on three studies. Through a survey of 147 U.S.-based knowledge workers, we investigate what activities respondents consider to be breaks from work, and offer an understanding of the benefit workers desire when they take breaks. We then present results from a two-week in-situ diary study with 28 participants in the U.S. who logged 800 breaks, offering insights into the effect of work breaks on productivity. We finally explore the space of information visualization of work breaks and productivity in a third study. We conclude with a discussion of implications for break recommendation systems, availability and interuptibility research, and the quantified workplace.",Daniel A. Epstein;Daniel Avrahami;Jacob T. Biehl,
CHI,2016,ChronoFab: Fabricating Motion,10.1145/2858036.2858138,"We present ChronoFab, a 3D modeling tool to craft motion sculptures, tangible representations of 3D animated models, visualizing an object's motion with static, transient, ephemeral visuals that are left behind. Our tool casts 3D modeling as a dynamic art-form by employing 3D animation and dynamic simulation for the modeling of motion sculptures. Our work is inspired by the rich history of stylized motion depiction techniques in existing 3D motion sculptures and 2D comic art. Based on a survey of such techniques, we present an interface that enables users to rapidly explore and craft a variety of static 3D motion depiction techniques, including motion lines, multiple stroboscopic stamps, sweeps and particle systems, using a 3D animated object as input. In a set of professional and non-professional usage sessions, ChronoFab was found to be a superior tool for the authoring of motion sculptures, compared to traditional 3D modeling workflows, reducing task completion times by 79%.",Rubaiat Habib Kazi;Tovi Grossman;Cory Mogk;Ryan M. Schmidt;George W. Fitzmaurice,
CHI,2016,A Comparative Evaluation on Online Learning Approaches using Parallel Coordinate Visualization,10.1145/2858036.2858101,"As visualizations are increasingly used as a storytelling medium for the general public, it becomes important to help people learn how to understand visualizations. Prior studies indicate that interactive multimedia learning environments can increase the effectiveness of learning [11]. To investigate the efficacy of the multimedia learning environments for data visualization education, we compared four online learning approaches 1) baseline (i.e., no tutorial), 2) static tutorial, 3) video tutorial, and 4) interactive tutorial-through a crowdsourced user study. We measured participants' learning outcomes in using parallel coordinates with 18 tasks. Results show that participants with the interactive condition achieved higher scores than those with the static and baseline conditions, and reported that they had a more engaging experience than those with the static condition.",Bum Chul Kwon;Bongshin Lee,
CHI,2016,Supporting Comment Moderators in Identifying High Quality Online News Comments,10.1145/2858036.2858389,"Online comments submitted by readers of news articles can provide valuable feedback and critique, personal views and perspectives, and opportunities for discussion. The varying quality of these comments necessitates that publishers remove the low quality ones, but there is also a growing awareness that by identifying and highlighting high quality contributions this can promote the general quality of the community. In this paper we take a user-centered design approach towards developing a system, CommentIQ, which supports comment moderators in interactively identifying high quality comments using a combination of comment analytic scores as well as visualizations and flexible UI components. We evaluated this system with professional comment moderators working at local and national news outlets and provide insights into the utility and appropriateness of features for journalistic tasks, as well as how the system may enable or transform journalistic practices around online comments.",Deokgun Park 0001;Simranjit Singh Sachar;Nicholas Diakopoulos;Niklas Elmqvist,
CHI,2016,Augmenting the Field-of-View of Head-Mounted Displays with Sparse Peripheral Displays,10.1145/2858036.2858212,"In this paper, we explore the concept of a sparse peripheral display, which augments the field-of-view of a head-mounted display with a lightweight, low-resolution, inexpensively produced array of LEDs surrounding the central high-resolution display. We show that sparse peripheral displays expand the available field-of-view up to 190º horizontal, nearly filling the human field-of-view. We prototyped two proof-of-concept implementations of sparse peripheral displays: a virtual reality headset, dubbed SparseLightVR, and an augmented reality headset, called SparseLightAR. Using SparseLightVR, we conducted a user study to evaluate the utility of our implementation, and a second user study to assess different visualization schemes in the periphery and their effect on simulator sickness. Our findings show that sparse peripheral displays are useful in conveying peripheral information and improving situational awareness, are generally preferred, and can help reduce motion sickness in nausea-susceptible people.",Robert Xiao;Hrvoje Benko,
CHI,2016,SnapToReality: Aligning Augmented Reality to the Real World,10.1145/2858036.2858250,"Augmented Reality (AR) applications may require the precise alignment of virtual objects to the real world. We propose automatic alignment of virtual objects to physical constraints calculated from the real world in real time (""snapping to reality""). We demonstrate SnapToReality alignment techniques that allow users to position, rotate, and scale virtual content to dynamic, real world scenes. Our proof-of-concept prototype extracts 3D edge and planar surface constraints. We furthermore discuss the unique design challenges of snapping in AR, including the user's limited field of view, noise in constraint extraction, issues with changing the view in AR, visualizing constraints, and more. We also report the results of a user study evaluating SnapToReality, confirming that aligning objects to the real world is significantly faster when assisted by snapping to dynamically extracted constraints. Perhaps more importantly, we also found that snapping in AR enables a fresh and expressive form of AR content creation.",Benjamin Nuernberger;Eyal Ofek;Hrvoje Benko;Andrew D. Wilson,
CHI,2016,"MyPart: Personal, Portable, Accurate, Airborne Particle Counting",10.1145/2858036.2858571,"In 2012, air pollution in both cities and rural areas was estimated to have caused 3.7 million premature deaths, 88% of those in at risk communities. The primary pollutant was small airborne particulate matter of 10 microns or less in diameter which led to the development of cardiovascular and respiratory diseases. In response, we developed MyPart, the first personal, portable, and accurate particle sensor under $50 capable of distinguishing and counting differently sized particles. We demonstrate how MyPart offers substantial enhancements over most existing air particle sensors by simultaneously improving accessibility, flexibility, portability, and accuracy. We describe the evolution and implementation of the sensor design, demonstrate its performance across twenty everyday urban environments versus a calibrated instrument, and conduct a preliminary user study to report on the overall user experience of MyPart. We also present a novel smart-phone visualization interface and a series of simple form factor adaptations of our design.",Rundong Tian;Christine Dierk;Christopher Myers;Eric Paulos,
CHI,2016,"Programming, Problem Solving, and Self-Awareness: Effects of Explicit Guidance",10.1145/2858036.2858252,"More people are learning to code than ever, but most learning opportunities do not explicitly teach the problem solving skills necessary to succeed at open-ended programming problems. In this paper, we present a new approach to impart these skills, consisting of: 1) explicit instruction on programming problem solving, which frames coding as a process of translating mental representations of problems and solutions into source code, 2) a method of visualizing and monitoring progression through six problem solving stages, 3) explicit, on-demand prompts for learners to reflect on their strategies when seeking help from instructors, and 4) context-sensitive help embedded in a code editor that reinforces the problem solving instruction. We experimentally evaluated the effects of our intervention across two 2-week web development summer camps with 48 high school students, finding that the intervention increased productivity, independence, programming self-efficacy, metacognitive awareness, and growth mindset. We discuss the implications of these results on learning technologies and classroom instruction.",Dastyni Loksa;Amy J. Ko;Will Jernigan;Alannah Oleson;Christopher J. Mendez;Margaret M. Burnett,
CHI,2016,Gaze Augmentation in Egocentric Video Improves Awareness of Intention,10.1145/2858036.2858127,"Video communication using head-mounted cameras could be useful to mediate shared activities and support collaboration. Growing popularity of wearable gaze trackers presents an opportunity to add gaze information on the egocentric video. We hypothesized three potential benefits of gaze-augmented egocentric video to support collaborative scenarios: support deictic referencing, enable grounding in communication, and enable better awareness of the collaborator's intentions. Previous research on using egocentric videos for real-world collaborative tasks has failed to show clear benefits of gaze point visualization. We designed a study, deconstructing a collaborative car navigation scenario, to specifically target the value of gaze-augmented video for intention prediction. Our results show that viewers of gaze-augmented video could predict the direction taken by a driver at a four-way intersection more accurately and more confidently than a viewer of the same video without the superimposed gaze point. Our study demonstrates that gaze augmentation can be useful and encourages further study in real-world collaborative scenarios.",Deepak Akkil;Poika Isokoski,
CHI,2016,Physikit: Data Engagement Through Physical Ambient Visualizations in the Home,10.1145/2858036.2858059,"Internet of things (IoT) devices and sensor kits have the potential to democratize the access, use, and appropriation of data. Despite the increased availability of low cost sensors, most of the produced data is ""black box"" in nature: users often do not know how to access or interpret data. We propose a ""human-data design"" approach in which end-users are given tools to create, share, and use data through tangible and physical visualizations. This paper introduces Physikit, a system designed to allow users to explore and engage with environmental data through physical ambient visualizations. We report on the design and implementation of Physikit, and present a two-week field study which showed that participants got an increased sense of the meaning of data, embellished and appropriated the basic visualizations to make them blend into their homes, and used the visualizations as a probe for community engagement and social behavior.",Steven Houben;Connie Golsteijn;Sarah Gallacher;Rose Johnson;Saskia Bakker;Nicolai Marquardt;Licia Capra;Yvonne Rogers,
CHI,2016,Infrastructure in the Wild: What Mapping in Post-Earthquake Nepal Reveals about Infrastructural Emergence,10.1145/2858036.2858545,"Disasters and their impacts have unavoidable spatial characteristics. As such, maps are necessary and omnipresent features of the information landscapes that surround and support disaster response. Professional and volunteer GIS services are increasingly in demand to support map-based information visualization during crises. This paper investigates the work of mapmakers working on the response to the 2015 Nepal earthquakes. In comparison to prior events, we found significantly more collaboration and spatial data sharing took place between map producers working across humanitarian organizations and parts of the Nepal government. Collaboration between mapping practitioners was supported by a complex and emergent information infrastructure composed of social and technical elements, some of which were brought through experience with prior disaster events, and some which were shaped anew by the availability and acceptance of open data sources. Our research investigates these elements of the spatial information infrastructure in post-earthquake Nepal to consider infrastructural emergence.",Robert Soden;Leysia Palen,
CHI,2016,HapTurk: Crowdsourcing Affective Ratings of Vibrotactile Icons,10.1145/2858036.2858279,"Vibrotactile (VT) display is becoming a standard component of informative user experience, where notifications and feedback must convey information eyes-free. However, effective design is hindered by incomplete understanding of relevant perceptual qualities, together with the need for user feedback to be accessed in-situ. To access evaluation streamlining now common in visual design, we introduce proxy modalities as a way to crowdsource VT sensations by reliably communicating high-level features through a crowd-accessible channel. We investigate two proxy modalities to represent a high-fidelity tactor: a new VT visualization, and low-fidelity vibratory translations playable on commodity smartphones. We translated 10 high-fidelity vibrations into both modalities, and in two user studies found that both proxy modalities can communicate affective features, and are consistent when deployed remotely over Mechanical Turk. We analyze fit of features to modalities, and suggest future improvements.",Oliver S. Schneider;Hasti Seifi;Salma Kashani;Matthew Chun;Karon E. MacLean,
CHI,2016,Chronicler: Interactive Exploration of Source Code History,10.1145/2858036.2858442,"Exploring source code history is an important task for software maintenance. Traditionally, source code history is navigated on the granularity of individual files. This is not fine-grained enough to support users in exploring the evolution of individual code elements. We suggest to consider the history of individual elements within the tree structure inherent to source code. A history graph created from these trees then enables new ways to explore events of interest defined by structural changes in the source code. We present Tree Flow, a visualization of these structural changes designed to enable users to choose the appropriate level of detail for the task at hand. In a user study, we show that both Chronicler and the history aware timeline, two prototype systems combining history graph navigation with a traditional source code view, outperform the more traditional history navigation on a file basis and users strongly prefer Chronicler for the exploration of source code.",Moritz Wittenhagen;Christian Cherek;Jan O. Borchers,
CHI,2016,Telling Stories about Dynamic Networks with Graph Comics,10.1145/2858036.2858387,"In this paper, we explore graph comics as a medium to communicate changes in dynamic networks. While previous re- search has focused on visualizing dynamic networks for data exploration, we want to see if we can take advantage of the visual expressiveness and familiarity of comics to present and explain temporal changes in networks to an audience. To understand the potential of comics as a storytelling medium, we first created a variety of comics during a 3 month structured design process, involving domain experts from public education and neuroscience. This process led to the definition of 8 design factors for creating graph comics and propose design solutions for each. Results from a qualitative study suggest that a general audience is quickly able understand complex temporal changes through graph comics, provided with minimal textual annotations and no training.",Benjamin Bach;Natalie Kerracher;Kyle Wm. Hall;Sheelagh Carpendale;Jessie Kennedy;Nathalie Henry Riche,
CHI,2016,Look Before You Leap: Improving the Users' Ability to Detect Fraud in Electronic Marketplaces,10.1145/2858036.2858555,"Reputation systems in current electronic marketplaces can easily be manipulated by malicious sellers in order to appear more reputable than appropriate. We conducted a controlled experiment with 40 UK and 41 German participants on their ability to detect malicious behavior by means of an eBay-like feedback profile versus a novel interface involving an interactive visualization of reputation data. The results show that participants using the new interface could better detect and understand malicious behavior in three out of four attacks (the overall detection accuracy 77% in the new vs. 56% in the old interface). Moreover, with the new interface, only 7% of the users decided to buy from the malicious seller (the options being to buy from one of the available sellers or to abstain from buying), as opposed to 30% in the old interface condition.",Johannes Sänger;Norman Hänsch;Brian Glass;Zinaida Benenson;Robert Landwirth;M. Angela Sasse,
CHI,2016,"'A bit like British Weather, I suppose': Design and Evaluation of the Temperature Calendar",10.1145/2858036.2858367,"In this paper we present the design and evaluation of the Temperature Calendar -- a visualization of temperature variation within a workplace over the course of the past week. This highlights deviation from organizational temperature policy, and aims to bring staff ""into the loop"" of understanding and managing heating, and so reduce energy waste. The display was deployed for three weeks in five public libraries. Analysis of interaction logs, questionnaires and interviews shows that staff used the displays to understand heating in their buildings, and took action reflecting this new understanding. Bringing together our results, we discuss design implications for workplace displays, and an analysis of carbon emissions generated in constructing and operating our design. More in general, the findings helped us to reflect on the role of policy on energy consumption, and the potential for the HCI community to engage with its application, as well as its definition or modification.",Enrico Costanza;Ben Bedwell;Michael O. Jewell;James A. Colley;Tom Rodden,
CHI,2016,iVoLVER: Interactive Visual Language for Visualization Extraction and Reconstruction,10.1145/2858036.2858435,"We present the design and implementation of iVoLVER, a tool that allows users to create visualizations without textual programming. iVoLVER is designed to enable flexible acquisition of many types of data (text, colors, shapes, quantities, dates) from multiple source types (bitmap charts, webpages, photographs, SVGs, CSV files) and, within the same canvas, supports transformation of that data through simple widgets to construct interactive animated visuals. Aside from the tool, which is web-based and designed for pen and touch, we contribute the design of the interactive visual language and widgets for extraction, transformation, and representation of data. We demonstrate the flexibility and expressive power of the tool through a set of scenarios, and discuss some of the challenges encountered and how the tool fits within the current infovis tool landscape.",Gonzalo Gabriel Méndez;Miguel A. Nacenta;Sebastien Vandenheste,
CHI,2016,Investigating Effects of Post-Selection Feedback for Acquiring Ultra-Small Targets on Touchscreen,10.1145/2858036.2858593,"In this paper, we investigate the effects of post-selection feedback for acquiring ultra-small (2-4mm) targets on touchscreens. Post-selection feedback shows the contact point on touchscreen after a user lifts his/her fingers to increase users' awareness of touching. Three experiments are conducted progressively using a single crosshair target, two reciprocally acquired targets and 2D random targets. Results show that in average post-selection feedback can reduce touch error rates by 78.4%, with a compromise of target acquisition time no more than 10%. In addition, we investigate participants' adjustment behavior based on correlation between successive trials. We conclude that the benefit of post-selection feedback is the outcome of both improved understanding about finger/point mapping and the dynamic adjustment of finger movement enabled by the visualization of the touch point.",Chun Yu;Hongyi Wen;Wei Xiong;Xiaojun Bi 0001;Yuanchun Shi,
CHI,2016,AniSAM & AniAvatar: Animated Visualizations of Affective States,10.1145/2858036.2858365,"Tools that provide visual feedback about emotions to the user in the form of an avatar or an emoticon have become increasingly important. While a great deal of effort has already been put into the reliable and accurate automatic detection of emotions, only very little is known about how this information about affective states should be displayed in a comprehensible way to the user. In the present study, three newly developed feedback tools were evaluated. The tools were developed on the basis of an existing non-verbal questionnaire to represent two dimensions of emotion (i.e. valence and arousal) based on the circumplex model of affect. A total number of 826 participants were tested, using different vignettes that describe situations with specific affective content. Employing three newly developed affective feedback tools (AniSAM, AniAvatar and MergedSAM), the ratings obtained were compared to ratings using the original SAM instrument, a well-established questionnaire to measure affect. Results indicated that the animated feedback increased the accuracy of the arousal representation. Furthermore, valence feedback was more accurate when provided with an animated manikin-based tool rather than an avatar-based tool. This provided first evidence for the usefulness of animated tools offering visual feedback on user emotion. All instruments need to undergo further development. AniSAM and AniAvatar can be downloaded for purposes of practical applications and further research.",Andreas Sonderegger;Klaus Heyden;Alain Chavaillaz;Jürgen S. Sauer,
CHI,2016,UX Heatmaps: Mapping User Experience on Visual Interfaces,10.1145/2858036.2858271,"In this paper, we present an off-the-shelf UX evaluation tool which contextualizes users' physiological and behavioral signals while interacting with a system. The proposed tool triangulates users' gaze data with inferred users' cognitive and emotional states to produce user experience (UX) heatmaps, which show where users were looking when they experienced specific cognitive and emotional states. Results show that for a given cognitive state (i.e., cognitive load), the proposed UX heatmap was able to effectively highlight the areas where users experienced different levels of cognitive load on an interface. The proposed tool enables the visual analysis of users' various emotional and cognitive states for specific areas on a given interface, and also to compare users' states across multiple interfaces, which should be useful for both UX researchers and practitioners.",Vanessa Georges;François Courtemanche;Sylvain Senecal;Thierry Baccino;Marc Fredette;Pierre-Majorique Léger,
CHI,2016,Egocentric Analysis of Dynamic Networks with EgoLines,10.1145/2858036.2858488,"The egocentric analysis of dynamic networks focuses on discovering the temporal patterns of a subnetwork around a specific central actor (i.e., an ego-network). These types of analyses are useful in many application domains, such as social science and business intelligence, providing insights about how the central actor interacts with the outside world. We present EgoLines, an interactive visualization to support the egocentric analysis of dynamic networks. Using a ""subway map"" metaphor, a user can trace an individual actor over the evolution of the ego-network. The design of EgoLines is grounded in a set of key analytical questions pertinent to egocentric analysis, derived from our interviews with three domain experts and general network analysis tasks. We demonstrate the effectiveness of EgoLines in egocentric analysis tasks through a controlled experiment with 18 participants and a use-case developed with a domain expert.",Jian Zhao 0010;Michael Glueck;Fanny Chevalier;Yanhong Wu;Azam Khan,
CHI,2016,ResViz: Politics and Design Issues in Visualizing Academic Metrics,10.1145/2858036.2858181,"The use of data and metrics on a professional and personal level has led to considerable discourse around the performative power and politics of 'big data' and data visualization, with academia being no exception. We have developed a university system, ResViz, which publicly visualizes the externally funded research projects of academics, and their internal collaborations. We present an interview study that engages 20 key stakeholders, academics and administrators who are part of the pilot release for the first version of this system. In doing so, we describe and problematize our design space, considering the implications of making metrics visible and their social use within a large organization. Our findings cut across the way people communicate, review and manage performance with metrics. We raise seven design issues in this space -- practical considerations that expose the tensions in making metrics available for public contestation.",Chris Elsden;Sebastian Mellor;Patrick Olivier;Pete Wheldon;David S. Kirk;Rob Comber,
CHI,2016,Evaluating Information Visualization via the Interplay of Heuristic Evaluation and Question-Based Scoring,10.1145/2858036.2858280,"In an instructional setting it can be difficult to accurately assess the quality of information visualizations of several variables. Instead of a standard design critique, an alternative is to ask potential readers of the chart to answer questions about it. A controlled study with 47 participants shows a good correlation between aggregated novice heuristic evaluation scores and results of answering questions about the data, suggesting that the two forms of assessment can be complementary. Using both metrics in parallel can yield further benefits; discrepancies between them may reveal incorrect application of heuristics or other issues.",Marti A. Hearst;Paul Laskowski;Luis Silva,
CHI,2016,A Comparison of Cooperative and Competitive Visualizations for Co-located Collaboration,10.1145/2858036.2858072,"We present a study that investigates the influence of different types of visualizations on collaboration. The visualizations present the group's performance either in a more cooperative or more competitive way. Decades of research suggest that cooperation leads to greater productivity than competition. However, most of the existing group mirror visualizations achieve an increase in productivity and better self-regulation by enabling a direct comparison of performance within the group. We conducted a repeated measures study with 12 groups that were supported by visualizations that displayed the number of ideas of a brainstorming session (1) per person (competitive condition) (2) per group (cooperative condition), (3) per person and per group (mixed condition) and (4) without visualization (baseline). Results indicate that groups that see a combination of individual and group performance (mixed condition) are more productive, more satisfied with their results and participate in a more balanced way.",Sarah Tausch;Stephanie Ta;Heinrich Hussmann,
CHI,2016,The Effect of Richer Visualizations on Code Comprehension,10.1145/2858036.2858372,"Researchers often introduce visual tools to programming environments in order to facilitate program comprehension, reduce navigation times, and help developers answer difficult questions. Syntax highlighting is the main visual lens through which developers perceive their code, and yet its effects and the effects of richer code presentations on code comprehension have not been evaluated systematically. We present a rigorous user study comparing mainstream syntax highlighting to two visually-enhanced presentations of code. Our results show that: (1) richer code visualizations reduce the time necessary to answer questions about code features, and (2) contrary to the subjective perception of developers, richer code visualizations do not lead to visual overload. Based on our results we outline practical recommendations for tool designers.",Dimitar Asenov;Otmar Hilliges;Peter Müller 0001,
CHI,2016,"When (ish) is My Bus?: User-centered Visualizations of Uncertainty in Everyday, Mobile Predictive Systems",10.1145/2858036.2858558,"Users often rely on realtime predictions in everyday contexts like riding the bus, but may not grasp that such predictions are subject to uncertainty. Existing uncertainty visualizations may not align with user needs or how they naturally reason about probability. We present a novel mobile interface design and visualization of uncertainty for transit predictions on mobile phones based on discrete outcomes. To develop it, we identified domain specific design requirements for visualizing uncertainty in transit prediction through: 1) a literature review, 2) a large survey of users of a popular realtime transit application, and 3) an iterative design process. We present several candidate visualizations of uncertainty for realtime transit predictions in a mobile context, and we propose a novel discrete representation of continuous outcomes designed for small screens, quantile dotplots. In a controlled experiment we find that quantile dotplots reduce the variance of probabilistic estimates by ~1.15 times compared to density plots and facilitate more confident estimation by end-users in the context of realtime transit prediction scenarios.",Matthew Kay 0001;Tara Kola;Jessica R. Hullman;Sean A. Munson,
CHI,2016,Personalized Compass: A Compact Visualization for Direction and Location,10.1145/2858036.2858068,"Maps on mobile/wearable devices often make it difficult to determine the location of a point of interest (POI). For example, a POI may exist outside the map or on a background with no meaningful cues. To address this issue, we present Personalized Compass, a self-contained compact graphical location indicator. Personalized Compass uses personal a priori POIs to establish a reference frame, within which a POI in question can then be localized. Graphically, a personalized compass combines a multi-needle compass with an abstract overview map. We analyze the characteristics of Personalized Compass and the existing Wedge technique, and report on a user study comparing them. Personalized Compass performs better for four inference tasks, while Wedge is better for a locating task. Based on our analysis and study results, we suggest the two techniques are complementary and offer design recommendations.",Daniel Miau;Steven Feiner,
CHI,2016,Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks,10.1145/2858036.2858438,"In this work, we investigate how remote collaboration between a local worker and a remote collaborator will change if eye fixations of the collaborator are presented to the worker. We track the collaborator's points of gaze on a monitor screen displaying a physical workspace and visualize them onto the space by a projector or through an optical see-through head-mounted display. Through a series of user studies, we have found the followings: 1) Eye fixations can serve as a fast and precise pointer to objects of the collaborator's interest. 2) Eyes and other modalities, such as hand gestures and speech, are used differently for object identification and manipulation. 3) Eyes are used for explicit instructions only when they are combined with speech. 4) The worker can predict some intentions of the collaborator such as his/her current interest and next instruction.",Keita Higuchi;Ryo Yonetani;Yoichi Sato,
CHI,2016,Evaluating the Paper-to-Screen Translation of Participant-Aided Sociograms with High-Risk Participants,10.1145/2858036.2858368,"While much social network data exists online, key network metrics for high-risk populations must still be captured through self-report. This practice has suffered from numerous limitations in workflow and response burden. However, advances in technology, network drawing libraries and databases are making interactive network drawing increasingly feasible. We describe the translation of an analog-based technique for capturing personal networks into a digital framework termed netCanvas that addresses many existing shortcomings such as: 1) complex data entry; 2) extensive interviewer intervention and field setup; 3) difficulties in data reuse; and 4) a lack of dynamic visualizations. We test this implementation within a health behavior study of a high-risk and difficult-to-reach population. We provide a within--subjects comparison between paper and touchscreens. We assert that touchscreen-based social network capture is now a viable alternative for highly sensitive data and social network data entry tasks.",Bernie Hogan;Joshua R. Melville;Gregory Lee Phillips II;Patrick Janulis;Noshir Contractor;Brian S. Mustanski;Michelle Birkett,
CHI,2016,Making Sense of Temporal Queries with Interactive Visualization,10.1145/2858036.2858408,"As real-time monitoring and analysis become increasingly important, researchers and developers turn to data stream management systems (DSMS's) for fast, efficient ways to pose temporal queries over their datasets. However, these systems are inherently complex, and even database experts find it difficult to understand the behavior of DSMS queries. To help analysts better understand these temporal queries, we developed StreamTrace, an interactive visualization tool that breaks down how a temporal query processes a given dataset, step-by-step. The design of StreamTrace is based on input from expert DSMS users; we evaluated the system with a lab study of programmers who were new to streaming queries. Results from the study demonstrate that StreamTrace can help users to verify that queries behave as expected and to isolate the regions of a query that may be causing unexpected results.",Leilani Battle;Danyel Fisher;Robert DeLine;Mike Barnett 0001;Badrish Chandramouli;Jonathan Goldstein,
CHI,2016,Investigating Time Series Visualisations to Improve the User Experience,10.1145/2858036.2858300,"Research on graphical perception of time series visualisations has focused on visual representation, and not on interaction. Even for visual representation, there has been limited study of the impact on users of visual encodings and the strengths and weaknesses of Cartesian and Polar coordinate systems. In order to address this research gap, we performed a comprehensive graphical perception study that measured the effectiveness of time series visualisations with different interactions, visual encodings and coordinate systems for several tasks. Our results show that, while positional and colour visual encodings were better for most tasks, area visual encoding performed better for data comparison. Most importantly, we identified that introducing interactivity within time series visualisations considerably enhances the user experience, without any loss of efficiency or accuracy. We believe that our findings can greatly improve the development of visual analytics tools using time series visualisations in a variety of domains.",Muhammad Adnan 0001;Mike Just;Lynne Baillie,
CHI,2016,Enhancing Cross-Device Interaction Scripting with Interactive Illustrations,10.1145/2858036.2858382,"Cross-device interactions involve input and output on multiple computing devices. Implementing and reasoning about interactions that cover multiple devices with a diversity of form factors and capabilities can be complex. To assist developers in programming cross-device interactions, we created DemoScript, a technique that automatically analyzes a cross-device interaction program while it is being written. DemoScript visually illustrates the step-by-step execution of a selected portion or the entire program with a novel, automatically generated cross-device storyboard visualization. In addition to helping developers understand the behavior of the program, DemoScript also allows developers to revise their program by interactively manipulating the cross-device storyboard. We evaluated DemoScript with 8 professional programmers and found that DemoScript significantly improved development efficiency by helping developers interpret and manage cross-device interaction; it also encourages testing to think through the script in a development process.",Pei-Yu (Peggy) Chi;Yang Li 0058;Björn Hartmann,
CHI,2016,Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models,10.1145/2858036.2858529,"Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these naïve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why specific datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.",Josua Krause;Adam Perer;Kenney Ng,
CHI,2016,Glowworms and Fireflies: Ambient Light on Large Interactive Surfaces,10.1145/2858036.2858524,"Ambient light is starting to be commercially used to enhance the viewing experience for watching TV. We believe that ambient light can add value in meeting and control rooms that use large vertical interactive surfaces. Therefore, we equipped a large interactive whiteboard with a peripheral ambient light display and explored its utility for different scenarios by conducting two controlled experiments. In the first experiment, we investigated how ambient light can be used for peripheral notifications, and how perception is influenced by the user's position and the type of work they are engaged in. The second experiment investigated the utility of ambient light for off-screen visualization. We condense our findings into several design recommendations that we then applied to application scenarios to show the versatility and usefulness of ambient light for large surfaces.",Florian Perteneder;Eva-Maria Beatrix Grossauer;Joanne Leong;Wolfgang Stuerzlinger;Michael Haller,
CHI,2016,Integrating the Smart Home into the Digital Calendar,10.1145/2858036.2858168,"With the growing adoption of smart home technologies, inhabitants are faced with the challenge of making sense of the data that their homes can collect to configure automated behaviors that benefit their routines. Current commercial smart home interfaces usually provide information on individual devices instead of a more comprehensive overview of a home's behavior. To reduce the complexity of smart home data and integrate it better into inhabitants' lives, we turned to the familiar metaphor of a calendar and developed our smart home interface Casalendar. In order to investigate the concept and evaluate our goals to facilitate the understanding of smart home data, we created a prototype that we installed in two commercial smart homes for a month. The results we present in this paper are based on our analysis of user data from questionnaires, semi-structured interviews, participant-driven audio and screenshot feedback as well as logged interactions with our system. Our findings exposed advantages and disadvantages of this metaphor, emerging usage patterns, privacy concerns and challenges for information visualization. We further report on implications for design and open challenges we revealed through this work.",Sarah Mennicken;David Kim;Elaine May Huang,
CHI,2015,Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing,10.1145/2702123.2702393,"Persons with hearing loss use visual signals such as gestures and lip movement to interpret speech. While hearing aids and cochlear implants can improve sound recognition, they generally do not help the wearer localize sound necessary to leverage these visual cues. In this paper, we design and evaluate visualizations for spatially locating sound on a head-mounted display (HMD). To investigate this design space, we developed eight high-level visual sound feedback dimensions. For each dimension, we created 3-12 example visualizations and evaluated these as a design probe with 24 deaf and hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings reaffirm past work on challenges faced by persons with hearing loss in group conversations, provide support for the general idea of sound awareness visualizations on HMDs, and reveal preferences for specific design options. Although preliminary, Study 2 further contextualizes the design probe and uncovers directions for future work.",Dhruv Jain;Leah Findlater;Jamie Gilkeson;Benjamin Holland;Ramani Duraiswami;Dmitry N. Zotkin;Christian Vogler;Jon E. Froehlich,
CHI,2015,MatrixWave: Visual Comparison of Event Sequence Data,10.1145/2702123.2702419,"Event sequence data analysis is common in many domains, including web and software development, transportation, and medical care. Few have investigated visualization techniques for comparative analysis of multiple event sequence datasets. Grounded in the real-world characteristics of web clickstream data, we explore visualization techniques for comparison of two clickstream datasets collected on different days or from users with different demographics. Through iterative design with web analysts, we designed MatrixWave, a matrix-based representation that allows analysts to get an overview of differences in traffic patterns and interactively explore paths through the website. We use color to encode differences and size to offer context over traffic volume. User feedback on MatrixWave is positive. Our study participants made fewer errors with MatrixWave and preferred it over the more familiar Sankey diagram.",Jian Zhao 0010;Zhicheng Liu 0001;Mira Dontcheva;Aaron Hertzmann;Alan Wilson 0004,
CHI,2015,The Effects of Representation and Juxtaposition on Graphical Perception of Matrix Visualization,10.1145/2702123.2702217,"Analyzing multiple networks at once is a common yet difficult task in many domains. Using adjacency matrices for this purpose, however, can be effective because of its superior ability to accommodate dense networks in a small area. We evaluate various representations and juxtaposition designs for visualizing adjacency matrices through a series of controlled experiments. We investigate the effect of using square matrices and triangular matrices on the speed and accuracy of performing graphical-perception tasks. Based on human symmetric perception, we propose two alternative juxtaposition designs to the conventional side-by-side juxtaposition, and study how users perform visual search and comparison tasks regarding different juxtaposition types. Our results show that the matrix representations have similar performance, and the matrix juxtaposition types perform differently. With the design guidelines derived from our studies, we present a compact visualization termed TileMatrix for juxtaposing a large number of matrices, and demonstrate its effectiveness in analyzing multi-faceted, time-varying networks using real-world data.",Xiaotong Liu;Han-Wei Shen,
CHI,2015,g-Miner: Interactive Visual Group Mining on Multivariate Graphs,10.1145/2702123.2702446,"With the rapid growth of rich network data available through various sources such as social media and digital archives,there is a growing interest in more powerful network visual analysis tools and methods. The rich information about the network nodes and links can be represented as multivariate graphs, in which the nodes are accompanied with attributes to represent the properties of individual nodes. An important task often encountered in multivariate network analysis is to uncover link structure with groups, e.g., to understand why a person fits a specific job or certain role in a social group well.The task usually involves complex considerations including specific requirement of node attributes and link structure, and hence a fully automatic solution is typically not satisfactory.In this work, we identify the design challenges for min-ing groups with complex criteria and present an interactive system, ""g-Miner,"" that enables visual mining of groups on multivariate graph data. We demonstrate the effectiveness of our system through case study and in-depth expert inter-views. This work contributes to understanding the design of systems for leveraging users' knowledge progressively with algorithmic capacity for tackling massive heterogeneous information.",Nan Cao 0001;Yu-Ru Lin;Liangyue Li;Hanghang Tong,
CHI,2015,Trajectory Bundling for Animated Transitions,10.1145/2702123.2702476,"Animated transition has been a popular design choice for smoothly switching between different visualization views or layouts, in which movement trajectories are created as cues for tracking objects during location shifting. Tracking moving objects, however, becomes difficult when their movement paths overlap or the number of tracking targets increases. We propose a novel design to facilitate tracking moving objects in animated transitions. Instead of simply animating an object along a straight line, we create ""bundled"" movement trajectories for a group of objects that have spatial proximity and share similar moving directions. To study the effect of bundled trajectories, we untangle variations due to different aspects of tracking complexity in a comprehensive controlled user study. The results indicate that using bundled trajectories is particularly effective when tracking more targets (six vs. three targets) or when the object movement involves a high degree of occlusion or deformation. Based on the study, we discuss the advantages and limitations of the new technique, as well as provide design implications.",Fan Du;Nan Cao 0001;Jian Zhao 0010;Yu-Ru Lin,
CHI,2015,LeviPath: Modular Acoustic Levitation for 3D Path Visualisations,10.1145/2702123.2702333,"LeviPath is a modular system to levitate objects across 3D paths. It consists of two opposed arrays of transducers that create a standing wave capable of suspending objects in mid-air. To control the standing wave, the system employs a novel algorithm based on combining basic patterns of movement. Our approach allows the control of multiple beads simultaneously along different 3D paths. Due to the patterns and the use of only two opposed arrays, the system is modular and can scale its interaction space by joining several LeviPaths. In this paper, we describe the hardware architecture, the basic patterns of movement and how to combine them to produce 3D path visualisations.",Themis Omirou;Asier Marzo;Sue Ann Seah;Sriram Subramanian,
CHI,2015,Twist and Learn: Interface Learning in 3DOF Exploration of 3D Scatterplots,10.1145/2702123.2702201,"The increasing availability of 3D interfaces brings promise of improved user experience in diverse areas. Our study focuses on visual analytics, testing whether 3D interactivity improves performance in a visual data exploration task. Specifically, we compared scene rotation around vertical axis to a full 3D rotation using a InterSense IS-900 3D controller, in a task involving trivariate trend detection in a 3D scatterplot. We found that, while 3D rotation leads to slower performance, previous exposure to single-axis rotation removes that difference. This shows that an interactive 3D scatterplot can be an effective visual exploration technique for detecting trivariate patterns in the data, and highlights the role of interface learning in design and assessment of novel interfaces.",Mark M. Shovman;James L. Bown;Andrea Szymkowiak;Kenneth C. Scott-Brown,
CHI,2015,ModelTracker: Redesigning Performance Analysis Tools for Machine Learning,10.1145/2702123.2702509,"Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker's debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance.",Saleema Amershi;Max Chickering;Steven Mark Drucker;Bongshin Lee;Patrice Y. Simard;Jina Suh,
CHI,2015,Stock Lamp: An Engagement-Versatile Visualization Design,10.1145/2702123.2702323,"Design methodologies for information visualizations are typically based on the assumption that the users will be fully engaged in the visual exploration of the displayed information. However, recent research suggests that there is an increasing diversity in how users engage with modern visualizations, and that the traditional design theories do not always satisfy the varied users needs. In this paper, we present a new design concept, engagement-versatile design, for visualizations that target users with a variety of engagement styles. Without losing generality, we demonstrate the feasibility of this concept through the designing of a system called Stock Lamp, an engagement-versatile visualization that helps users keep track of the stock market in real-time. This design process includes identifying different modes of engagement, deriving design implications from each engagement-mode, and applying them to the visualization's design. Our user study shows that Stock Lamp is able to consistently relay market information even when the users are multi-tasking. We believe this study establishes a new concept that promotes a systematic design approach that leverages both theoretical and empirical design methodologies for future visualization development.",Yuzuru Tanahashi;Kwan-Liu Ma,
CHI,2015,VeilMe: An Interactive Visualization Tool for Privacy Configuration of Using Personality Traits,10.1145/2702123.2702293,"With the recent advances in using data analytics to automatically infer one's personality traits from their social media data, users are facing a growing tension between the use of the technology to aid self development in workplace and the privacy concerns of such use. Given the richness of personality data that can be derived today and the varied sensitivity of revealing such data, it is a non-trivial task for users to configure their privacy settings for sharing and protecting their derived personality data. Here we present the design, development, and evaluation of an interactive visualization tool, VeilMe, which helps users configure the privacy settings for the use of their personality portraits derived from social media. Unlike other privacy configuration tools, our tool offers two distinct advantages. First, it presents a novel and intuitive visual interface that aids users in understanding and exploring their own personality traits derived from their social media data, and configuring their privacy preferences. Second, our tool helps users to jump start their privacy settings by suggesting initial sharing strategies based on a set of factors, including the users' personality and target audience. We have evaluated the use of our tool with 124 participants in an enterprise context. Our results show that VeilMe effectively supports various user privacy configuration tasks, and also suggest several design implications, including the approaches to personalized privacy configurations.",Yang Wang;Liang Gou;Anbang Xu;Michelle X. Zhou;Huahai Yang;Hernan Badenes,
CHI,2015,BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization,10.1145/2702123.2702299,"Internal organs are hidden and untouchable, making it difficult for children to learn their size, position, and function. Traditionally, human anatomy (body form) and physiology (body function) are taught using techniques ranging from worksheets to three-dimensional models. We present a new approach called BodyVis, an e-textile shirt that combines biometric sensing and wearable visualizations to reveal otherwise invisible body parts and functions. We describe our 15-month iterative design process including lessons learned through the development of three prototypes using participatory design and two evaluations of the final prototype: a design probe interview with seven elementary school teachers and three single-session deployments in after-school programs. Our findings have implications for the growing area of wearables and tangibles for learning.",Leyla Norooz;Matthew Louis Mauriello;Anita Jorgensen;Brenna McNally;Jon E. Froehlich,
CHI,2015,Patina Engraver: Visualizing Activity Logs as Patina in Fashionable Trackers,10.1145/2702123.2702213,"Despite technological improvements in commercial activity trackers, little attention has been given to their emotional, social, or fashion-related qualities, such as their visual aesthetics and their relationship to self-expression and social connection. As an alternative integrated approach incorporating HCI, fashion, and product design, our project made use of the characteristics of patina to improve activity trackers as fashionable wearables. We developed the Patina Engraving System, which engraves patina-like patterns on an activity tracker according to a user's activity logs. Using a piercing technique, the patina of activity logs has been made abstract, visually rich, gradually emerging, and historically accumulated. During the field trial, we found that the patina motivated the participants to increase exercises for engraving aesthetic patinas. A tracker with patina triggered spontaneous social interactions in face-to-face situations. The participants also cherished the trackers that held their own history. Based on the field trial, we discuss design implications for utilizing patina in designing future fashionable technologies.",Moon-Hwan Lee;Seijin Cha;Tek-Jin Nam,
CHI,2015,Infographic Aesthetics: Designing for the First Impression,10.1145/2702123.2702545,"Information graphics, or infographics, combine elements of data visualization with design and have become an increasingly popular means for disseminating data. While several studies have suggested that aesthetics in visualization and infographics relate to desirable outcomes like engagement and memorability, it remains unknown how quickly aesthetic impressions are formed, and what it is that makes an infographic appealing. We address these questions by analyzing 1,278 participants' ratings on appeal after seeing infographics for 500ms. Our results establish that: 1) people form a reliable first impression of the appeal of an infographic based on a mere exposure effect, 2) this first impression is largely based on colorfulness and visual complexity, and 3) age, gender, and education level influence the preferred level of colorfulness and complexity. More generally, these findings suggest that outcomes such as engagement and memorability might be determined much earlier than previously thought.",Lane Harrison;Katharina Reinecke;Remco Chang,
CHI,2015,"ISOTYPE Visualization: Working Memory, Performance, and Engagement with Pictographs",10.1145/2702123.2702275,"Although the infographic and design communities have used simple pictographic representations for decades, it is still unclear whether they can make visualizations more effective. Using simple charts, we tested how pictographic representations impact (1) memory for information just viewed, as well as under the load of additional information, (2) speed of finding information, and (3) engagement and preference in seeking out these visualizations. We find that superfluous images can distract. But we find no user costs -- and some intriguing benefits -- when pictographs are used to represent the data.",Steve Haroz;Robert Kosara;Steven L. Franconeri,
CHI,2015,Storytelling in Information Visualizations: Does it Engage Users to Explore Data?,10.1145/2702123.2702452,"We present the results of three web-based field experiments, in which we evaluate the impact of using initial narrative visualization techniques and storytelling on user-engagement with exploratory information visualizations. We conducted these experiments on a popular news and opinion outlet, and on a popular visualization gallery website. While data-journalism exposes visualizations to a large public, we do not know how effectively this public makes sense of interactive graphics, and in particular if people explore them to gain additional insight to that provided by the journalists. In contrast to our hypotheses, our results indicate that augmenting exploratory visualizations with introductory 'stories' does not seem to increase user-engagement in exploration.",Jeremy Boy;Françoise Détienne;Jean-Daniel Fekete,
CHI,2015,Understanding Data Videos: Looking at Narrative Visualization through the Cinematography Lens,10.1145/2702123.2702431,"Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process.",Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Christophe Hurter;Pourang Irani,
CHI,2015,How Deceptive are Deceptive Visualizations?: An Empirical Analysis of Common Distortion Techniques,10.1145/2702123.2702608,"In this paper, we present an empirical analysis of deceptive visualizations. We start with an in-depth analysis of what deception means in the context of data visualization, and categorize deceptive visualizations based on the type of deception they lead to. We identify popular distortion techniques and the type of visualizations those distortions can be applied to, and formalize why deception occurs with those distortions. We create four deceptive visualizations using the selected distortion techniques, and run a crowdsourced user study to identify the deceptiveness of those visualizations. We then present the findings of our study and show how deceptive each of these visual distortion techniques are, and for what kind of questions the misinterpretation occurs. We also analyze individual differences among participants and present the effect of some of those variables on participants' responses. This paper presents a first step in empirically studying deceptive visualizations, and will pave the way for more research in this direction.",Anshul Vikram Pandey;Katharina Rall;Margaret L. Satterthwaite;Oded Nov;Enrico Bertini,
CHI,2015,STRATOS: Using Visualization to Support Decisions in Strategic Software Release Planning,10.1145/2702123.2702426,"Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each release. This is a complex planning process involving numerous trade-offs-constraints and factors that often make decisions difficult. Since the success of a product depends on this plan, it is important to understand the trade-offs between different release plans in order to make an informed choice. We present STRATOS, a tool that simultaneously visualizes several software release plans. The visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs between alternative plans. We evaluated our tool via a qualitative study and found that STRATOS enables a range of decision-making processes, helping participants decide on which plan is most optimal.",Bon Adriel Aseniero;Tiffany Wun;David Ledo;Guenther Ruhe;Anthony Tang 0001;Sheelagh Carpendale,
CHI,2015,Making Software Tutorial Video Responsive,10.1145/2702123.2702209,"Tutorial videos are widely available to help people use software. These videos, however, are viewed by users as captured and offer little direct interaction between users and software. This paper presents a video navigation method that allows users to interact with software tutorial video as if they were using the software. To make the tutorial video responsive, our method records the user interaction events like mouse click and drag during capturing the video. Our method then analyzes, selects, and visualizes these user interaction events at the event locations. When a user directly interacts with an event visualization, our method automatically navigates to the proper video frame to provide the visual feedback as if the software were responding to the user input. Thus, our method provides the experience of interacting with the software through directly manipulating the tutorial video. Our study shows our method can better help users follow tutorial videos to complete tasks than the baseline timeline interface.",Cuong Nguyen 0003;Feng Liu 0015,
CHI,2015,TurkBench: Rendering the Market for Turkers,10.1145/2702123.2702279,"Crowdsourcing is a relatively new model of labor where both the workers and work providers are experiencing its growing pains. A dominant platform that implements this model of labor is Amazon Mechanical Turk (AMT). While AMT has evolved over the years, the changes have focused mainly on work providers and have not addressed the problems workers face (e.g. dealing with market volatility and unpaid time searching for work). In this paper we present emph{TurkBench}, a tool meant to provide workers with personalized market visualization and session management. We discuss the design philosophy of the tool, briefly discuss four Turkers' reaction to a demo, and outline future work.",Benjamin V. Hanrahan;Jutta K. Willamowski;Saiganesh Swaminathan;David B. Martin 0001,
CHI,2015,Exploring the Role of Activity Trace Design on Evaluations of Online Worker Quality,10.1145/2702123.2702195,"Websites can record individual users' activities and display them in a variety of ways. There is a tradeoff between detail and abstraction in visualization, especially when the amount of content increases and becomes more difficult to process. We conducted an experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual's past work to see how these design features affected perceptions of the worker. We found that providing detail in the display through text increased processing time and led to less positive evaluations. Visually abstract displays required less processing time but decreased confidence in evaluation. This suggests that different design parameters may engender differing psychological processes that influence reactions towards an unknown person.",Jennifer Marlow;Laura A. Dabbish;Jodi L. Forlizzi,
CHI,2015,DocuViz: Visualizing Collaborative Writing,10.1145/2702123.2702517,"Collaborative writing is on the increase. In order to write well together, authors often need to be aware of who has done what recently. We offer a new tool, DocuViz, that displays the entire revision history of Google Docs, showing more than the one-step-at-a-time view now shown in revision history and tracking changes in Word. We introduce the tool and present cases in which the tool has the potential to be useful: To authors themselves to see recent ""seismic activity,"" indicating where in particular a co-author might want to pay attention, to instructors to see who has contributed what and which changes were made to comments from them, and to researchers interested in the new patterns of collaboration made possible by simultaneous editing capabilities.",Dakuo Wang;Judith S. Olson;Jingwen Zhang;Trung Nguyen;Gary M. Olson,
CHI,2015,EnviroPulse: Providing Feedback about the Expected Affective Valence of the Environment,10.1145/2702123.2702510,"Interacting with nature is beneficial to a person's mental-state, but it can sometimes be difficult to find environments that will induce positive affect (e.g., when planning a run). In this paper, we describe EnviroPulse-a system for auto-matically determining and communicating the expected affective valence (EAV) of environments to individuals. We describe a prototype that allows this to be used in real-time on a smartphone, but EnviroPulse could easily be incorporated into GPS systems, mapping services, or image-based systems. Our work differs from existing work in af-fective computing in that, rather than detecting a user's affect directly, we automatically determine the EAV of the environment through visual analysis. We present results that suggest our system can determine the EAV of envi-ronments. We also introduce real-time affective visual feedback of the calculated EAV of the images, and present results from an informal study suggesting that real-time visual feedback can be used for induction of affect.",Deltcho Valtchanov;Mark S. Hancock,
CHI,2015,Designing Information for Remediating Cognitive Biases in Decision-Making,10.1145/2702123.2702239,"Software is playing an increasingly important role in supporting human decision-making. Previous HCI research on decision support systems (DSS) has improved the information visualization aspect of DSS information design, but has somewhat overlooked the cognitive aspect of decision-making, namely that human reasoning is heuristic and reflects systematic errors or cognitive biases. We report on an empirical study of two cognitive biases: conservatism and loss aversion. Two remediation techniques recommended by previous research were tested: the expected return method, an actuarial-inspired approach presenting objective metrics; and bootstrapping, a technique successful in improving judgment consistency. The results show that the two biases can occur simultaneously and can have a huge impact on decision-making. The results also show that the two debiasing techniques are only partly effective. These findings suggest a need for more research on debiasing, and indicate some directions for exploring debiasing techniques and building decision support systems.",Yunfeng Zhang;Rachel K. E. Bellamy;Wendy A. Kellogg,
CHI,2015,ImmerseBoard: Immersive Telepresence Experience using a Digital Whiteboard,10.1145/2702123.2702160,"ImmerseBoard is a system for remote collaboration through a digital whiteboard that gives participants a 3D immersive experience, enabled only by an RGBD camera (Microsoft Kinect) mounted on the side of a large touch display. Using 3D processing of the depth images, life-sized rendering, and novel visualizations, ImmerseBoard emulates writing side-by-side on a physical whiteboard, or alternatively on a mirror. User studies involving three tasks show that compared to standard video conferencing with a digital whiteboard, ImmerseBoard provides participants with a quantitatively better ability to estimate their remote partners' eye gaze direction, gesture direction, intention, and level of agreement. Moreover, these quantitative capabilities translate qualitatively into a heightened sense of being together and a more enjoyable experience. ImmerseBoard's form factor is suitable for practical and easy installation in homes and offices.",Keita Higuchi;Yinpeng Chen;Philip A. Chou;Zhengyou Zhang;Zicheng Liu 0001,
CHI,2015,(s|qu)eries: Visual Regular Expressions for Querying and Exploring Event Sequences,10.1145/2702123.2702262,"Many different domains collect event sequence data and rely on finding and analyzing patterns within it to gain meaningful insights. Current systems that support such queries either provide limited expressiveness, hinder exploratory workflows or present interaction and visualization models which do not scale well to large and multi-faceted data sets. In this paper we present (s|qu)eries (pronounced ""Squeries""), a visual query interface for creating queries on sequences (series) of data, based on regular expressions. (s|qu)eries is a touch-based system that exposes the full expressive power of regular expressions in an approachable way and interleaves query specification with result visualizations. Being able to visually investigate the results of different query-parts supports debugging and encourages iterative query-building as well as exploratory work-flows. We validate our design and implementation through a set of informal interviews with data scientists that analyze event sequences on a daily basis.",Emanuel Zgraggen;Steven Mark Drucker;Danyel Fisher;Robert DeLine,
CHI,2015,Statsplorer: Guiding Novices in Statistical Analysis,10.1145/2702123.2702347,"Each step of statistical analysis requires researchers to make decisions based on both statistical knowledge and the knowledge of their own data. For novice analysts, this is cognitively demanding and can lead to mistakes and misinterpretations of the results. We present Statsplorer, a software that helps novices learn and perform inferential statistical tests. It lets the user kick-start data analysis from their research questions. Statsplorer automatically tests necessary statistical assumptions and uses visualizations to guide the user in both selecting statistical tests and interpreting the results. We compared Statsplorer with a statistics lecture and investigated how Statsplorer prepares novices for learning statistics in an AB/BA crossover experiment. The results indicates that using Statsplorer prior to the lecture leads to significantly better test scores in understanding statistical assumptions and choosing appropriate statistical tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer.",Chat Wacharamanotham;Krishna Subramanian 0002;Sarah Theres Völkel;Jan O. Borchers,
CHI,2015,Evaluating How Level of Detail of Visual History Affects Process Memory,10.1145/2702123.2702376,"Visual history tools provide visual representations of the workflow during data analysis tasks. While there is an established need for reviewing analytic processes, and many visual history tools provide visualizations to do so, it is not well known how helpful the tools actually are for process recall. Through a controlled experiment, we evaluated how the presence of a visual history aid and varying levels of visual detail affect process memory. Participants conducted an analysis task using a visual text-document analysis tool. We evaluated their memories of the process both immediately after the analysis and then again one week later. Results showed that even visual history views with reduced data-resolution were effective for aiding process memory. Further, even without inclusion of any data in the visual history aids, the visual cues alone from the final workspace were enough to improve memory of the main themes of analyses.",Eric D. Ragan;John R. Goodall;Albert Tung,
CHI,2015,Effects of Display Size and Resolution on User Behavior and Insight Acquisition in Visual Exploration,10.1145/2702123.2702406,"Large high-resolution displays are becoming increasingly common in research settings, providing data scientists with visual interfaces for the analysis of large datasets. Numerous studies have demonstrated unique perceptual and cognitive benefits afforded by these displays in visual analytics and information visualization tasks. However, the effects of these displays on knowledge discovery in exploratory visual analysis are still poorly understood. We present the results of a small-scale study to better understand how display size and resolution affect insight. Analyzing participants' verbal statements, we find preliminary evidence that larger displays with more pixels can significantly increase the number of discoveries reported during visual exploration, while yielding broader, more integrative insights. Furthermore, we find important differences in how participants performed the same visual exploration task using displays of varying sizes. We tie these results to extant work and propose explanations by considering the cognitive and interaction costs associated with visual exploration.",Khairi Reda;Andrew E. Johnson 0001;Michael E. Papka;Jason Leigh,
CHI,2015,TastyBeats: Designing Palatable Representations of Physical Activity,10.1145/2702123.2702197,"In this paper, we introduce palatable representations that besides improving the understanding of physical activity through abstract visualization also provide an appetizing drink to celebrate the experience of being physically active. By designing such palatable representations, our aim is to offer novel opportunities for reflection on one's physical activities. We present TastyBeats, a fountain-based interactive system that creates a fluidic spectacle of mixing sport drinks based on heart rate data of physical activity, which the user can later consume to replenish the loss of body fluids due to the physical activity. We articulate our experiences in designing the system as well as learning gained through field deployments of the system in participants' homes for a period of two weeks. We found that our system increased participants' awareness of physical activity and facilitated a shared social experience, while the prepared drink was treated as a hedonic reward that motivated participants to exercise more. Ultimately, with this work, we aim to inspire and guide design thinking on palatable representations, which we believe opens up new interaction possibilities to support physical activity experience.",Rohit Ashok Khot;Jeewon Lee;Deepti Aggarwal;Larissa Hjorth;Florian 'Floyd' Mueller,
CHI,2015,An Interactive System for Data Structure Development,10.1145/2702123.2702319,"Data structure algorithms are of fundamental importance in teaching and software development, yet are difficult to understand. We propose a new approach for understanding, debugging and developing heap manipulating data structures. The key technical idea of our work is to combine deep parametric abstraction techniques emerging from the area of static analysis with interactive abstraction manipulation. Our approach bridges program analysis with HCI and enables new capabilities not possible before: i) online automatic visualization of the data structure in a way which captures its essential operation, thus enabling powerful local reasoning, and ii) fine grained pen and touch gestures allowing for interactive control of the abstraction -- at any point the developer can pause the program, graphically interact with the data, and continue program execution. These features address some of the most pressing challenges in developing data structures. We implemented our approach in a Java-based system called FluiEdt and evaluated it with $27$ developers. The results indicate that FluiEdt is more effective in helping developers find data structure errors than existing state of the art IDEs (e.g. Eclipse) or pure visualization based approaches.",Jibin Ou;Martin T. Vechev;Otmar Hilliges,
CHI,2015,"""Everyone Is Talking about It!"": A Distributed Approach to Urban Voting Technology and Visualisations",10.1145/2702123.2702263,"The deployment of technology interventions, such as public displays and mobile apps, in community settings has been found to engage people in sharing and comparing their opinions. Our research is concerned with how to extend this to community-wide participation by devising and deploying multiple voting devices and visualisations. We present an in-the-wild study where a number of shopkeepers along a street participated by placing a novel voting device in their shops to collect locals' opinions. Results were displayed outside the shops, on the pavement. This distributed set-up was found to promote public debate on local issues, particularly around the perceived divide between people on either end of the street. We outline our design process and describe the impact of distributing voting devices and situated visualisations in a local community. \",Lisa Koeman;Vaiva Kalnikaité;Yvonne Rogers,
CHI,2015,Opportunities and Challenges for Data Physicalization,10.1145/2702123.2702180,"Physical representations of data have existed for thousands of years. Yet it is now that advances in digital fabrication, actuated tangible interfaces, and shape-changing displays are spurring an emerging area of research that we call Data Physicalization. It aims to help people explore, understand, and communicate data using computer-supported physical data representations. We call these representations physicalizations, analogously to visualizations -- their purely visual counterpart. In this article, we go beyond the focused research questions addressed so far by delineating the research area, synthesizing its open challenges and laying out a research agenda.",Yvonne Jansen;Pierre Dragicevic;Petra Isenberg;Jason Alexander;Abhijit Karnik;Johan Kildal;Sriram Subramanian;Kasper Hornbæk,
CHI,2015,Exploring Interactions with Physically Dynamic Bar Charts,10.1145/2702123.2702604,"Visualizations such as bar charts help users reason about data, but are mostly screen-based, rarely physical, and almost never physical and dynamic. This paper investigates the role of physically dynamic bar charts and evaluates new interactions for exploring and working with datasets rendered in dynamic physical form. To facilitate our exploration we constructed a 10x10 interactive bar chart and designed interactions that supported fundamental visualisation tasks, specifically; annotation, filtering, organization, and navigation. The interactions were evaluated in a user study with 17 participants. Our findings identify the preferred methods of working with the data for each task i.e. directly tapping rows to hide bars, highlight the strengths and limitations of working with physical data, and discuss the challenges of integrating the proposed interactions together into a larger data exploration system. In general, physical interactions were intuitive, informative, and enjoyable, paving the way for new explorations in physical data visualizations.",Faisal Taher;John Hardy;Abhijit Karnik;Christian Weichel;Yvonne Jansen;Kasper Hornbæk;Jason Alexander,
CHI,2015,Evaluating the Memorability of Physical Visualizations,10.1145/2702123.2702248,"Physical Visualizations are currently mostly used in casual contexts, e.g., as artistic data sculptures. However, their measurable benefits for traditional information visualization are largely unexplored. As a step in this direction, we compared the memorability of physical visualizations to that of digital visualizations. We conducted a user study with 40 participants in which we measured the recall of three types of information immediately after exploration and with a delay of two weeks. The results show that the physical visualization led to significantly less information decay within this time span. Our results build on known effects from cognitive psychology and provide a first indicator for measurable benefits of physical visualizations regarding memorability.",Simon Stusak;Jeannette Schwarz;Andreas Butz,
CHI,2015,Personality as a Predictor of User Strategy: How Locus of Control Affects Search Strategies on Tree Visualizations,10.1145/2702123.2702590,"Individual differences matter. While this has been the theme for many recent works in the Visualization and HCI communities, the mystery of how to develop personalized visualizations remains. This is largely because very little is known about how users actually use visualizations to solve problems and even less is known about how individual differences affect these problem-solving strategies. In this paper, we provide evidence that strategies are indeed influenced by individual differences. We demonstrate how the personality trait locus of control impacts strategies on hierarchical visualizations, and we introduce design recommendations for personalized visualizations.",Alvitta Ottley;Huahai Yang;Remco Chang,
CHI,2015,SketchSliders: Sketching Widgets for Visual Exploration on Wall Displays,10.1145/2702123.2702129,"We introduce a mobile sketching interface for exploring multi-dimensional datasets on wall displays. We demonstrate the idea of SketchSliders, range sliders that users can freely sketch on a mobile surface to customize their exploration. A small combination of sketches and gestures allows the creation of complex interactive sliders, such as circular sliders for periodic data, slider branches for detailed interaction, and fisheye transformation sliders. We augment sliders with a suite of tools, such as markers, slider cursors, and approximate views of data distributions. Our designs are inspired by a design study with three visualization experts and validated through a user study with six experts using our system. Our findings indicate that our sketching interface accommodates a wide range of exploration strategies, helping users customize as well as focus their visual explorations.",Theophanis Tsandilas;Anastasia Bezerianos;Thibaut Jacob,
CHI,2015,An Evaluation of Interactive Map Comparison Techniques,10.1145/2702123.2702130,"Geovisualization applications typically organize data into layers. These layers hold different types of geographical features, describe different characteristics of the same features, or represent those features at different points in time. Layers can be composited in various ways, most often employing a juxtaposition or superimposition strategy, to produce maps that users can explore interactively. From an HCI perspective, one of the main challenges is to design interactive compositions that optimize the legibility of the resulting map and that ease layer comparison. We characterize five representative techniques, and empirically evaluate them using a set of real-world maps in which we purposefully introduce six types of differences amenable to inter-layer visual comparison. We discuss the merits of these techniques in terms of visual interference, user attention and scanning strategy. Our results can help inform the design of map-based visualizations for supporting geo-analysis tasks in many application areas.",María-Jesús Lobo;Emmanuel Pietriga;Caroline Appert,
CHI,2014,SonicExplorer: fluid exploration of audio parameters,10.1145/2556288.2557206,"In digital music production, the phrase ""in the box"" refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.",Alexander Travis Adams;Berto Gonzalez;Celine Latulipe,
CHI,2014,ISSE: an interactive source separation editor,10.1145/2556288.2557253,"Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.",Nicholas J. Bryan;Gautham J. Mysore;Ge Wang 0002,
CHI,2014,A user study of different gameplay visualizations,10.1145/2556288.2557317,"With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness, suitability, and player preference. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data.",Simone Kriglstein;Günter Wallner;Margit Pohl,
CHI,2014,Automatic generation of semantic icon encodings for visualizations,10.1145/2556288.2557408,"Authors use icon encodings to indicate the semantics of categorical information in visualizations. The default icon libraries found in visualization tools often do not match the semantics of the data. Users often manually search for or create icons that are more semantically meaningful. This process can hinder the flow of visual analysis, especially when the amount of data is large, leading to a suboptimal user experience. We propose a technique for automatically generating semantically relevant icon encodings for categorical dimensions of data points. The algorithm employs natural language processing in order to find relevant imagery from the Internet. We evaluate our approach on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created icons, and particularly has higher user satisfaction for larger cardinalities of data.",Vidya Setlur;Jock D. Mackinlay,
CHI,2014,Task-driven evaluation of aggregation in time series visualization,10.1145/2556288.2557200,"Many visualization tasks require the viewer to make judgments about aggregate properties of data. Recent work has shown that viewers can perform such tasks effectively, for example to efficiently compare the maximums or means over ranges of data. However, this work also shows that such effectiveness depends on the designs of the displays. In this paper, we explore this relationship between aggregation task and visualization design to provide guidance on matching tasks with designs. We combine prior results from perceptual science and graphical perception to suggest a set of design variables that influence performance on various aggregate comparison tasks. We describe how choices in these variables can lead to designs that are matched to particular tasks. We use these variables to assess a set of eight different designs, predicting how they will support a set of six aggregate time series comparison tasks. A crowd-sourced evaluation confirms these predictions. These results not only provide evidence for how the specific visualizations support various tasks, but also suggest using the identified design variables as a tool for designing visualizations well suited for various types of tasks.",Danielle Albers;Michael Correll;Michael Gleicher,
CHI,2014,Dive in!: enabling progressive loading for real-time navigation of data visualizations,10.1145/2556288.2557195,"We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash streamlines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.",Michael Glueck;Azam Khan;Daniel J. Wigdor,
CHI,2014,"Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions",10.1145/2556288.2557131,"We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. ""compare two bars"") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.",Nivan Ferreira;Danyel Fisher;Arnd Christian König,
CHI,2014,Visualizing dynamic networks with matrix cubes,10.1145/2556288.2557010,"Designing visualizations of dynamic networks is challenging, both because the data sets tend to be complex and because the tasks associated with them are often cognitively demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people comprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations can produce a range of different 2D visualizations that emphasize specific aspects of the dynamic network suited to particular analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them in the Cubix system. We then show how two domain experts, an astronomer and a neurologist, used Cubix to explore and report on their own network data.",Benjamin Bach;Emmanuel Pietriga;Jean-Daniel Fekete,
CHI,2014,Kinetica: naturalistic multi-touch data visualization,10.1145/2556288.2557231,"Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.",Jeffrey M. Rzeszotarski;Aniket Kittur,
CHI,2014,Traffigram: distortion for clarification via isochronal cartography,10.1145/2556288.2557224,"Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its practical value. To attempt to settle this issue, we utilized a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design.",Sungsoo (Ray) Hong;Yea-Seul Kim;Jong-Chul Yoon;Cecilia R. Aragon,
CHI,2014,Faces engage us: photos with faces attract more likes and comments on Instagram,10.1145/2556288.2557403,"Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.",Saeideh Bakhshi;David A. Shamma;Eric Gilbert,
CHI,2014,Coding livecoding,10.1145/2556288.2557049,"Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported ""coding"" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a ""performer fingerprint"". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.",Ben Swift;Andrew Sorensen;Michael A. Martin;Henry J. Gardner,
CHI,2014,Visualization of personal history for video navigation,10.1145/2556288.2557106,"We present an investigation of two different visualizations of video history: Video Timeline and Video Tiles. Video Timeline extends the commonly employed list-based visualization for navigation history by applying size to indicate heuristics and occupying the full screen with a two-sided timeline. Video Tiles visualizes history items in a grid-based layout by following pre-defined templates based on items' heuristics and ordering, utilizing screen space more effectively at the expense of a clearer temporal location. The visualizations are compared against the state-of-the-art method (a filmstrip-based visualization), with ten participants tasked with sharing their previously-seen affective intervals. Our study shows that our visualizations are perceived as intuitive and both outperform and are strongly preferred to the current method. Based on these results, Video Timeline and Video Tiles provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously-seen intervals, leading to efficient clip sharing, simpler authoring and video summarization.",Abir Al Hajri;Gregor Miller;Matthew Fong;Sidney S. Fels,
CHI,2014,"End-users publishing structured information on the web: an observational study of what, why, and how",10.1145/2556288.2557036,"End-users are accustomed to filtering and browsing styled collections of data on professional web sites, but they have few ways to create and publish such information architectures for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework - an end-user tool which provides such functionality - to understand the needs, capabilities, and practices of this class of users. We include interviews, as well as analysis of over 1,800 visualizations and 200,000 web interactions with these visualizations. Our analysis reveals important findings about this user population which generalize to the task of providing better end-user structured content publication tools.",Edward Benson;David R. Karger,
CHI,2014,Monadic exploration: seeing the whole through its parts,10.1145/2556288.2557083,"Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization of a highly cross-referenced book and its six-month deployment.",Marian Dörk;Rob Comber;Martyn Dade-Robertson,
CHI,2014,The role of interactive biclusters in sensemaking,10.1145/2556288.2557337,"Visual exploration of relationships within large, textual datasets is an important aid for human sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and locations), users can leverage domain expertise and intuition to determine the importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present results of a study that analyzes how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We found that biclusters played four principal roles in the analytical process: an effective starting point for analysis, a revealer of two levels of connections, an indicator of potentially important entities, and a useful label for clusters of organized information.",Maoyuan Sun;Lauren Bradel;Christopher L. North;Naren Ramakrishnan,
CHI,2014,DemoWiz: re-performing software demonstrations for a live presentation,10.1145/2556288.2557254,"Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with (or worry about) unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present with pre-recorded screencast videos. It is, however, challenging to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations. DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing. A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.",Pei-Yu Chi;Bongshin Lee;Steven Mark Drucker,
CHI,2014,Structuring the space: a study on enriching node-link diagrams with visual references,10.1145/2556288.2557112,"Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report mixed results regarding their utility. While some evidence showed that grid and other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.",Basak Alper;Nathalie Henry Riche;Tobias Höllerer,
CHI,2014,Highlighting interventions and user differences: informing adaptive information visualization support,10.1145/2556288.2557141,"There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each user. This suggests that it is important to investigate information visualization systems that can dynamically adapt to each user. In this paper, we address the question of how to adapt. In particular, we present a study to evaluate a variety of visual prompts, called ""interventions"", that can be performed on a visualization to help users process it. Our results show that some of the tested interventions perform better than a condition in which no intervention is provided, both in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity.",Giuseppe Carenini;Cristina Conati;Enamul Hoque;Ben Steichen;Dereck Toker;James T. Enns,
CHI,2014,Visualizing interactive narratives: employing a branching comic to tell a story and show its readings,10.1145/2556288.2557296,"This paper describes the design and evaluation of a branching comic to compare how readers recall a visual narrative when presented as an interactive, digital program, or as a linear sequence on paper. The layout of the comic is used to visualize this data as heat maps and explore patterns of users' recollections. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns in the data that complement other research in both interactive stories and visualizations. We argue that the heat maps helped identify these patterns, which have implications for future designs and analyses of interactive visual and/or narrative media.",Daniel Andrews;Chris Baber,
CHI,2014,Supporting learners in collecting and exploring data from immersive simulations in collective inquiry,10.1145/2556288.2557162,"Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.",Michelle Lui;Alex C. Kuhn;Alisa Acosta;Chris Quintana;James D. Slotta,
CHI,2014,Addressing misconceptions about code with always-on programming visualizations,10.1145/2556288.2557409,"We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.",Thomas Lieber;Joel R. Brandt;Robert C. Miller,
CHI,2014,A novel knee rehabilitation system for the home,10.1145/2556288.2557353,"In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.",Mobolaji Ayoade;Lynne Baillie,
CHI,2014,Smarties: an input system for wall display development,10.1145/2556288.2556956,"Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of an interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to.",Olivier Chapuis;Anastasia Bezerianos;Stelios Frantzeskakis,
CHI,2014,NewsViews: an automated pipeline for creating custom geovisualizations for news,10.1145/2556288.2557228,"Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews' maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of 'found' databases, and techniques adapted from cartography to identify and create visually 'interesting' thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, 'interestingness' of representation and annotation quality).",Tong Gao;Jessica Hullman;Eytan Adar;Brent J. Hecht;Nicholas Diakopoulos,
CHI,2014,Permulin: mixed-focus collaboration on multi-view tabletops,10.1145/2556288.2557405,"We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.",Roman Lissermann;Jochen Huber;Martin Schmitz;Jürgen Steimle;Max Mühlhäuser,
CHI,2014,"In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time",10.1145/2556288.2557063,"One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user's field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.",Felix Lauber;Andreas Butz,
CHI,2014,Show me the invisible: visualizing hidden content,10.1145/2556288.2557032,"Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.",Thomas Geymayer;Markus Steinberger;Alexander Lex;Marc Streit;Dieter Schmalstieg,
CHI,2014,Supporting the design and fabrication of physical visualizations,10.1145/2556288.2557310,"Physical visualizations come in increasingly diverse forms, and are used in domains including art and entertainment, business analytics, and scientific research. However, creating physical visualizations requires laborious craftsmanship and demands expertise in both data visualization and digital fabrication. We present three case studies that illustrate limitations of current visualization fabrication workflows. We then present MakerVis, a prototype tool that integrates the entire process of creating physical visualizations, from data filtering to physical fabrication. Design sessions with three end users demonstrate how tools such as MakerVis can dramatically lower the barriers to producing physical visualizations. Observations and interviews from these sessions highlighted future research areas, including customization support, using material properties to represent data variables, and allowing the reuse of physical data objects in new visualizations.",Saiganesh Swaminathan;Conglei Shi;Yvonne Jansen;Pierre Dragicevic;Lora Oehlberg;Jean-Daniel Fekete,
CHI,2014,Crowdsourcing step-by-step information extraction to enhance existing how-to videos,10.1145/2556288.2556986,"Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations. We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player. To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77% precision and 81% recall.",Juho Kim;Phu Tran Nguyen;Sarah A. Weir;Philip J. Guo;Robert C. Miller;Krzysztof Z. Gajos,
CHI,2014,Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D),10.1145/2556288.2557365,"The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.",Christian Winkler 0001;Julian Seifert;David Dobbelstein;Enrico Rukzio,
CHI,2014,Effects of display size and navigation type on a classification task,10.1145/2556288.2557020,"The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.",Can Liu 0003;Olivier Chapuis;Michel Beaudouin-Lafon;Eric Lecolinet;Wendy E. Mackay,
CHI,2013,SpaceTop: integrating 2D and spatial 3D interactions in a see-through desktop environment,10.1145/2470654.2470680,"SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace. It extends the traditional desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop allows users to type, click, draw in 2D, and directly manipulate interface elements that float in the 3D space above the keyboard. It makes it possible to easily switch from one modality to another, or to simultaneously use two modalities with different hands. We introduce hardware and software configurations for co-locating these various interaction modalities in a unified workspace using depth cameras and a transparent display. We describe new interaction and visualization techniques that allow users to interact with 2D elements floating in 3D space. We present the results from a preliminary user study that indicates the benefit of such hybrid workspaces.",Jinha Lee;Alex Olwal;Hiroshi Ishii 0001;Cati N. Boulanger,
CHI,2013,Individual user characteristics and information visualization: connecting the dots through eye tracking,10.1145/2470654.2470696,"There is increasing evidence that users' characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user's cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.",Dereck Toker;Cristina Conati;Ben Steichen;Giuseppe Carenini,
CHI,2013,The efficacy of human post-editing for language translation,10.1145/2470654.2470718,"Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.",Spence Green;Jeffrey Heer;Christopher D. Manning,
CHI,2013,Using fNIRS brain sensing to evaluate information visualization interfaces,10.1145/2470654.2470723,"We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization. Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user's cognitive state. Unfortunately, objectively and unobtrusively monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS) has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain's quick, massively parallel visual system, which may be inaccessible to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone. In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain. Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.",Evan M. Peck;Beste F. Yuksel;Alvitta Ottley;Robert J. K. Jacob;Remco Chang,
CHI,2013,Weighted graph comparison techniques for brain connectivity analysis,10.1145/2470654.2470724,"The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.",Basak Alper;Benjamin Bach;Nathalie Henry Riche;Tobias Isenberg 0001;Jean-Daniel Fekete,
CHI,2013,IllumiRoom: peripheral projected illusions for interactive experiences,10.1145/2470654.2466112,"IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.",Brett R. Jones;Hrvoje Benko;Eyal Ofek;Andrew D. Wilson,
CHI,2013,Direct manipulation video navigation in 3D,10.1145/2470654.2466150,"Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.",Cuong Nguyen 0003;Yuzhen Niu;Feng Liu 0015,
CHI,2013,The dubuque electricity portal: evaluation of a city-scale residential electricity consumption feedback system,10.1145/2470654.2466155,"This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions - both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system's users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.",Thomas Erickson;Ming Li 0009;Younghun Kim;Ajay Deshpande;Sambit Sahu;Tian Chao;Piyawadee Sukaviriya;Milind R. Naphade,
CHI,2013,Exploring & designing tools to enhance falls rehabilitation in the home,10.1145/2470654.2466159,"Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.",Stephen Uzor;Lynne Baillie,
CHI,2013,Pt Viz: towards a wearable device for visualizing knee rehabilitation exercises,10.1145/2470654.2466161,"We present a wearable sensory display for visualizing knee rehabilitation as part of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation have limited ways of assessing exercise form and extent of movement at home. To address this issue, we developed an exploratory wearable electronic prototype to visualize knee bend. We evaluated the device with physical therapy patients to get feedback on the design and to help us understand some of the challenges they face. We discovered that our current design is better suited for patients recovering from surgery as opposed to patients with chronic conditions.",Swamy Ananthanarayan;Miranda Sheh;Alice Chien;Halley Profita;Katie A. Siek,
CHI,2013,Talking about tactile experiences,10.1145/2470654.2466220,"A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants' verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.",Marianna Obrist;Sue Ann Seah;Sriram Subramanian,
CHI,2013,HeartLink: open broadcast of live biometric data to social networks,10.1145/2470654.2466231,"A number of studies in the literature have looked into the use of real-time biometric data to improve one's own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one's social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.",Franco Curmi;Maria Angela Ferrario;Jen Southern;Jon Whittle 0001,
CHI,2013,TouchViz: a case study comparing two interfaces for data analytics on tablets,10.1145/2470654.2481318,"As more applications move from the desktop to touch devices like tablets, designers must wrestle with the costs of porting a design with as little revision of the UI as possible from one device to the other, or of optimizing the interaction per device. We consider the tradeoffs between two versions of a UI for working with data on a touch tablet. One interface is based on using the conventional desktop metaphor (WIMP) with a control panel, push buttons, and checkboxes -- where the mouse click is effectively replaced by a finger tap. The other interface (which we call FLUID) eliminates the control panel and focuses touch actions on the data visualization itself. We describe our design process and evaluation of each interface. We discuss the significantly better task performance and preference for the FLUID interface, in particular how touch design may challenge certain assumptions about the performance benefits of WIMP interfaces that do not hold on touch devices, such as the superiority of gestural vs. control panel based interaction.",Steven Mark Drucker;Danyel Fisher;Ramik Sadana;Jessica Herron;m. c. schraefel,
CHI,2013,Evaluating the efficiency of physical visualizations,10.1145/2470654.2481359,"Data sculptures are an increasingly popular form of physical visualization whose purposes are essentially artistic, communicative or educational. But can physical visualizations help carry out actual information visualization tasks? We present the first infovis study comparing physical to on-screen visualizations. We focus on 3D visualizations, as these are common among physical visualizations but known to be problematic on computers. Taking 3D bar charts as an example, we show that moving visualizations to the physical world can improve users' efficiency at information retrieval tasks. In contrast, augmenting on-screen visualizations with stereoscopic rendering alone or with prop-based manipulation was of limited help. The efficiency of physical visualizations seems to stem from features that are unique to physical objects, such as their ability to be touched and their perfect visual realism. These findings provide empirical motivation for current research on fast digital fabrication and self-reconfiguring interfaces.",Yvonne Jansen;Pierre Dragicevic;Jean-Daniel Fekete,
CHI,2013,Quantity estimation in visualizations of tagged text,10.1145/2470654.2481373,"A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.",Michael Correll;Eric C. Alexander;Michael Gleicher,
CHI,2013,Contextifier: automatic generation of annotated stock visualizations,10.1145/2470654.2481374,"Online news tools - for aggregation, summarization and automatic generation - are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier, a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier's algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company's history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.",Jessica Hullman;Nicholas Diakopoulos;Eytan Adar,
CHI,2013,Effects of visualization and note-taking on sensemaking and analysis,10.1145/2470654.2481376,"Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools' individual features is rarely tested. In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations. The visualization significantly improved participants' ability to solve the crime whereas the notepad did not. Having both features available provided no benefit over having just the visualization. The results raise questions about the potential constraints on the usefulness of intelligence analysis tools.",Nitesh Goyal;Gilly Leshed;Susan R. Fussell,
CHI,2013,inAir: a longitudinal study of indoor air quality measurements and visualizations,10.1145/2470654.2481380,,Sunyoung Kim;Eric Paulos;Jennifer Mankoff,
CHI,2013,Influencing visual judgment through affective priming,10.1145/2470654.2481410,"Recent research suggests that individual personality differences can influence performance with visualizations. In addition to stable personality traits, research in psychology has found that temporary changes in affect (emotion) can also significantly impact performance during cognitive tasks. In this paper, we show that affective priming also influences user performance on visual judgment tasks through an experiment that combines affective priming with longstanding graphical perception experiments. Our results suggest that affective priming can influence accuracy in common graphical perception tasks. We discuss possible explanations for these findings, and describe how these findings can be applied to design visualizations that are less (or more) susceptible to error in common visualization contexts.",Lane Harrison;Drew Skau;Steven Franconeri;Aidong Lu;Remco Chang,
CHI,2013,Canyon: providing location awareness of multiple moving objects in a detail view on large displays,10.1145/2470654.2466431,"Overview+Detail interfaces can be used to examine the details of complex data while retaining the data's overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person's field of view if they are working at a large interactive surface. To address this ""off-view"" problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually ""folded"" to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.",Alexandra Ion;Yu-Ling Betty Chang;Michael Haller;Mark S. Hancock;Stacey D. Scott,
CHI,2013,Binocular cursor: enabling selection on transparent displays troubled by binocular parallax,10.1145/2470654.2466433,"Binocular parallax is a problem for any interaction system that has a transparent display and objects behind it, as users will see duplicated and overlapped images. In this note, we propose a quantitative measure called Binocular Selectability Discriminant (BSD) to predict the ability of the user to perform selection task in such a setup. In addition, we propose a technique called Binocular Cursor (BC) which takes advantage of this duplicating and overlapping phenomenon, rather than being hampered by it, to resolve binocular selection ambiguity by visualizing the correct selection point. An experiment shows that selection with BC is not slower than monocular selection, and that it can be significantly more precise, depending on the design of BC.",Joon Hyub Lee;Seok-Hyung Bae,
CHI,2013,Interactive horizon graphs: improving the compact visualization of multiple time series,10.1145/2470654.2466441,"Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC), which display small multiples for time series, and the more recent horizon graphs (HG). We propose to unify RLC and HG using a new technique - interactive horizon graphs (IHG) - which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).",Charles Perin;Frédéric Vernier;Jean-Daniel Fekete,
CHI,2013,Patina: dynamic heatmaps for visualizing application usage,10.1145/2470654.2466442,"We present Patina, an application independent system for collecting and visualizing software application usage data. Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system.",Justin Matejka;Tovi Grossman;George W. Fitzmaurice,
CHI,2013,Evaluation of alternative glyph designs for time series data in a small multiple setting,10.1145/2470654.2466443,"We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space. Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point. Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.",Johannes Fuchs 0001;Fabian Fischer 0001;Florian Mansmann;Enrico Bertini;Petra Isenberg,
CHI,2013,"Motif simplification: improving network visualization readability with fan, connector, and clique glyphs",10.1145/2470654.2466444,"Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difficult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simplification, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several benefits: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simplification.",Cody Dunne;Ben Shneiderman,
CHI,2013,Reveal-it!: the impact of a social visualization projection on public awareness and discourse,10.1145/2470654.2466476,"Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it!, a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people's perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.",Nina Valkanova;Sergi Jordà;Martin Tomitsch;Andrew Vande Moere,
CHI,2012,LightGuide: projected visualizations for hand movement guidance,10.1145/2207676.2207702,"LightGuide is a system that explores a new approach to gesture guidance where we project guidance hints directly on a user's body. These projected hints guide the user in completing the desired motion with their body part which is particularly useful for performing movements that require accuracy and proper technique, such as during exercise or physical therapy. Our proof-of-concept implementation consists of a single low-cost depth camera and projector and we present four novel interaction techniques that are focused on guiding a user's hand in mid-air. Our visualizations are designed to incorporate both feedback and feedforward cues to help guide users through a range of movements. We quantify the performance of LightGuide in a user study comparing each of our on-body visualizations to hand animation videos on a computer display in both time and accuracy. Exceeding our expectations, participants performed movements with an average error of 21.6mm, nearly 85% more accurately than when guided by video.",Rajinder Sodhi;Hrvoje Benko;Andrew D. Wilson,
CHI,2012,MirageTable: freehand interaction on a projected augmented reality tabletop,10.1145/2207676.2207704,"Instrumented with a single depth camera, a stereoscopic projector, and a curved screen, MirageTable is an interactive system designed to merge real and virtual worlds into a single spatially registered experience on top of a table. Our depth camera tracks the user's eyes and performs a real-time capture of both the shape and the appearance of any object placed in front of the camera (including user's body and hands). This real-time capture enables perspective stereoscopic 3D visualizations to a single user that account for deformations caused by physical objects on the table. In addition, the user can interact with virtual objects through physically-realistic freehand actions without any gloves, trackers, or instruments. We illustrate these unique capabilities through three application examples: virtual 3D model creation, interactive gaming with real and virtual objects, and a 3D teleconferencing experience that not only presents a 3D view of a remote person, but also a seamless 3D shared task space. We also evaluated the user's perception of projected 3D objects in our system, which confirmed that the users can correctly perceive such objects even when they are projected over different background colors and geometries (e.g., gaps, drops).",Hrvoje Benko;Ricardo Jota;Andrew Wilson,
CHI,2012,Interpretation and trust: designing model-driven visualizations for text analysis,10.1145/2207676.2207738,"Statistical topic models can help analysts discover patterns in large text corpora by identifying recurring sets of words and enabling exploration by topical concepts. However, understanding and validating the output of these models can itself be a challenging analysis task. In this paper, we offer two design considerations - interpretation and trust - for designing visualizations based on data-driven models. Interpretation refers to the facility with which an analyst makes inferences about the data through the lens of a model abstraction. Trust refers to the actual and perceived accuracy of an analyst's inferences. These considerations derive from our experiences developing the Stanford Dissertation Browser, a tool for exploring over 9,000 Ph.D. theses by topical similarity, and a subsequent review of existing literature. We contribute a novel similarity measure for text collections based on a notion of ""word-borrowing"" that arose from an iterative design process. Based on our experiences and a literature review, we distill a set of design recommendations and describe how they promote interpretable and trustworthy visual analysis tools.",Jason Chuang;Daniel Ramage;Christopher D. Manning;Jeffrey Heer,
CHI,2012,V-model: a new innovative model to chronologically visualize narrative clinical texts,10.1145/2207676.2207739,"Visualizing narrative medical events into a timeline can have positive effects on clinical environments. However, the characteristics of natural language and medical environments make this representation more difficult. This paper explains the obstacles and suggests a solution called the V-Model. The V-Model is a new innovative time model that was developed to represent chronological narrative events in a medical domain. Forty medical students participated in evaluating this model. The experimental results show the new model successfully solved the modeling requirements and had better usability compared to conventional timeline models. All the participants assessed the new timeline as very useful in effectively understanding a patient's history.",Heekyong Park;Jinwook Choi,
CHI,2012,JigsawMap: connecting the past to the future by mapping historical textual cadasters,10.1145/2207676.2207740,"In this paper, we present an interactive visualization tool, JigsawMap, for visualizing and mapping historical textual cadasters. A cadaster is an official register that records land properties (e.g., location, ownership, value and size) for land valuation and taxation. Such mapping of old and new cadasters can help historians understand the social/economic background of changes in land uses or ownership. With JigsawMap, historians can continue mapping older or newer cadasters. In this way, JigsawMap can connect the past land survey results to today and to the future. We conducted usability studies and long term case studies to evaluate JigsawMap, and received positive responses. As well as summarizing the evaluation results, we also present design guidelines for participatory design projects with historians.",Hyungmin Lee;Sooyun Lee;Namwook Kim;Jinwook Seo,
CHI,2012,Semantic interaction for visual text analytics,10.1145/2207676.2207741,"Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual document collections in a spatial metaphor, where similarities between documents are approximately represented through their relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analysts' mental models of the document collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users must interact with such visualizations using controls external to the visual metaphor, such as sliders, menus, or text fields, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called semantic interaction, which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, called ForceSPIRE, for interactive analysis of textual data within a spatial visualization. Analysts can express their expert domain knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking the user's feedback into account.",Alex Endert;Patrick Fiaux;Chris North 0001,
CHI,2012,EEG analysis of implicit human visual perception,10.1145/2207676.2207746,"Image Based Rendering (IBR) allows interactive scene exploration from images alone. However, despite considerable development in the area, one of the main obstacles to better quality and more realistic visualizations is the occurrence of visually disagreeable artifacts. In this paper we present a methodology to map out the perception of IBR-typical artifacts. This work presents an alternative to traditional image and video quality evaluation methods by using an EEG device to determine the implicit visual processes in the human brain. Our work demonstrates the distinct differences in the perception of different types of visual artifacts and the implications of these differences.",Maryam Mustafa;Lea Lindemann;Marcus A. Magnor,
CHI,2012,Video summagator: an interface for video summarization and navigation,10.1145/2207676.2207767,"This paper presents Video Summagator (VS), a volume-based interface for video summarization and navigation. VS models a video as a space-time cube and visualizes the video cube using real-time volume rendering techniques. VS empowers a user to interactively manipulate the video cube. We show that VS can quickly summarize both the static and dynamic video content by visualizing the space-time information in 3D. We demonstrate that VS enables a user to quickly look into the video cube, understand the content, and navigate to the content of interest.",Cuong Nguyen 0003;Yuzhen Niu;Feng Liu 0015,
CHI,2012,Delta: a tool for representing and comparing workflows,10.1145/2207676.2208549,"Tutorials and sample workflows for complicated, feature-rich software packages are widely available online. As a result users must differentiate between workflows to choose the most suitable one for their task. We present Delta, an interactive workflow visualization and comparison tool that helps users identify the tradeoffs between workflows. We conducted an initial study to identify the set of attributes users attend to when comparing workflows, finding that they consider result quality, their knowledge of commands, and the efficiency of the workflow. We then designed Delta to surface these attributes at three granularities: a high-level, clustered view; an intermediate-level list view that contains workflow summaries; and a low-level detail view that allows users to compare two individual workflows. Finally, we conducted an evaluation of Delta on a small corpus of 30 workflows and found that the intermediate list view provided the best information density. We conclude with thoughts on how such a workflow comparison system could be scaled up to larger corpora in the future.",Nicholas Kong;Tovi Grossman;Björn Hartmann;Maneesh Agrawala;George W. Fitzmaurice,
CHI,2012,Omnipedia: bridging the wikipedia language gap,10.1145/2207676.2208553,"We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.",Patti Bao;Brent J. Hecht;Samuel Carton;Mahmood Quaderi;Michael S. Horn;Darren Gergle,
CHI,2012,Comparing averages in time series data,10.1145/2207676.2208556,"Visualizations often seek to aid viewers in assessing the big picture in the data, that is, to make judgments about aggregate properties of the data. In this paper, we present an empirical study of a representative aggregate judgment task: finding regions of maximum average in a series. We show how a theory of perceptual averaging suggests a visual design other than the typically-used line graph. We describe an experiment that assesses participants' ability to estimate averages and make judgments based on these averages. The experiment confirms that this color encoding significantly outperforms the standard practice. The experiment also provides evidence for a perceptual averaging theory.",Michael Correll;Danielle Albers;Steven Franconeri;Michael Gleicher,
CHI,2012,A spatiotemporal visualization approach for the analysis of gameplay data,10.1145/2207676.2208558,"Contemporary video games are highly complex systems with many interacting variables. To make sure that a game provides a satisfying experience, a meaningful analysis of gameplay data is crucial, particularly because the quality of a game directly relates to the experience a user gains from playing it. Automatic instrumentation techniques are increasingly used to record data during playtests. However, the evaluation of the data requires strong analytical skills and experience. The visualization of such gameplay data is essentially an information visualization problem, where a large number of variables have to be displayed in a comprehensible way in order to be able to make global judgments. This paper presents a visualization tool to assist the analytical process. It visualizes the game space as a set of nodes which players visit over the course of a game and is also suitable to observe time-dependent information, such as player distribution. Our tool is not tailored to a specific type of genre. To show the flexibility of our approach we use two different kinds of games as case studies.",Günter Wallner;Simone Kriglstein,
CHI,2012,Interactive visualization for low literacy users: from lessons learnt to design,10.1145/2207676.2208565,"This paper aims to address the problems low literacy (LL) users face when searching for information online. The first part of this paper summarizes the problems that LL user's face, and establishes a set of design principles for interfaces suitable for LL users. This is followed by a description of how these design principles are mapped to a novel interface for interactive data retrieval. The interface was realized into a working system and evaluated against a traditional web interface for both high literacy (HL) and LL users. The suitability of the designs was analyzed using performance data, subjective feedback and an observational analysis. The findings from the study suggest that LL users perform better and prefer the proposed designs over a traditional web interface.",Neesha Kodagoda;B. L. William Wong;Chris Rooney;Nawaz Khan,
CHI,2012,Digital pen and paper practices in observational research,10.1145/2207676.2208590,"Researchers from many disciplines are taking advantage of increasingly inexpensive digital video to capture extensive records of human activity in real-world settings. The ability to record and share such data has created a critical moment in the practice and scope of behavioral research. While recent work is beginning to develop techniques for visualizing and interacting with integrated multimodal information collected during field research, navigating and analyzing these large datasets remains challenging and tools are especially needed to support the early stages of data exploration. In this paper we describe digital pen and paper practices in observational research and their integration with ChronoViz, a tool for annotating, visualizing, and analyzing multimodal data. The goal is to better support researchers both in the field, while collecting data, and later in the lab, during analysis. We document the co-evolution of notetaking practices and system features as 28 participants used the tool during an 18-month deployment.",Nadir Weibel;Adam Fouse;Colleen Emmenegger;Whitney Friedman;Edwin L. Hutchins;James D. Hollan,
CHI,2012,The case of the missed icon: change blindness on mobile devices,10.1145/2207676.2208606,"Insights into human visual attention have benefited many areas of computing, but perhaps most significantly visualisation and UI design [3]. With the proliferation of mobile devices capable of supporting significantly complex applications on small screens, demands on mobile UI design and the user's visual system are becoming greater. In this paper, we report results from an empirical study of human visual attention, specifically the Change Blindness phenomenon, on handheld mobile devices and its impact on mobile UI design. It is arguable that due to the small size of the screen - unlike a typical computer monitor - a greater visual coverage of the mobile device is possible, and that these phenomena may occur less frequently during the use of the device, or even that they may not occur at all. Our study shows otherwise. We tested for Change Blindness (CB) and Inattentional Blindness (IB) in a single-modal, mobile context and attempted to establish factors in the application interface design that induce and/or reduce their occurrences. The results show that both CB and IB can and do occur while using mobile devices. The results also suggest that the number of separate attendable items on-screen is directly proportional to rates of CB. Newly inserted objects were correctly identified more often than changes applied to existing on-screen objects. These results suggest that it is important for mobile UI designers to take these aspects of visual attention into account when designing mobile applications that attempt to deliver information through visual changes or notifications.",Thomas Davies;Ashweeni Kumar Beeharee,
CHI,2012,The bohemian bookshelf: supporting serendipitous book discoveries through information visualization,10.1145/2207676.2208607,"Serendipity, a trigger of exciting yet unexpected discoveries, is an important but comparatively neglected factor in information seeking, research, and ideation. We suggest that serendipity can be facilitated through visualization. To explore this, we introduce the Bohemian Bookshelf, which aims to support serendipitous discoveries in the context of digital book collections. The Bohemian Bookshelf consists of five interlinked visualizations each offering a unique overview of the collection. It aims at encouraging serendipity by (1) offering multiple visual access points to the collection, (2) highlighting adjacencies between books, (3) providing flexible visual pathways for exploring the collection, (4) enticing curiosity through abstract, metaphorical, and visually distinct representations of books, and (5) enabling a playful approach to information exploration. A deployment at a library revealed that visitors embraced this approach of utilizing visualization to support open-ended explorations and serendipitous discoveries. This encourages future explorations into promoting serendipity through information visualization.",Alice Thudt;Uta Hinrichs;Sheelagh Carpendale,
CHI,2012,Supporting improvisation work in inter-organizational crisis management,10.1145/2207676.2208617,"Improvisation is necessary when planned decision-making as the main managerial activity does not fit the conditions the practice provides. In these cases, information technology should not just automate planned and structured decisions, but support improvisational practice. In this contribution we present an empirical study about the improvisation work in scenarios of medium to large power outages in Germany. Our focus is on inter-organizational cooperation practices, thus we examined the cooperation of fire departments, police, public administration, electricity infrastructure operators and citizens. Our empirical material allows to describe reasons and conditions for improvisation. Our resulting recommendations address the support of aggregation and visualization of information, a necessary individualization of information compositions, options for collaborative situation assessment, requirements for informal and formal communication, and accessibility of information resources.",Benedikt Ley;Volkmar Pipek;Christian Reuter 0001;Torben Wiedenhoefer,
CHI,2012,Annotating BI visualization dashboards: needs & challenges,10.1145/2207676.2208288,"Annotations have been identified as an important aid in analysis record-keeping and recently data discovery. In this paper we discuss the use of annotations on visualization dashboards, with a special focus on business intelligence (BI) analysis. In-depth interviews with experts lead to new annotation needs for multi-chart visualization systems, on which we based the design of a dashboard prototype that supports data and context aware annotations. We focus particularly on novel annotation aspects, such as multi-target annotations, annotation transparency across charts and data dimension levels, as well as annotation properties such as lifetime and validity. Moreover, our prototype is built on a data layer shared among different data-sources and BI applications, allowing cross application annotations. We discuss challenges in supporting context aware annotations in dashboards and other visualizations, such as dealing with changing annotated data, and provide design solutions. Finally we report reactions and recommendations from a different set of expert users.",Micheline Elias;Anastasia Bezerianos,
CHI,2012,Analysis within and between graphs: observed user strategies in immunobiology visualization,10.1145/2207676.2208291,"We present an analysis of two user strategies in interactive data analysis, based on an observational study of four researchers in the immunology domain. Screen captures, video records, interviews, and verbal protocols are used to analyze common procedures in this type of visual data analysis, as well as how these procedures differ among these users. Our findings present a case where skilled users can approach a similar problem with diverging analysis strategies. In the group we observed, strategies fell within two broad categories: within-graph analysis, in which a user generates a few graph layouts and interacts heavily within them, and between-graph analysis, in which a user generates a series of graphs and switches between them in sequence. Differences in strategies lead to distinct interaction patterns, and are likely to be best supported by different interface designs. We characterize these observed strategies and discuss their implications for scientific visualization design and evaluation.",Caroline Ziemkiewicz;Steven R. Gomez;David H. Laidlaw,
CHI,2012,Understanding the verbal language and structure of end-user descriptions of data visualizations,10.1145/2207676.2208292,"Tools exist for people to create visualizations with their data; however, they are often designed for programmers or they restrict less technical people to pre-defined templates. This can make creating novel, custom visualizations difficult for the average person. For example, existing tools typically do not support syntax or interaction techniques that are natural to end users. To explore how to support a more natural production of data visualizations by end users, we conducted an exploratory study to illuminate the structure and content of the language employed by end users when describing data visualizations. We present our findings from the study and discuss their design implications for future visualization languages and toolkits.",Ronald A. Metoyer;Bongshin Lee;Nathalie Henry Riche;Mary Czerwinski,
CHI,2012,"GraphTrail: analyzing large multivariate, heterogeneous networks while supporting exploration history",10.1145/2207676.2208293,"Exploring large network datasets, such as scientific collaboration networks, is challenging because they often contain a large number of nodes and edges in several types and with multiple attributes. Analyses of such networks are often long and complex, and may require several sessions by multiple users. Therefore, it is often difficult for users to recall their own exploration history or share it with others. We introduce GraphTrail, an interactive visualization for analyzing networks through exploration of node and edge aggregates that captures users' interactions and integrates this history directly in the exploration workspace. To facilitate large network analysis, GraphTrail integrates aggregation with familiar charts, drag-and-drop interaction on a canvas, and a novel pivoting mechanism for transitioning between aggregates. Through a three-month field study with a team of archeologists and a qualitative lab study with ten users, we demonstrate the effectiveness of our design and the benefits of integrated exploration history, including analysis comprehension, insight discovery, and exploration recall.",Cody Dunne;Nathalie Henry Riche;Bongshin Lee;Ronald A. Metoyer;George G. Robertson,
CHI,2012,"Trust me, i'm partially right: incremental visualization lets analysts explore large datasets faster",10.1145/2207676.2208294,Queries over large scale (petabyte) data bases often mean waiting overnight for a result to come back. Scale costs time. Such time also means that potential avenues of exploration are ignored because the costs are perceived to be too high to run or even propose them. With sampleAction we have explored whether interaction techniques to present query results running over only incremental samples can be presented as sufficiently trustworthy for analysts both to make closer to real time decisions about their queries and to be more exploratory in their questions of the data. Our work with three teams of analysts suggests that we can indeed accelerate and open up the query process with such incremental visualizations.,Danyel Fisher;Igor O. Popov;Steven Mark Drucker;m. c. schraefel,
CHI,2012,"""I'd never get out of this !?$%# office"": redesigning time management for the enterprise",10.1145/2207676.2208307,"In this paper, we propose to improve time management in the enterprise by providing users interactive visualizations of how they are spending their time. Through an interview study (n=21) in a multi-national corporation, we were able to determine the data available for visualizations and the value of a number of general visualizations of employees' calendar data. We develop implications for design in improving personal time management.",Casey Dugan;Werner Geyer;Michael J. Muller;Abel N. Valente;Katherine James;Steve Levy;Li-Te Cheng;Elizabeth M. Daly;Beth Brownholtz,
CHI,2012,"Legible, are you sure?: an experimentation-based typographical design in safety-critical context",10.1145/2207676.2208387,"Designing Safety-critical interfaces entails proving the safety and operational usability of each component. Largely taken for granted in everyday interface design, the typographical component, through its legibility and aesthetics, weighs heavily on the ubiquitous reading task at the heart of most visualizations and interactions. In this paper, we present a research project whose goal is the creation of a new typeface to display textual information on future aircraft interfaces. After an initial task analysis leading to the definition of specific needs, requirements and design principles, the design constantly evolves from an iterative cycle of design and experimentation. We present three experiments (laboratory and cockpit) used mainly to validate initial choices and fine-tune font properties. Results confirm the importance of rigorously testing the typographical component as a part of text output evaluation in interactive systems.",Jean-Luc Vinot;Sylvie Athènes,
CHI,2012,Observational and experimental investigation of typing behaviour using virtual keyboards for mobile devices,10.1145/2207676.2208658,"With the rise of current smartphones, virtual keyboards for touchscreens became the dominant mobile text entry technique. We developed a typing game that records how users touch on the standard Android keyboard to investigate users' typing behaviour. 47,770,625 keystrokes from 72,945 installations have been collected by publishing the game. By visualizing the touch distribution we identified a systematic skew and derived a function that compensates this skew by shifting touch events. By updating the game we conduct an experiment that investigates the effect of shifting touch events, changing the keys' labels, and visualizing the touched position. Results based on 6,603,659 keystrokes and 13,013 installations show that visualizing the touched positions using a simple dot decreases the error rate of the Android keyboard by 18.3% but also decreases the speed by 5.2% with no positive effect on learnability. The Android keyboard outperforms the control condition but the constructed shift function further improves the performance by 2.2% and decreases the error rate by 9.1%. We argue that the shift function can improve existing keyboards at no costs.",Niels Henze;Enrico Rukzio;Susanne Boll,
CHI,2012,Tangible remote controllers for wall-size displays,10.1145/2207676.2208691,"We explore the use of customizable tangible remote controllers for interacting with wall-size displays. Such controllers are especially suited to visual exploration tasks where users need to move to see details of complex visualizations. In addition, we conducted a controlled user study suggesting that tangibles make it easier for users to focus on the visual display while they interact. We explain how to build such controllers using off-the-shelf touch tablets and describe a sample application that supports multiple dynamic queries.",Yvonne Jansen;Pierre Dragicevic;Jean-Daniel Fekete,
CHI,2012,Gaze-augmented think-aloud as an aid to learning,10.1145/2207676.2208710,"The use of recorded eye movements, or scanpaths, has been demonstrated as an effective visualization for feed-forward visual search training, instruction, and stimulated retrospective think-aloud usability testing. In this paper we show that creation of a scripted or recorded video of an expert's think-aloud session augmented by an animation of their scanpaths can result in an effective aid for learners of visual search. Because the creation of such a video is relatively easy, the benefits-to-cost ratio may potentially be substantial, especially in settings where learned visual scanning strategies are indicators of expertise. We suggest that two such examples are examinations of Chest X-Rays and histological slides. Results are presented where straightforward construction of an instruction video provides measurable benefit to novice as well as experienced learners in the latter context.",Sarah A. Vitak;John E. Ingram;Andrew T. Duchowski;Steven Ellis;Anand K. Gramopadhye,
CHI,2012,WebCrystal: understanding and reusing examples in web authoring,10.1145/2207676.2208740,"Examples have been widely used in the area of web design to help web authors create web pages. However, without actually understanding how an example is constructed, people often have trouble extracting the elements they want and incorporating them into their own design. This paper introduces WebCrystal, a web development tool that helps users understand how a web page is built. WebCrystal contributes novel interaction techniques that let the user quickly access HTML and CSS information by selecting questions regarding how a selected element is designed. It provides answers using a textual description and a customized code snippet that can be copied-and-pasted to recreate the desired properties. WebCrystal also supports combining the styles and structures from multiple elements into the generated code snippet, and provides visualizations on the web page itself to explain layout relationships. Our user study shows that WebCrystal helped both novice and experienced developers complete more tasks successfully using significantly less time.",Kerry Shih-Ping Chang;Brad A. Myers,
CHI,2011,CueT: human-guided fast and accurate network alarm triage,10.1145/1978942.1978966,"Network alarm triage refers to grouping and prioritizing a stream of low-level device health information to help operators find and fix problems. Today, this process tends to be largely manual because existing tools cannot easily evolve with the network. We present CueT, a system that uses interactive machine learning to learn from the triaging decisions of operators. It then uses that learning in novel visualizations to help them quickly and accurately triage alarms. Unlike prior interactive machine learning systems, CueT handles a highly dynamic environment where the groups of interest are not known a-priori and evolve constantly. A user study with real operators and data from a large network shows that CueT significantly improves the speed and accuracy of alarm triage compared to the network's current practice.",Saleema Amershi;Bongshin Lee;Ashish Kapoor;Ratul Mahajan;Blaine Christian,
CHI,2011,Apolo: making sense of large network data by combining rich user interaction and machine learning,10.1145/1978942.1978967,"Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.",Duen Horng Chau;Aniket Kittur;Jason I. Hong;Christos Faloutsos,
CHI,2011,Twitinfo: aggregating and visualizing microblogs for event exploration,10.1145/1978942.1978975,"Microblogs are a tremendous repository of user-generated content about world events. However, for people trying to understand events by querying services like Twitter, a chronological log of posts makes it very difficult to get a detailed understanding of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing events on Twitter. TwitInfo allows users to browse a large collection of tweets using a timeline-based display that highlights peaks of high tweet activity. A novel streaming algorithm automatically discovers these peaks and labels them meaningfully using text from the tweets. Users can drill down to subevents, and explore further via geolocation, sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment visualization to produce more honest sentiment overviews. An evaluation of the system revealed that users were able to reconstruct meaningful summaries of events in a small amount of time. An interview with a Pulitzer Prize-winning journalist suggested that the system would be especially useful for understanding a long-running event and for identifying eyewitnesses. Quantitatively, our system can identify 80-100% of manually labeled peaks, facilitating a relatively complete view of each event studied.",Adam Marcus 0002;Michael S. Bernstein;Osama Badar;David R. Karger;Samuel Madden 0001;Robert C. Miller,
CHI,2011,Many bills: engaging citizens through visualizations of congressional legislation,10.1145/1978942.1979004,"US federal legislation is a common subject of discussion and advocacy on the web, inspired by the open government movement. While the contents of these bills are freely available for download, understanding them is a significant challenge to experts and average citizens alike due to their length, complex language, and obscure topics. To make these important documents more accessible to the general public, we present Many Bills (http://manybills.us): a web-based set of visualization tools that reveals the underlying semantics of a bill. Using machine learning techniques, we classify each bill's sections based on existing document-level categories. We then visualize the resulting topic substructure of these bills. These visualizations provide an overview-and-detail view of bills, enabling users to read individual sections of a bill and compare topic patterns across multiple bills. Through an overview of the site's user activity and interviews with active users, this paper highlights how Many Bills makes the tasks of reading bills, identifying outlier sections in bills, and understanding congressperson's legislative activity more manageable.",Yannick Assogba;Irene Ros;Joan Morris DiMicco;Matt McKeon,
CHI,2011,Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool,10.1145/1978942.1979072,"Internet users are targets for ever-advancing phishing- and other attacks. The risks are, for example, to disclose credit card information or passwords to unauthorized instances. One approach to help users with insecure situations is provided by MoodyBoard, which uses ambient information to highlight potential risks. In this paper, we present findings from an evaluation of this system. Two user studies were conducted in order to find out whether an ambient security tool can protect users during sensitive tasks. We designed a pilot study to find out whether users understand the warnings and a security study to see if it helps to protect users from phishing attacks. Results show that MoodyBoard users behaved significantly more secure.",Alexander De Luca;Bernhard Frauendienst;Max-Emanuel Maurer;Julian Seifert;Doris Hausen;Niels Kammerer;Heinrich Hussmann,
CHI,2011,Enhancing credibility judgment of web search results,10.1145/1978942.1979126,"In this paper, we propose a system for helping users to judge the credibility of Web search results and to search for credible Web pages. Conventional Web search engines present only titles, snippets, and URLs for users, which give few clues to judge the credibility of Web search results. Moreover, ranking algorithms of the conventional Web search engines are often based on relevance and popularity of Web pages. Towards credibility-oriented Web search, our proposed system provides users with the following three functions: (1) calculation and visualization of several scores of Web search results on the main credibility aspects, (2) prediction of user's credibility judgment model through user's credibility feedback for Web search results, and (3) re-ranking of Web search results based on user's predicted credibility model. Experimental results suggest that our system enables users - in particular, users with knowledge about search topics - to find credible Web pages from a list of Web search results more efficiently than conventional Web search interfaces.",Yusuke Yamamoto;Katsumi Tanaka,
CHI,2011,Augmenting web pages and search results to support credibility assessment,10.1145/1978942.1979127,"The presence (and, sometimes, prominence) of incorrect and misleading content on the Web can have serious consequences for people who increasingly rely on the internet as their information source for topics such as health, politics, and financial advice. In this paper, we identify and collect several page features (such as popularity among specialized user groups) that are currently difficult or impossible for end users to assess, yet provide valuable signals regarding credibility. We then present visualizations designed to augment search results and Web pages with the most promising of these features. Our lab evaluation finds that our augmented search results are particularly effective at increasing the accuracy of users'"" credibility assessments, highlighting the potential of data aggregation and simple interventions to help people make more informed decisions as they search for information online.",Julia Schwarz;Meredith Ringel Morris,
CHI,2011,2d touching of 3d stereoscopic objects,10.1145/1978942.1979142,"Recent developments in the area of touch and display technologies have suggested to combine multi-touch systems and stereoscopic visualization. Stereoscopic perception requires each eye to see a slightly different perspective of the same scene, which results in two distinct projections on the display. Thus, if the user wants to select a 3D stereoscopic object in such a setup, the question arises where she would touch the 2D surface to indicate the selection. A user may apply different strategies, for instance touching the midpoint between the two projections, or touching one of them. In this paper we analyze the relation between the 3D positions of stereoscopically rendered objects and the on-surface touch points, where users touch the surface. We performed an experiment in which we determined the positions of the users' touches for objects, which were displayed with positive, negative or zero parallaxes. We found that users tend to touch between the projections for the two eyes with an offset towards the projection for the dominant eye. Our results give implications for the development of future touch-enabled interfaces, which support 3D stereoscopic visualization.",Dimitar Valkov;Frank Steinicke;Gerd Bruder;Klaus H. Hinrichs,
CHI,2011,Evaluating video visualizations of human behavior,10.1145/1978942.1979155,"Previously, we presented Viz-A-Vis, a VIsualiZation of Activity through computer VISion [17]. Viz-A-Vis visualizes behavior as aggregate motion over observation space. In this paper, we present two complementary user studies of Viz-A-Vis measuring its performance and discovery affordances. First, we present a controlled user study aimed at comparatively measuring behavioral analysis preference and performance for observation and search tasks. Second, we describe a study with architects measuring discovery affordances and potential impacts on their work practices. We conclude: 1) Viz-A-Vis significantly reduced search time; and 2) it increased the number and quality of insightful discoveries.",Mario Romero;Alice Vialard;John Peponis;John T. Stasko;Gregory D. Abowd,
CHI,2011,"Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces",10.1145/1978942.1979156,"Whereas the literature is clear on the benefits of large displays and visualizations, little is known about their combination, that is, how display size affect the usability of visualizations. We describe a controlled experiment where 19 participants used focus+context, overview+detail, and zooming techniques with varying display sizes (13.8, 1.5, and 0.17 megapixels). Participants navigated geographical maps to find specific locations, compare items, and follow routes. Results show that for multi-scale navigation, classic interactive visualization techniques did not benefit from being scaled to a large display: In contrast to the literature we find similar performance on medium and large displays. Across display sizes, overview+detail works the best, in particular for comparing items. Focus+context is relatively more difficult to use at a small display size. We explain these findings and discuss the design of interactive visualization techniques for large displays.",Mikkel Rønne Jakobsen;Kasper Hornbæk,
CHI,2011,The impact of social information on visual judgments,10.1145/1978942.1979157,"Social visualization systems have emerged to support collective intelligence-driven analysis of a growing influx of open data. As with many other online systems, social signals (e.g., forums, polls) are commonly integrated to drive use. Unfortunately, the same social features that can provide rapid, high-accuracy analysis are coupled with the pitfalls of any social system. Through an experiment involving over 300 subjects, we address how social information signals (social proof) affect quantitative judgments in the context of graphical perception. We identify how unbiased social signals lead to fewer errors over non-social settings and conversely, how biased signals lead to more errors. We further reflect on how systematic bias nullifies certain collective intelligence benefits, and we provide evidence of the formation of information cascades. We describe how these findings can be applied to collaborative visualization systems to produce more accurate individual interpretations in social contexts.",Jessica Hullman;Eytan Adar;Priti Shah,
CHI,2011,"Multi-touch document folding: gesture models, fold directions and symmetries",10.1145/1978942.1979174,"For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections. To enable richer interaction, we explore the design space of multi-touch document folding. We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures. We categorize gesture models along the characteristics of Symmetric/Asymmetric and Serial/Parallel, which yields three gesture models. We built a prototype document workspace application that integrates folding and standard gestures, and a system for testing the gesture models. A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance when folding a document to a specific shape. Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets.",Patrick Chiu;Chunyuan Liao;Francine Chen 0001,
CHI,2011,Playable data: characterizing the design space of game-y infographics,10.1145/1978942.1979193,"This work explores the intersection between infographics and games by examining how to embed meaningful visual analytic interactions into game mechanics that in turn impact user behavior around a data-driven graphic. In contrast to other methods of narrative visualization, games provide an alternate method for structuring a story, not bound by a linear arrangement but still providing structure via rules, goals, and mechanics of play. We designed two different versions of a game-y infographic, Salubrious Nation, and compared them to a non-game-y version in an online experiment. We assessed the relative merits of the game-y approach of presentation in terms of exploration of the visualization, insights and learning, and enjoyment of the experience. Based on our results, we discuss some of the benefits and drawbacks of our designs. More generally, we identify challenges and opportunities for further exploration of this new design space.",Nicholas Diakopoulos;Funda Kivran-Swaine;Mor Naaman,
CHI,2011,Cardiogram: visual analytics for automotive engineers,10.1145/1978942.1979194,"We present Cardiogram, a visual analytics system that supports automotive engineers in debugging masses of traces each consisting of millions of recorded messages from in-car communication networks. With their increasing complexity, ensuring these safety-critical networks to be error-free has become a major task and challenge for automotive engineers. To overcome shortcomings of current analysis tools, Cardiogram combines visualization techniques with a data preprocessing approach to automatically reduce complexity based on engineers' domain knowledge. In this paper, we provide the findings from an exploratory, three-year field study within a large automotive company, studying current practices of engineers, the challenges they meet and the characteristics for integrating novel visual analytics tools into their work practices. We then introduce Cardiogram, discuss how our field analysis influenced our design decisions, and present a qualitative, long-term, in-depth evaluation. Results of this study showed that our participants successfully used Cardiogram to increase the amount of analyzable information, to externalize domain knowledge, and to provide new insights into trace data. Our design approach finally led to the adoption of Cardiogram into engineers' daily practices.",Michael Sedlmair;Petra Isenberg;Dominikus Baur;Michael Mauerer;Christian Pigorsch;Andreas Butz,
CHI,2011,KronoMiner: using multi-foci navigation for the visual exploration of time-series data,10.1145/1978942.1979195,"The need for pattern discovery in long time-series data led researchers to develop interactive visualization tools and analytical algorithms for gaining insight into the data. Most of the literature on time-series data visualization either focus on a small number of tasks or a specific domain. We propose KronoMiner, a tool that embeds new interaction and visualization techniques as well as analytical capabilities for the visual exploration of time-series data. The interface's design has been iteratively refined based on feedback from expert users. Qualitative evaluation with an expert user not involved in the design process indicates that our prototype is promising for further research.",Jian Zhao 0010;Fanny Chevalier;Ravin Balakrishnan,
CHI,2011,LifeFlow: visualizing an overview of event sequences,10.1145/1978942.1979196,"Event sequence analysis is an important task in many domains: medical researchers may study the patterns of transfers within the hospital for quality control; transportation experts may study accident response logs to identify best practices. In many cases they deal with thousands of records. While previous research has focused on searching and browsing, overview tasks are often overlooked. We introduce a novel interactive visual overview of event sequences called \emph{LifeFlow}. LifeFlow is scalable, can summarize all possible sequences, and represents the temporal spacing of the events within sequences. Two case studies with healthcare and transportation domain experts are presented to illustrate the usefulness of LifeFlow. A user study with ten participants confirmed that after 15 minutes of training novice users were able to rapidly answer questions about the prevalence and temporal characteristics of sequences, find anomalies, and gain significant insight from the data.",Krist Wongsuphasawat;John Alexis Guerra Gómez;Catherine Plaisant;Taowei David Wang;Meirav Taieb-Maimon;Ben Shneiderman,
CHI,2011,Evaluating longitudinal projects combining technology with temporal arts,10.1145/1978942.1979209,"The integration of interactive technology with temporal art such as dance is an exciting, emerging area. The design space for such collaborations is immense, with variations in sensors, visualizations, and how these interact with dancers and choreography. This paper presents the evaluation methodology and results of Dance.Draw, a longitudinal project spanning two years and three productions, which aimed to develop a deep, interdisciplinary understanding of this space. Given that this is pioneering work, there is little guidance on how to evaluate such collaborations. We describe the significant confounds in doing evaluation in this area, and we present our evolving mixed-methods approach, which includes two unique methods to address the multiple stakeholders in a holistic manner: dancer focus groups and repeated presentations. Our approach has generated insights, such as differing perspectives of audience members and the responses of dancers to technological variables. We conclude by discussing the challenges and successes of our evaluation approach.",Celine Latulipe;Erin A. Carroll;Danielle M. Lottridge,
CHI,2011,The polymath project: lessons from a successful online collaboration in mathematics,10.1145/1978942.1979213,"Although science is becoming increasingly collaborative, there are remarkably few success stories of online collaborations between professional scientists that actually result in real discoveries. A notable exception is the Polymath Project, a group of mathematicians who collaborate online to solve open mathematics problems. We provide an in-depth descriptive history of Polymath, using data analysis and visualization to elucidate the principles that led to its success, and the difficulties that must be addressed before the project can be scaled up. We find that although a small percentage of users created most of the content, almost all users nevertheless contributed some content that was highly influential to the task at hand. We also find that leadership played an important role in the success of the project. Based on our analysis, we present a set of design suggestions for how future collaborative mathematics sites can encourage and foster newcomer participation.",Justin Cranshaw;Aniket Kittur,
CHI,2011,Location visualization in social media applications,10.1145/1978942.1979298,"Location sharing applications are becoming increasingly popular in social media and for use on mobile devices, yet little research has focused on their user interface design. In this paper we describe our method of charting and creating comparable designs, and present a survey-based study of 106 social media users on their preferences regarding location indicators. Our paper contributes in proposing a methodology for visual element evaluation purposes, and reveals results, e.g., that users preferred simple indicators such as points or pins for their own location, and friend location indicators to include the corresponding name.",Minna Pakanen;Jussi Huhtala;Jonna Häkkilä,
CHI,2011,Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops,10.1145/1978942.1979390,"We introduce ""Facet-Streams"", a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.",Hans-Christian Jetter;Jens Gerken;Michael Zöllner;Harald Reiterer;Natasa Milic-Frayling,
CHI,2011,CommentSpace: structured support for collaborative visual analysis,10.1145/1978942.1979407,"Collaborative visual analysis tools can enhance sensemaking by facilitating social interpretation and parallelization of effort. These systems enable distributed exploration and evidence gathering, allowing many users to pool their effort as they discuss and analyze the data. We explore how adding lightweight tag and link structure to comments can aid this analysis process. We present CommentSpace, a collaborative system in which analysts comment on visualizations and websites and then use tags and links to organize findings and identify others'"" contributions. In a pair of studies comparing CommentSpace to a system without support for tags and links, we find that a small, fixed vocabulary of tags (question, hypothesis, to-do) and links (evidence-for, evidence-against) helps analysts more consistently and accurately classify evidence and establish common ground. We also find that managing and incentivizing participation is important for analysts to progress from exploratory analysis to deeper analytical tasks. Finally, we demonstrate that tags and links can help teams complete evidence gathering and synthesis tasks and that organizing comments using tags and links improves analytic results.",Wesley Willett;Jeffrey Heer;Joseph M. Hellerstein;Maneesh Agrawala,
CHI,2011,ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading,10.1145/1978942.1979417,"We present a method for displaying prosody, the melody of speech, to aid beginning readers with fluent oral reading. We build on proven auditory techniques by manipulating and augmenting text in children's stories. The acoustic properties of a fluent recording are used to construct visualizations of pitch, loudness and length variations in read samples aligned with text. Our initial approach was to directly manipulate text, which was tested on ten children who showed significant increases in pitch modulation with manipulated text but reported difficulty with word recognition. This motivated designing the augmented text renderings, which display prosodic cues layered with text. Manipulated and augmented texts were compared with two beginning readers. Children showed similar prosodic gains with both versions and reported greater satisfaction with augmented pitch cues. Visual prosodic cues show promise for improving reading fluency in early readers and may have applications for disability education and second language learning.",Rupal Patel;William Furr,
CHI,2010,Crowdsourcing graphical perception: using mechanical turk to assess visualization design,10.1145/1753326.1753357,"Understanding perception is critical to effective visualization design. With its low cost and scalability, crowdsourcing presents an attractive option for evaluating the large design space of visualizations; however, it first requires validation. In this paper, we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly, we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.",Jeffrey Heer;Michael Bostock,
CHI,2010,ManyNets: an interface for multiple network analysis and visualization,10.1145/1753326.1753358,"Traditional network analysis tools support analysts in studying a single network. ManyNets offers these analysts a powerful new approach that enables them to work on multiple networks simultaneously. Several thousand networks can be presented as rows in a tabular visualization, and then inspected, sorted and filtered according to their attributes. The networks to be displayed can be obtained by subdivision of larger networks. Examples of meaningful subdivisions used by analysts include ego networks, community extraction, and time-based slices. Cell visualizations and interactive column overviews allow analysts to assess the distribution of attributes within particular sets of networks. Details, such as traditional node-link diagrams, are available on demand. We describe a case study analyzing a social network geared towards film recommendations by means of decomposition. A small usability study provides feedback on the use of the interface on a set of tasks issued from the case study.",Manuel Freire 0001;Catherine Plaisant;Ben Shneiderman;Jennifer Golbeck,
CHI,2010,A comparative evaluation on tree visualization methods for hierarchical structures with large fan-outs,10.1145/1753326.1753359,"Hierarchical structures with large fan-outs are hard to browse and understand. In the conventional node-link tree visualization, the screen quickly becomes overcrowded as users open nodes that have too many child nodes to fit in one screen. To address this problem, we propose two extensions to the conventional node-link tree visualization: a list view with a scrollbar and a multi-column interface. We compared them against the conventional tree visualization interface in a user study. Results show that users are able to browse and understand the tree structure faster with the multi-column interface than the other two interfaces. Overall, they also liked the multi-column better than others.",Hyunjoo Song;Bo Hyoung Kim;Bongshin Lee;Jinwook Seo,
CHI,2010,The case of the disappearing Ox: a field study of mobile activity and context logging,10.1145/1753326.1753397,"There are numerous settings where people examine, scrutinize and discuss the details of images in the course of their work. In most medical domains, scans and x-rays are used in the diagnosis of cases; in most areas of science, methods of visualization have been adopted to assist in the analysis of data; and images of different kinds are critical for many research fields in the social sciences and humanities. It is not surprising that recently technologies have been proposed to assist with the analysis and examination of images. In this paper, we consider requirements for technologies in a rather distinctive domain of research, the classics. Drawing upon an analysis of the detailed ways in which classicists work with digital images, we discuss the requirements for systems to support researchers in this domain, and also provide further considerations on the general development of image processing technologies and visualization techniques.",Grace de la Flor;Paul Luff;Marina Jirotka;John Pybus;Ruth Kirkham;Annamaria Carusi,
CHI,2010,Timeline collaboration,10.1145/1753326.1753404,"This paper explores timelines as a web-based tool for collaboration between citizens and municipal caseworkers. The paper takes its outset in a case study of planning and control of parental leave; a process that may involve surprisingly many actors. As part of the case study, a web-based timeline, CaseLine, was designed. This design crosses the boundaries between leisure and work, in ways that are different from what is often seen in current HCI. The timeline has several roles on these boundaries: It is a shared planning and visualization tool that may be used by parents and caseworkers alone or together, it serves as a contract and a sandbox, as a record and a plan, as inspiration for planning and an authoritative road, as a common information space and a fragmented exchange. Serving all these roles does not happen smoothly, and the paper discusses the challenges of such timeline interaction in, and beyond this case.",Morten Bohøj;Nikolaj Gandrup Borchorst;Niels Olof Bouvin;Susanne Bødker;Pär-Ola Zander,
CHI,2010,Using text animated transitions to support navigation in document histories,10.1145/1753326.1753427,"This article examines the benefits of using text animated transitions for navigating in the revision history of textual documents. We propose an animation technique for smoothly transitioning between different text revisions, then present the Diffamation system. Diffamation supports rapid exploration of revision histories by combining text animated transitions with simple navigation and visualization tools. We finally describe a user study showing that smooth text animation allows users to track changes in the evolution of textual documents more effectively than flipping pages.",Fanny Chevalier;Pierre Dragicevic;Anastasia Bezerianos;Jean-Daniel Fekete,
CHI,2010,Small business applications of sourcemap: a web tool for sustainable design and supply chain transparency,10.1145/1753326.1753465,"This paper introduces sustainable design applications for small businesses through the Life Cycle Assessment and supply chain publishing platform Sourcemap.org. This web-based tool was developed through a year-long participatory design process with five small businesses in Scotland and in New England. Sourcemap was used as a diagnostic tool for carbon accounting, design and supply chain management. It offers a number of ways to market sustainable practices through embedded and printed visualizations. Our experiences confirm the potential of web sustainability tools and social media to expand the discourse and to negotiate the diverse goals inherent in social and environmental sustainability.",Leonardo Bonanni;Matthew Hockenberry;David Zwarg;Chris Csikszentmihályi;Hiroshi Ishii 0001,
CHI,2010,Apatite: a new interface for exploring APIs,10.1145/1753326.1753525,"We present Apatite, a new tool that aids users in learning and understanding a complex API by visualizing the common associations between its various components. Current object-oriented API documentation is usually navigated in a fixed tree structure, starting with a package and then filtering by a specific class. For large APIs, this scheme is overly restrictive, because it prevents users from locating a particular action without first knowing which class it belongs to. Apatite's design instead enables users to search across any level of an API's hierarchy. This is made possible by the introduction of a novel interaction technique that presents popular items from multiple categories simultaneously, determining their relevance by approximating the strength of their association using search engine data. The design of Apatite was refined through iterative usability testing, and it has been released publicly as a web application.",Daniel S. Eisenberg;Jeffrey Stylos;Brad A. Myers,
CHI,2010,Interactive optimization for steering machine classification,10.1145/1753326.1753529,"Interest has been growing within HCI on the use of machine learning and reasoning in applications to classify such hidden states as user intentions, based on observations. HCI researchers with these interests typically have little expertise in machine learning and often employ toolkits as relatively fixed ""black boxes"" for generating statistical classifiers. However, attempts to tailor the performance of classifiers to specific application requirements may require a more sophisticated understanding and custom-tailoring of methods. We present ManiMatrix, a system that provides controls and visualizations that enable system builders to refine the behavior of classification systems in an intuitive manner. With ManiMatrix, users directly refine parameters of a confusion matrix via an interactive cycle of re-classification and visualization. We present the core methods and evaluate the effectiveness of the approach in a user study. Results show that users are able to quickly and effectively modify decision boundaries of classifiers to tai-lor the behavior of classifiers to problems at hand.",Ashish Kapoor;Bongshin Lee;Desney S. Tan;Eric Horvitz,
CHI,2010,pCubee: a perspective-corrected handheld cubic display,10.1145/1753326.1753535,"In this paper, we describe the design of a personal cubic display that offers novel interaction techniques for static and dynamic 3D content. We extended one-screen Fish Tank VR by arranging five small LCD panels into a box shape that is light and compact enough to be handheld. The display uses head-coupled perspective rendering and a real-time physics simulation engine to establish an interaction metaphor of having real objects inside a physical box that a user can hold and manipulate. We evaluated our prototype as a visualization tool and as an input device by comparing it with a conventional LCD display and mouse for a 3D tree-tracing task. We found that bimanual interaction with pCubee and a mouse offered the best performance and was most preferred by users. pCubee has potential in 3D visualization and interactive applications such as games, storytelling and education, as well as viewing 3D maps, medical and architectural data.",Ian Stavness;Billy Lam;Sidney S. Fels,
CHI,2010,Biketastic: sensing and mapping for better biking,10.1145/1753326.1753598,"Bicycling is an affordable, environmentally friendly alternative transportation mode to motorized travel. A common task performed by bikers is to find good routes in an area, where the quality of a route is based on safety, efficiency, and enjoyment. Finding routes involves trial and error as well as exchanging information between members of a bike community. Biketastic is a platform that enriches this experimentation and route sharing process making it both easier and more effective. Using a mobile phone application and online map visualization, bikers are able to document and share routes, ride statistics, sensed information to infer route roughness and noisiness, and media that documents ride experience. Biketastic was designed to ensure the link between information gathering, visualization, and bicycling practices. In this paper, we present architecture and algorithms for route data inferences and visualization. We evaluate the system based on feedback from bicyclists provided during a two-week pilot.",Sasank Reddy;Katie Shilton;Gleb Denisov;Christian Cenizal;Deborah Estrin;Mani B. Srivastava,
CHI,2010,UpStream: motivating water conservation with low-cost water flow sensing and persuasive displays,10.1145/1753326.1753604,"Water is our most precious and most rapidly declining natural resource. We explore pervasive technology as an approach for promoting water conservation in public and private spaces. We hope to motivate immediate reduction in water use as well as higher-order behaviors (seeking new information, etc) through unobtrusive low-cost water flow sensing and several persuasive displays. Early prototypes were installed at public faucets and a private (shared) shower, logging water usage first without and then with ambient displays. This pilot study led to design iterations, culminating in long-term deployment of sensors in four private showers over the course of three weeks. Sensors first logged baseline water usage without visualization. Then, two display styles, ambient and numeric, were deployed in random order, each showing individual and average water consumption. Quantitative data along with participants' feedback contrast the effectiveness of numeric displays against abstract visualization in this very important domain of water conservation and public health.",Stacey Kuznetsov;Eric Paulos,
CHI,2010,InAir: sharing indoor air quality measurements and visualizations,10.1145/1753326.1753605,"This paper describes inAir, a tool for sharing measurements and visualizations of indoor air quality within one's social network. Poor indoor air quality is difficult for humans to detect through sight and smell alone and can contribute to the development of chronic diseases. Through a four-week long study of fourteen households as six groups, we found that inAir (1) increased awareness of, and reflection on air quality, (2) promoted behavioral changes that resulted in improved indoor air quality, and (3) demonstrated the persuasive power of sharing for furthering improvements to indoor air quality in terms of fostering new social awareness and behavior changes as well as strengthening social bonds and prompting collaborative efforts across social networks to improve human health and well being.",Sunyoung Kim;Eric Paulos,
CHI,2010,Individual models of color differentiation to improve interpretability of information visualization,10.1145/1753326.1753715,"Color is commonly used to represent categories and values in many computer applications, but differentiating these colors can be difficult in many situations (e.g., for users with color vision deficiency (CVD), or in bright light). Current solutions to this problem can adapt colors based on standard simulations of CVD, but these models cover only a fraction of the ways in which color perception can vary. To improve the specificity and accuracy of these approaches, we have developed the first ever individualized model of color differentiation (ICD). The model is based on a short calibration performed by a particular user for a particular display, and so automatically covers all aspects of the user's ability to see and differentiate colors in an environment. In this paper we introduce the new model and the manner in which differentiability limits are predicted. We gathered empirical data from 16 users to assess the model's accuracy and robustness. We found that the model is highly effective at capturing individual differentiation abilities, works for users with and without CVD, can be tuned to balance accuracy and color availability, and can serve as the basis for improved color adaptation schemes.",David R. Flatla;Carl Gutwin,
CHI,2009,PrintMarmoset: redesigning the print button for sustainability,10.1145/1518701.1518720,"In this paper, we discuss some unique challenges of sustainable interaction design (SID) and present our work that aims to reduce paper waste from web printing. We conducted a two-month field study of current behaviors and attitudes around printing, and the results confirmed the affordances of paper, but also revealed many problems associated with printing web content. We then designed and implemented a browser extension, PrintMarmoset, that targets these problems while simultaneously addressing user needs and environmental responsibility. It allows users to effortless select or remove web content for printing. We have also incorporated a data sharing mechanism into our solution to assist in the adoption of the tool and created visualizations to encourage user reflection and exploration.",Jun Xiao;Jian Fan,
CHI,2009,Creating a spoken impact: encouraging vocalization through audio visual feedback in children with ASD,10.1145/1518701.1518774,"One hallmark difficulty of children with Autism Spectrum Disorder (ASD) centers on communication and speech. Research into computer visualizations of voice has been shown to influence conversational patterns and allow users to reflect upon their speech. In this paper, we present the Spoken Impact Project (SIP), an effort to examine the effect of audio and visual feedback on vocalizations in low-functioning children with ASD by providing them with additional means of understanding and exploring their voice. This research spans over 12 months, including the creation of multiple software packages and detailed analysis of more than 20 hours of experimental video. SIP demonstrates the potential of computer generated audio and visual feedback to encourage vocalizations of children with ASD.",Joshua M. Hailpern;Karrie Karahalios;James Halle,
CHI,2009,Visualizing real-time language-based feedback on teamwork behavior in computer-mediated groups,10.1145/1518701.1518784,"While most collaboration technologies are concerned with supporting particular tasks such as workflows or meetings, many work groups do not have the teamwork skills essential to effective collaboration. One way to improve teamwork is to provide dynamic feedback generated by automated analyses of behavior, such as language use. Such feedback can lead members to reflect on and subsequently improve their collaborative behavior, but might also distract from the task at hand. We have experimented with GroupMeter - a chat-based system that presents visual feedback on team members' language use. Feedback on proportion of agreement words and overall word count was presented using two different designs. When receiving feedback, teams in our study expressed more agreement in their conversations and reported greater focus on language use as compared to when not receiving feedback. This suggests that automated, real-time linguistic feedback can elicit behavioral changes, offering opportunities for future research.",Gilly Leshed;Diego Perez;Jeffrey T. Hancock;Dan Cosley;Jeremy P. Birnholtz;Soyoung Lee;Poppy L. McLeod;Geri Gay,
CHI,2009,What's next?: emergent storytelling from video collection,10.1145/1518701.1518825,"In the world of visual storytelling, narrative development relies on a particular temporal ordering of shots and sequences and scenes. Rarely is this ordering cast in stone. Rather, the particular ordering of a story reflects a myriad of interdependent decisions about the interplay of structure, narrative arc and character development. For storytellers, particularly those developing their narratives from large documentary archives, it would be helpful to have a visualization system partnered with them to present suggestions for the most compelling story path. We present Storied Navigation, a video editing system that helps authors compose a sequence of scenes that tell a story, by selecting from a corpus of annotated clips. The clips are annotated in unrestricted natural language. Authors can also type a story in unrestricted English, and the system finds possibilities for clips that best match high-level elements of the story. Beyond simple keyword matching, these elements can include the characters, emotions, themes, and story structure. Authors can also interactively replace existing scenes or predict the next scene to continue a story, based on these characteristics. Storied Navigation gives the author the feel of brainstorming about the story rather than simply editing the media.",Edward Yu-Te Shen;Henry Lieberman;Glorianna Davenport,
CHI,2009,Unravelling seams: improvoing mobile gesture recognition with visual feedback techniques,10.1145/1518701.1518844,"Gesture recognition is emerging as an engaging interaction technique in mobile scenarios, and high recognition rates promote user acceptance. Several factors influence recognition rates including the nature of the gesture set and the suitability of the gesture recognition algorithm. This work explores how seamfulness in gesture stroke visualization affects recognition rates. We present the results of a user evaluation of a gesture recognition system that shows that raw (seamful) visualization of low-delity gesture stroke data has recognition rates comparable to no feedback. Providing filtered (seamless) stroke visualization to the user, while retaining the un-filtered input data for recognition, resulted in a 34.9% improvement in gesture recognition rate over raw stroke data. The results provide insights into the broader design space of seamful design, and identifies areas where seamlessness is advantageous.",Sven G. Kratz;Rafael Ballagas,
CHI,2009,PhotoScope: visualizing spatiotemporal coverage of photos for construction management,10.1145/1518701.1518869,"PhotoScope visualizes the spatiotemporal coverage of photos in a photo collection. It extends the standard photo browsing paradigm in two main ways: visualizing spatial coverage of photos, and indexing photos by a combination of spatial coverage, time, and content specifications. This approach enables users to browse and search space- and time-indexed photos more effectively. We designed PhotoScope specifically to address challenges in the construction management industry, where large photo collections are amassed to document project progress. These ideas may also apply to any photo collection that is spatially constrained and must be searched using spatial, temporal, and content criteria. We describe the design choices made when developing PhotoScope and the results of user evaluation.",Fuqu Wu;Melanie Tory,
CHI,2009,SiteLens: situated visualization techniques for urban site visits,10.1145/1518701.1518871,"Urban designers and urban planners often conduct site visits prior to a design activity to search for patterns or better understand existing conditions. We introduce SiteLens, an experimental system and set of techniques for supporting site visits by visualizing relevant virtual data directly in the context of the physical site, which we call situated visualization. We address alternative visualization representations and techniques for data collection, curation, discovery, comparison, manipulation, and provenance. A real use scenario is presented and two iterations of evaluation with faculty and students from the Columbia University Graduate School of Architecture, Planning and Preservation provide directions and insight for further investigation.",Sean White;Steven Feiner,
CHI,2009,WeSpace: the design development and deployment of a walk-up and share multi-surface visual collaboration system,10.1145/1518701.1518886,"We present WeSpace -- a collaborative work space that integrates a large data wall with a multi-user multi-touch table. WeSpace has been developed for a population of scientists who frequently meet in small groups for data exploration and visualization. It provides a low overhead walk-up and share environment for users with their own personal applications and laptops. We present our year-long effort from initial ethnographic studies, to iterations of design, development and user testing, to the current experiences of these scientists carrying out their collaborative research in the WeSpace. We shed light on the utility, the value of the multi-touch table, the manifestation, usage patterns and the changes in their workflow that WeSpace has brought about.",Daniel Wigdor;Hao Jiang;Clifton Forlines;Michelle Borkin;Chia Shen,
CHI,2009,EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers,10.1145/1518701.1518895,"Machine learning is an increasingly used computational tool within human-computer interaction research. While most researchers currently utilize an iterative approach to refining classifier models and performance, we propose that ensemble classification techniques may be a viable and even preferable alternative. In ensemble learning, algorithms combine multiple classifiers to build one that is superior to its components. In this paper, we present EnsembleMatrix, an interactive visualization system that presents a graphical view of confusion matrices to help users understand relative merits of various classifiers. EnsembleMatrix allows users to directly interact with the visualizations in order to explore and build combination models. We evaluate the efficacy of the system and the approach in a user study. Results show that users are able to quickly combine multiple classifiers operating on multiple feature sets to produce an ensemble classifier with accuracy that approaches best-reported performance classifying images in the CalTech-101 dataset.",Justin Talbot;Bongshin Lee;Ashish Kapoor;Desney S. Tan,
CHI,2009,FacetLens: exposing trends and relationships to support sensemaking within faceted datasets,10.1145/1518701.1518896,"Previous research has shown that faceted browsing is effective and enjoyable in searching and browsing large collections of data. In this work, we explore the efficacy of interactive visualization systems in supporting exploration and sensemaking within faceted datasets. To do this, we developed an interactive visualization system called FacetLens, which exposes trends and relationships within faceted datasets. FacetLens implements linear facets to enable users not only to identify trends but also to easily compare several trends simultaneously. Furthermore, it offers pivot operations to allow users to navigate the faceted dataset using relationships between items. We evaluate the utility of the system through a description of insights gained while experts used the system to explore the CHI publication repository as well as a database of funding grant data, and report a formative user study that identified usability issues.",Bongshin Lee;Greg Smith;George G. Robertson;Mary Czerwinski;Desney S. Tan,
CHI,2009,Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations,10.1145/1518701.1518897,"We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs - a space-efficient time series visualization technique - across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception.",Jeffrey Heer;Nicholas Kong;Maneesh Agrawala,
CHI,2009,An intuitive model of perceptual grouping for HCI design,10.1145/1518701.1518903,"Understanding and exploiting the abilities of the human visual system is an important part of the design of usable user interfaces and information visualizations. Good design enables quick, easy and veridical perception of key components of that design. An important facet of human vision is its ability to seemingly effortlessly perform ""perceptual organization; it transforms individual feature estimates into perception of coherent regions, structures, and objects. We perceive regions grouped by proximity and feature similarity, grouping of curves by good continuation, and grouping of regions of coherent texture. In this paper, we discuss a simple model for a broad range of perceptual grouping phenomena. It takes as input an arbitrary image, and returns a structure describing the predicted visual organization of the image. We demonstrate that this model can capture aspects of traditional design rules, and predicts visual percepts in classic perceptual grouping displays.",Ruth Rosenholtz;Nathaniel R. Twarog;Nadja Schinkel-Bielefeld;Martin Wattenberg,
CHI,2009,So you know you're getting the best possible information: a tool that increases Wikipedia credibility,10.1145/1518701.1518929,"An experiment was conducted to study how credibility judgments about Wikipedia are affected by providing users with an interactive visualization (WikiDashboard) of article and author editing history. Overall, users who self-reported higher use of Internet information and higher rates of Wikipedia usage tended to produce lower credibility judgments about Wikipedia articles and authors. However, use of WikiDashboard significantly increased article and author credibility judgments, with effect sizes larger than any other measured effects of background media usage and attitudes on Wikiepedia credibility. The results suggest that increased exposure to the editing/authoring histories of Wikipedia increases credibility judgments.",Peter Pirolli;Evelin Wollny;Bongwon Suh,
CHI,2009,Fisheyes in the field: using method triangulation to study the adoption and use of a source code visualization,10.1145/1518701.1518943,"Information visualizations have been shown useful in numerous laboratory studies, but their adoption and use in real-life tasks are curiously under-researched. We present a field study of ten programmers who work with an editor extended with a fisheye view of source code. The study triangulates multiple methods (experience sampling, logging, thinking aloud, and interviews) to describe how the visualization is adopted and used. At the concrete level, our results suggest that the visualization was used as frequently as other tools in the programming environment. We also propose extensions to the interface and discuss features that were not used in practice. At the methodological level, the study identifies contributions distinct to individual methods and to their combination, and discusses the relative benefits of laboratory studies and field studies for the evaluation of information visualizations.",Mikkel Rønne Jakobsen;Kasper Hornbæk,
CHI,2009,A user study on visualizing directed edges in graphs,10.1145/1518701.1519054,"Graphs are often visualized using node-link representations: vertices are depicted as dots, edges are depicted as (poly)lines connecting two vertices. A directed edge running from vertex A to B is generally visualized using an arrow representation: a (poly)line with a triangular arrowhead at vertex B. Although this representation is intuitive, it is not guaranteed that a user is able to determine edge direction as quickly and unambiguously as possible; alternative representations that exhibit less occlusion and visual clutter might be better suited. To investigate this, we developed five additional directed-edge representations using combinations of shape and color. We performed a user study in which subjects performed different tasks on a collection of graphs using these representations and combinations thereof to investigate which representation is best in terms of speed and accuracy. We present our initial hypotheses, the outcome of the user studies, and recommendations regarding directed-edge visualization.",Danny Holten;Jarke J. van Wijk,
CHI,2009,Topology-aware navigation in large networks,10.1145/1518701.1519056,"Applications supporting navigation in large networks are used every days by millions of people. They include road map navigators, flight route visualization systems, and network visualization systems using node-link diagrams. These applications currently provide generic interaction methods for navigation: pan-and-zoom and sometimes bird's eye views. This article explores the idea of exploiting the connection information provided by the network to help navigate these large spaces. We visually augment two traditional navigation methods, and develop two special-purpose techniques. The first new technique, called ""Link Sliding"", provides guided panning when continuously dragging along a visible link. The second technique, called ""Bring & Go"", brings adjacent nodes nearby when pointing to a node. We compare the performance of these techniques in both an adjacency exploration task and a node revisiting task. This comparison illustrates the various advantages of content-aware network navigation techniques. A significant speed advantage is found for the Bring & Go technique over other methods.",Tomer Moscovich;Fanny Chevalier;Nathalie Henry;Emmanuel Pietriga;Jean-Daniel Fekete,
CHI,2009,Conversation clusters: grouping conversation topics through human-computer dialog,10.1145/1518701.1519060,"Conversation Clusters explores the use of visualization to highlight salient moments of live conversation while archiving a meeting. Cheaper storage and easy access to recording devices allows extensive archival. However, as the size of the archive grows, retrieving the desired moments becomes increasingly difficult. We approach this problem from a socio-technical perspective and utilize human intuition aided by computer memory. We present computationally detected topics of conversation as visual summaries of discussion and as reference points into the archive. To further bootstrap the system, humans can participate in a dialog with the visualization of the clustering process and shape the development of clustering models.",Tony Bergstrom;Karrie Karahalios,
CHI,2008,Handsaw: tangible exploration of volumetric data by direct cut-plane projection,10.1145/1357054.1357098,"Tangible User Interfaces are well-suited to handling three-dimensional data sets by direct manipulation of real objects in space, but current interfaces can make it difficult to look inside dense volumes of information. This paper presents the Handsaw, a system that detects a virtual cut-plane projected by an outstretched hand or laser-line directly on an object or space and reveals sectional data on an adjacent display. By leaving the hands free and using a remote display, these techniques can be shared between multiple users and integrated into everyday practice. The Handsaw has been prototyped for scientific visualizations in medicine, engineering and urban design. User evaluations suggest that using a hand is more intuitive while projected light is more precise than keyboard and mouse control, and the Handsaw system has the potential to be used effectively by novices and in groups.",Leonardo Bonanni;Jason Alonso;Neil Chao;Greg Vargas;Hiroshi Ishii 0001,
CHI,2008,Do I live in a flood basin?: synthesizing ten thousand maps,10.1145/1357054.1357100,"The recent introduction of simple, web-based geographic visualization interfaces has unleashed a tidal wave of new geographic content now available on the Internet. There has been enormous attention on the development of data interchange standards and programming interfaces that make all this content interoperable, but far less thought about how the user experience should change when users have their choice of 10,000 maps. To inform the design of online mapping systems, we investigate the case of queries that require correlation of multiple maps---that is, discovery and synthesis of several map layers. We based our study on interviews with expert users of maps: archivists and librarians. This paper describes our user-task taxonomy distilled from these interviews, and presents MapSynthesizer, a prototype system that allows users to efficiently query, discover, and integrate many maps from a corpus of thousands.",Miguel Elías;Jeremy Elson;Danyel Fisher;Jon Howell,
CHI,2008,Integrating statistics and visualization: case studies of gaining clarity during exploratory data analysis,10.1145/1357054.1357101,"Although both statistical methods and visualizations have been used by network analysts, exploratory data analysis remains a challenge. We propose that a tight integration of these technologies in an interactive exploratory tool could dramatically speed insight development. To test the power of this integrated approach, we created a novel social network analysis tool, SocialAction, and conducted four long-term case studies with domain experts, each working on unique data sets with unique problems. The structured replicated case studies show that the integrated approach in SocialAction led to significant discoveries by a political analyst, a bibliometrician, a healthcare consultant, and a counter-terrorism researcher. Our contributions demonstrate that the tight integration of statistics and visualizations improves exploratory data analysis, and that our evaluation methodology for long-term case studies captures the research strategies of data analysts.",Adam Perer;Ben Shneiderman,
CHI,2008,Your place or mine?: visualization as a community component,10.1145/1357054.1357102,"Many Eyes is a web site that provides collaborative visualization services, allowing users to upload data sets, visualize them, and comment on each other's visualizations. This paper describes a first interview-based study of Many Eyes users, which sheds light on user motivation for creating public visualizations. Users talked about data for many reasons, from scientific research to political advocacy to hobbies. One consistent theme across these different scenarios is the use of visualizations in communication and collaborative practices. Collaboration and conversation, however, often took place outside the site, leaving no traces on Many Eyes itself. In other words, despite spurring significant social activity, Many Eyes is not so much an online community as a ""community component"" which users insert into pre-existing online social systems.",Catalina M. Danis;Fernanda B. Viégas;Martin Wattenberg;Jesse Kriss,
CHI,2008,ArtLinks: fostering social awareness and reflection in museums,10.1145/1357054.1357121,"Technologies in museums often support learning goals, providing information about exhibits. However, museum visitors also desire meaningful experiences and enjoy the social aspects of museum-going, values ignored by most museum technologies. We present ArtLinks, a visualization with three goals: helping visitors make connections to exhibits and other visitors by highlighting those visitors who share their thoughts; encouraging visitors' reflection on the social and liminal aspects of museum-going and their expectations of technology in museums; and doing this with transparency, aligning aesthetically pleasing elements of the design with the goals of connection and reflection. Deploying ArtLinks revealed that people have strong expectations of technology as an information appliance. Despite these expectations, people valued connections to other people, both for their own sake and as a way to support meaningful experience. We also found several of our design choices in the name of transparency led to unforeseen tradeoffs between the social and the liminal.",Dan Cosley;Joel Lewenstein;Andrew Herman;Jenna Holloway;Jonathan Baxter;Saeko Nomura;Kirsten Boehner;Geri Gay,
CHI,2008,Wedge: clutter-free visualization of off-screen locations,10.1145/1357054.1357179,"To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge, a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.",Sean Gustafson;Patrick Baudisch;Carl Gutwin;Pourang Irani,
CHI,2008,Generalized selection via interactive query relaxation,10.1145/1357054.1357203,"Selection is a fundamental task in interactive applications, typically performed by clicking or lassoing items of interest. However, users may require more nuanced forms of selection. Selecting regions or attributes may be more important than selecting individual items. Selections may be over dynamic items and selections might be more easily created by relaxing simpler selections (e.g., ""select all items like this one""). Creating such selections requires that interfaces model the declarative structure of the selection, not just individually selected items. We present direct manipulation techniques that couple declarative selection queries with a query relaxation engine that enables users to interactively generalize their selections. We apply our selection techniques in both information visualization and graphics editing applications, enabling generalized selection over both static and dynamic interface objects. A controlled study finds that users create more accurate selection queries when using our generalization techniques.",Jeffrey Heer;Maneesh Agrawala;Wesley Willett,
CHI,2008,Sesame: informing user security decisions with system visualization,10.1145/1357054.1357217,"Non-expert users face a dilemma when making security decisions. Their security often cannot be fully automated for them, yet they generally lack both the motivation and technical knowledge to make informed security decisions on their own. To help users with this dilemma, we present a novel security user interface called Sesame. Sesame uses a concrete, spatial extension of the desktop metaphor to provide users with the security-related, visualized system-level information they need to make more informed decisions. It also provides users with actionable controls to affect a system's security state. Sesame graphically facilitates users' comprehension in making these decisions, and in doing so helps to lower the bar for motivating them to participate in the security of their system. In a controlled study, users with Sesame were found to make fewer errors than a control group which suggests that our novel security interface is a viable alternative approach to helping users with their dilemma.",Jennifer Stoll;Craig S. Tashman;W. Keith Edwards;Kyle Spafford,
CHI,2008,An exploratory study of visual information analysis,10.1145/1357054.1357245,"To design information visualization tools for collaborative use, we need to understand how teams engage with visualizations during their information analysis process. We report on an exploratory study of individuals, pairs, and triples engaged in information analysis tasks using paper-based visualizations. From our study results, we derive a framework that captures the analysis activities of co-located teams and individuals. Comparing this framework with existing models of the information analysis process suggests that information visualization tools may benefit from providing a flexible temporal flow of analysis actions.",Petra Isenberg;Anthony Tang 0001;Sheelagh Carpendale,
CHI,2008,Do visualizations improve synchronous remote collaboration?,10.1145/1357054.1357246,"Information visualizations can improve collaborative problem solving, but this improvement may depend on whether visualizations promote communication. In an experiment on the effect of network visualizations, remote pairs worked synchronously to identify a serial killer. They discussed disparate evidence distributed across the pair using IM. Four conditions, respectively, offered (a) spreadsheet only (controls), (b) individual unshared visualizations, (c) view-only shared visualizations, and (d) a full-access shared visualization of all evidence. We examined collaborative performance, use of the visualization tool, and communication as a function of condition. All visualization conditions improved remote collaborators' performance over the control condition. Full access to a shared visualization best facilitated remote collaboration by encouraging tool use and fostering discussion between the partners. Shared visualization without full access impaired performance somewhat and made communication even more vital to identifying the serial killer. This study provides direct evidence of visualization tool features and partner behavior that promote collaboration.",Aruna D. Balakrishnan;Susan R. Fussell;Sara B. Kiesler,
CHI,2008,Supporting the analytical reasoning process in information visualization,10.1145/1357054.1357247,"This paper presents a new information visualization framework that supports the analytical reasoning process. It consists of three views - a data view, a knowledge view and a navigation view. The data view offers interactive information visualization tools. The knowledge view enables the analyst to record analysis artifacts such as findings, hypotheses and so on. The navigation view provides an overview of the exploration process by capturing the visualization states automatically. An analysis artifact recorded in the knowledge view can be linked to a visualization state in the navigation view. The analyst can revisit a visualization state from both the navigation and knowledge views to review the analysis and reuse it to look for alternate views. The whole analysis process can be saved along with the synthesized information. We present a user study and discuss the perceived usefulness of a prototype based on this framework that we have developed.",Yedendra Babu Shrinivasan;Jarke J. van Wijk,
CHI,2008,LivOlay: interactive ad-hoc registration and overlapping of applications for collaborative visual exploration,10.1145/1357054.1357266,"The interoperability of disparate data types and sources has been a long standing problem and a hindering factor for the efficacy and efficiency in visual exploration applications. In this paper, we present a solution, called LivOlay, that enables the rapid visual overlay of live data rendered in different applications. Our tool addresses datasets in which visual registration of the information is necessary in order to allow for thorough understanding and visual analysis. We also discuss initial evaluation and user feedback of LivOlay.",Hao Jiang;Daniel Wigdor;Clifton Forlines;Michelle Borkin;Jens Kauffmann;Chia Shen,
CHI,2008,Expandable grids for visualizing and authoring computer security policies,10.1145/1357054.1357285,"We introduce the Expandable Grid, a novel interaction technique for creating, editing, and viewing many types of security policies. Security policies, such as file permissions policies, have traditionally been displayed and edited in user interfaces based on a list of rules, each of which can only be viewed or edited in isolation. These list-of-rules interfaces cause problems for users when multiple rules interact, because the interfaces have no means of conveying the interactions amongst rules to users. Instead, users are left to figure out these rule interactions themselves. An Expandable Grid is an interactive matrix visualization designed to address the problems that list-of-rules interfaces have in conveying policies to users. This paper describes the Expandable Grid concept, shows a system using an Expandable Grid for setting file permissions in the Microsoft Windows XP operating system, and gives results of a user study involving 36 participants in which the Expandable Grid approach vastly outperformed the native Windows XP file-permissions interface on a broad range of policy-authoring tasks.",Robert W. Reeder;Lujo Bauer;Lorrie Faith Cranor;Michael K. Reiter;Kelli Bacon;Keisha How;Heather Strong,
CHI,2008,LiveRAC: interactive visual exploration of system management time-series data,10.1145/1357054.1357286,"We present LiveRAC, a visualization system that supports the analysis of large collections of system management time-series data consisting of hundreds of parameters across thousands of network devices. LiveRAC provides high information density using a reorderable matrix of charts, with semantic zooming adapting each chart's visual representation to the available space. LiveRAC allows side-by-side visual comparison of arbitrary groupings of devices and parameters at multiple levels of detail. A staged design and development process culminated in the deployment of LiveRAC in a production environment. We conducted an informal longitudinal evaluation of LiveRAC to better understand which proposed visualization techniques were most useful in the target environment.",Peter McLachlan;Tamara Munzner;Eleftherios Koutsofios;Stephen C. North,
CHI,2008,Metrics for measuring human interaction with interactive visualizations for information analysis,10.1145/1357054.1357287,"There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.",Theresa A. O'Connell;Yee-Yin Choong,
CHI,2008,On the benefits of confidence visualization in speech recognition,10.1145/1357054.1357288,"In a typical speech dictation interface, the recognizer's best-guess is displayed as normal, unannotated text. This ignores potentially useful information about the recognizer's confidence in its recognition hypothesis. Using a confidence measure (which itself may sometimes be inaccurate), we investigated providing visual feedback about low-confidence portions of the recognition using shaded, red underlining. An evaluation showed, compared to a baseline without underlining, underlining low-confidence areas did not increase user's speed or accuracy in detecting errors. However, we found that when recognition errors were correctly underlined, they were discovered significantly more often than baseline. Conversely, when errors failed to be underlined, they were discovered less often. Our results indicate confidence visualization can be effective --- but only if the confidence measure has high accuracy. Further, since our results show that users tend to trust confidence visualization, designers should be careful in its application if a high accuracy confidence measure is not available.",Keith Vertanen;Per Ola Kristensson,
CHI,2008,Rendering navigation and information space with honeycombTM,10.1145/1357054.1357333,"The growing amount of available information poses challenges not only in the process of information retrieval. The usability of the rendered search process and results can be increased by appropriate visualization techniques or new interaction paradigms, or both. In this article we present the HoneyComb™ paradigm, an information visualization style that aims to render and manage large quantities of information items. We describe the design objectives and the prototype of HC™. Finally, we present a short evaluation of the HC™ paradigm in the context of search and browsing.",Sebastian Ryszard Kruk;Bill McDaniel,
CHI,2007,Improving recognition and characterization in groupware with rich embodiments,10.1145/1240624.1240627,"Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways.",Tadeusz Stach;Carl Gutwin;David Pinelle;Pourang Irani,
CHI,2007,Beyond visual acuity: the perceptual scalability of information visualizations for large displays,10.1145/1240624.1240639,"The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed.",Beth Yost;Yonca Haciahmetoglu;Chris North 0001,
CHI,2007,White rooms and morphing don't mix: setting and the evaluation of visualization techniques,10.1145/1240624.1240640,"The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute.",Derek F. Reilly;Kori M. Inkpen,
CHI,2007,Perception of elementary graphical elements in tabletop and multi-surface environments,10.1145/1240624.1240701,"Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments.",Daniel Wigdor;Chia Shen;Clifton Forlines;Ravin Balakrishnan,
CHI,2007,Let's go to the whiteboard: how and why software developers use drawings,10.1145/1240624.1240714,"Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research.",Mauro Cherubini;Gina Venolia;Robert DeLine;Amy J. Ko,
CHI,2007,Task and social visualization in software development: evaluation of a prototype,10.1145/1240624.1240716,"As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles.",Jason B. Ellis;Shahtab Wahid;Catalina Danis;Wendy A. Kellogg,
CHI,2007,CAAD: an automatic task support system,10.1145/1240624.1240731,"Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more ""ready-at-hand"" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system.",Tye Rattenbury;John F. Canny,
CHI,2007,Senspectra: a computationally augmented physical modeling toolkit for sensing and visualization of structural strain,10.1145/1240624.1240744,"We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes. Using Senspectra, a user incrementally assembles and refines a physical 3D model of discrete elements with a real-time visualization of structural strain. While the Senspectra infrastructure provides a flexible modular sensor network platform, its primary application derives from the need to couple physical modeling techniques utilized in architecture and design disciplines with systems for structural engineering analysis. This offers direct manipulation augmented with visual feedback for an intuitive approach to physical real-time finite element analysis, particularly for organic forms.",Vincent Leclerc;Amanda J. Parkes;Hiroshi Ishii 0001,
CHI,2007,An empirical study of the use of visually enhanced voip audio conferencing: the case of IEAC,10.1145/1240624.1240780,"IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics.",Xianghua Ding;Thomas Erickson;Wendy A. Kellogg;Stephen Levy;Jim Christensen;Jeremy B. Sussman;Tracee Vetting Wolf;William E. Bennett,
CHI,2007,Voyagers and voyeurs: supporting asynchronous collaborative information visualization,10.1145/1240624.1240781,"This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.",Jeffrey Heer;Fernanda B. Viégas;Martin Wattenberg,
CHI,2007,Seconds matter: improving distributed coordination bytracking and visualizing display trajectories,10.1145/1240624.1240822,"Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause.",Mike Fraser 0001;Michael R. McCarthy;Muneeb Shaukat;Phillip Smith,
CHI,2007,FASTDash: a visual dashboard for fostering awareness in software teams,10.1145/1240624.1240823,"Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash.",Jacob T. Biehl;Mary Czerwinski;Greg Smith;George G. Robertson,
CHI,2007,ExperiScope: an analysis tool for interaction data,10.1145/1240624.1240826,"We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques.",François Guimbretière;Morgan Dixon;Ken Hinckley,
CHI,2006,Minimap: a web page visualization method for mobile phones,10.1145/1124772.1124779,"The Web has become available even on mobile phones, but the current methods to view large pages on small screens have not been highly usable. Current mobile phone browsers reformat Web pages to a single column that fits the screen width. Because not all content is comprehensible in this format, browsers provide a second mode for viewing pages in the same layout as on a PC. We have developed a modeless Web page visualization method called Minimap that shows pages in a modified Original layout. We conducted a long-term usability study with 20 participants to compare the state-of-the-art mobile phone browser with this new method. 18 participants preferred the new method, and it also scored better in more detailed usability ratings.",Virpi Roto;Andrei Popescu 0003;Antti Koivisto;Elina Vartiainen,
CHI,2006,Visualization of large hierarchical data by circle packing,10.1145/1124772.1124851,In this paper a novel approach is described for tree visualization using nested circles. The brother nodes at the same level are represented by externally tangent circles; the tree nodes at different levels are displayed by using 2D nested circles or 3D nested cylinders. A new layout algorithm for tree structure is described. It provides a good overview for large data sets. It is easy to see all the branches and leaves of the tree. The new method has been applied to the visualization of file systems.,Weixin Wang;Henry (Hui) Wang;Guozhong Dai;Hongan Wang,
CHI,2006,GUESS: a language and interface for graph exploration,10.1145/1124772.1124889,"As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis.",Eytan Adar,
CHI,2006,Visual exploration of multivariate graphs,10.1145/1124772.1124891,"This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are ""multivariate,"" i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets.",Martin Wattenberg,
CHI,2006,Sashay: designing for wonderment,10.1145/1124772.1124901,"No longer confined to our offices, schools, and homes, technology is expanding at an astonishing rate across our everyday public urban landscapes. From the visible (mobile phones, laptops, and blackberries) to the invisible (GPS, WiFi, GSM, and EVDO), we find the full spectrum of digital technologies transforming nearly every facet of our urban experience. Many current urban computing systems focus on improving our efficiency and productivity in the city by providing ""location services"" and/or interactive navigation and mapping tools. While agreeing with the need for such systems, we are reminded that urban life spans a much wider range of emotions and experiences. Our claim is that our successful future urban technological tools will be those that incorporate the full range of urban experiences -- from improving productivity and efficiency to promoting wonderment and daydreaming. We discuss intervention as a research strategy for understanding wonderment; demonstrate an example of such a study using a matchbook experiment to expose relationships between locations and emotions within a city; and use the results to develop Sashay -- a mobile phone application that promotes wonderment by visualizing an individual's personal patterns across the invisible, manufactured geography of mobile phone cellular towers.",Eric Paulos;Chris Beckmann,
CHI,2006,Visualizing email content: portraying relationships from conversational histories,10.1145/1124772.1124919,"We present Themail, a visualization that portrays relationships using the interaction histories preserved in email archives. Using the content of exchanged messages, it shows the words that characterize one's correspondence with an individual and how they change over the period of the relationship.This paper describes the interface and content-parsing algorithms in Themail. It also presents the results from a user study where two main interaction modes with the visualization emerged: exploration of ""big picture"" trends and themes in email (haystack mode) and more detail-oriented exploration (needle mode). Finally, the paper discusses the limitations of the content parsing approach in Themail and the implications for further research on email content visualization.",Fernanda B. Viégas;Scott A. Golder;Judith S. Donath,
CHI,2006,A fisheye follow-up: further reflections on focus + context,10.1145/1124772.1124921,"Information worlds continue to grow, posing daunting challenges for interfaces. This paper tries to increase our understanding of approaches to the problem, building on the Generalized Fisheye View framework. Three issues are discussed. First a number of existing techniques are unified by the commonality of what they show, certain fisheye-related subsets, with the techniques differing only in how they show those subsets. Then the elevated importance of these subsets, and their generality, is used to discuss the possibility of non-visual fisheye-views, to attack problems not so amenable to visualization. Finally, several models are given for why these subsets might be important in user interactions, with the goal of better informing design rationales.",George W. Furnas,
CHI,2006,groupTime: preference based group scheduling,10.1145/1124772.1124929,"As our business, academic, and personal lives continue to move at an ever-faster pace, finding times for busy people to meet has become an art. One of the most perplexing challenges facing groupware is effective asynchronous group scheduling (GS). This paper presents a lightweight interaction model for GS that can extend its reach beyond users of current group calendaring solutions. By expressing availability in terms of preferences, we create a flexible framework for GS that preserves plausible deniability while exerting social pressure to encourage honesty among users. We also propose an ontology that enables us to model user preferences with machine learning, predicting user responses to further lower cognitive load. The combination of visualization/direct manipulation with machine learning allows users to easily and efficiently optimize meeting times. We also suggest resulting design implications for this class of intelligent user interfaces.",Mike Brzozowski;Kendra Carattini;Scott R. Klemmer;Patrick Mihelich;Jiang Hu;Andrew Y. Ng,
CHI,2006,Feeling what you hear: tactile feedback for navigation of audio graphs,10.1145/1124772.1124941,"Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques.",Steven A. Wall;Stephen A. Brewster,
CHI,2006,"Keepin' it real: pushing the desktop metaphor with physics, piles and the pen",10.1145/1124772.1124965,"We explore making virtual desktops behave in a more physically realistic manner by adding physics simulation and using piling instead of filing as the fundamental organizational structure. Objects can be casually dragged and tossed around, influenced by physical characteristics such as friction and mass, much like we would manipulate lightweight objects in the real world. We present a prototype, called BumpTop, that coherently integrates a variety of interaction and visualization techniques optimized for pen input we have developed to support this new style of desktop organization.",Anand Agarawala;Ravin Balakrishnan,
CHI,2005,Who gets to know what when: configuring privacy permissions in an awareness application,10.1145/1054972.1054987,"We report on a study (N=36) of user preferences for balancing awareness with privacy. Participants defined permissions for sharing of location, availability, calendar information and instant messaging (IM) activity within an application called mySpace. MySpace is an interactive visualization of the physical workplace that provides dynamic information about people, places and equipment. We found a significant preference for defining privacy permissions at the group level. While ""family"" received high levels of awareness sharing, interestingly, ""team"" was granted comparable levels during business hours at work. Surprisingly, presenting participants with a detailed list of all pieces of personal context to which the system had access, did not result in more conservative privacy settings. Although location was the most sensitive aspect of awareness, participants were comfortable disclosing room-level location information to their team members at work. Our findings suggest utilizing grouping mechanisms to balance privacy control with configuration burden, and argue for increased system transparency to build trust.",Sameer Patil;Jennifer Lai,
CHI,2005,Use of eye movements as feedforward training for a synthetic aircraft inspection task,10.1145/1054972.1054993,"Aircraft inspection is a vital element in assuring safety and reliability of the air transportation system. The human inspector performing visual inspection of an aircraft is the backbone of this process and training is an effective strategy for improving their inspection performance. Previous studies have shown offline feedback training to be effective in improving subsequent visual inspection performance. Because experienced inspectors are known to adopt a better inspection strategy than novices, providing visualization of experts' cognitive processes a priori can accelerate novices' adoption of the experts' strategy. Using eye tracking equipment, we record the point of regard of an expert inspector performing an inspection task in a virtual reality simulator. Analysis of their eye movements leads to a visualization of their scanpaths and allows us to display the inspector's visual search (hence cognitive) strategy. We show how providing this type of scanpath-based feedforward training of novices leads to improved accuracy performance in the simulator coupled with an observed speed-accuracy tradeoff. We contend that the tradeoff results from trained novices adopting a slower paced strategy through increased fixation durations, suggesting trained novices learn a more deliberate target search/discrimination strategy that requires more time to execute.",Sajay Sadasivan;Joel S. Greenstein;Anand K. Gramopadhye;Andrew T. Duchowski,
CHI,2005,prefuse: a toolkit for interactive information visualization,10.1145/1054972.1055031,"Although information visualization (infovis) technologies have proven indispensable tools for making sense of complex data, wide-spread deployment has yet to take hold, as successful infovis applications are often difficult to author and require domain-specific customization. To address these issues, we have created prefuse, a software framework for creating dynamic visualizations of both structured and unstructured data. prefuse provides theoretically-motivated abstractions for the design of a wide range of visualization applications, enabling programmers to string together desired components quickly to create and customize working visualizations. To evaluate prefuse we have built both existing and novel visualizations testing the toolkit's flexibility and performance, and have run usability studies and usage surveys finding that programmers find the toolkit usable and effective.",Jeffrey Heer;Stuart K. Card;James A. Landay,
CHI,2005,Visualization of mappings between schemas,10.1145/1054972.1055032,"In this paper we describe a novel approach to the visualization of the mapping between two schemas. Current approaches to visually defining such a mapping fail when the schemas or maps become large. The new approach uses various information visualization techniques to simplify the view, making it possible for users to effectively deal with much larger schemas and maps. A user study verifies that the new approach is useful, usable, and effective. The primary contribution is a demonstration of novel ways to effectively present highly complex information.",George G. Robertson;Mary Czerwinski;John E. Churchill,
CHI,2005,Improving aviation safety with information visualization: a flight simulation study,10.1145/1054972.1055033,"Many aircraft accidents each year are caused by encounters with invisible airflow hazards. Recent advances in aviation sensor technology offer the potential for aircraft-based sensors that can gather large amounts of airflow velocity data in real-time. With this influx of data comes the need to study how best to present it to the pilot - a cognitively overloaded user focused on a primary task other than that of information visualization.We focus on one particular aviation application, but the results may be relevant to user interfaces in other operationally stressful environments.",Cecilia R. Aragon;Marti A. Hearst,
CHI,2005,Studying the effectiveness of MOVE: a contextually optimized in-vehicle navigation system,10.1145/1054972.1055051,"In-vehicle navigation has changed substantially in recent years, due to the advent of computer generated maps and directions. However, these maps are still problematic, due to a mismatch between the complexity of the maps and the attentional demands of driving. In response to this problem, we are developing the MOVE (Maps Optimized for Vehicular Environments) system. This system will provide situationally appropriate map information by presenting information that uses appropriate amounts of the driver's attention. In this paper, we describe our findings of studies to help shape the design of the MOVE system, including studies on map reading and in-vehicle navigation, and studies on the effectiveness of a variety of contextually optimized route map visualizations in a simulated driving context.Results show that contextually optimized displays designed for the MOVE system should significantly reduce perceptual load in the context of driving. In our laboratory experiment there was a six-fold decrease in the total map display fixation time and nearly threefold decrease in the number of glances needed to interpret the contextually optimized display compared to a static display.",Joonhwan Lee;Jodi Forlizzi;Scott E. Hudson,
CHI,2005,Feature congestion: a measure of display clutter,10.1145/1054972.1055078,"Management of clutter is an important factor in the design of user interfaces and information visualizations, allowing improved usability and aesthetics. However, clutter is not a well defined concept. In this paper, we present the Feature Congestion measure of display clutter. This measure is based upon extensive modeling of the saliency of elements of a display, and upon a new operational definition of clutter. The current implementation is based upon two features: color and luminance contrast. We have tested this measure on maps that observers ranked by perceived clutter. Results show good agreement between the observers' rankings and our measure of clutter. Furthermore, our measure can be used to make design suggestions in an automated UI critiquing tool.",Ruth Rosenholtz;Yuanzhen Li;Jonathan Mansfield;Zhenlan Jin,
CHI,2004,Connecting time-oriented data and information to a coherent interactive visualization,10.1145/985692.985706,"In modern intensive care units (ICUs), the medical staff has to monitor a huge amount of high-dimensional and time-oriented data, which needs to be visualized user- and task-specifically to ease diagnosis and treatment planning. Available visual representations, like diagrams or charts neglect the implicit information as well as a-priory or associated knowledge about the data and its meaning (for example, 38.5°C (101.3°F) is moderate fever and 41°C (105.8°F) is critical fever). Another challenge is to provide appropriate interaction techniques to explore and navigate the data and its temporal dimensions. In this context one major challenge is to connect time-oriented data and information to a coherent interactive visualization. In this paper we present different interactive visualization techniques which enable the users to reveal the data at several levels of detail and abstraction, ranging from a broad overview to the fine structure. We will also introduce a time visualization and navigation technique that connects overview+detail, pan+zoom, and focus+context features to one powerful time-browser.",Ragnar Bade;Stefan Schlechtweg;Silvia Miksch,
CHI,2004,Feeling bumps and holes without a haptic interface: the perception of pseudo-haptic textures,10.1145/985692.985723,"We present a new interaction technique to simulate textures in desktop applications without a haptic interface. The proposed technique consists in modifying the motion of the cursor on the computer screen - i.e. the Control/Display ratio. Assuming that the image displayed on the screen corresponds to a top view of the texture, an acceleration (or deceleration) of the cursor indicates a negative (or positive) slope of the texture. Experimental evaluations showed that participants could successfully identify macroscopic textures such as bumps and holes, by simply using the variations of the motion of the cursor. Furthermore, the participants were able to draw the different profiles of bumps and holes which were simulated, correctly. These results suggest that our technique enabled the participants to successfully conjure a mental image of the topography of the macroscopic textures. Applications for this technique are: the feeling of images (pictures, drawings) or GUI components (windows' edges, buttons), the improvement of navigation, or the visualization of scientific data.",Anatole Lécuyer;Jean-Marie Burkhardt;Laurent Étienne,
CHI,2004,A social proxy for distributed tasks: design and evaluation of a working prototype,10.1145/985692.985763,"This paper describes an approach to managing tasks and processes that are distributed across a large number of people. The basic idea is to use a social visualization called a task proxy to create a shared awareness amongst the participants in a task or process. The process awareness provided by the task proxy enables its users to monitor the task state, the states of participants, and to communicate with those in particular states. We describe the concept, a first prototype, its evaluation, and discuss future directions.",Thomas Erickson;Wei Huang;Catalina Danis;Wendy A. Kellogg,
CHI,2004,Studying cooperation and conflict between authors with history flow visualizations,10.1145/985692.985765,"The Internet has fostered an unconventional and powerful style of collaboration: ""wiki"" web sites, where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia, a prominent, thriving wiki. We make three contributions. First, we introduce a new exploratory data analysis tool, the history flow visualization, which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second, we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third, we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship, the value of community surveillance in ameliorating antisocial behavior, and how authors with competing perspectives negotiate their differences.",Fernanda B. Viégas;Martin Wattenberg;Kushal Dave,
CHI,2003,Designing novel interactional workspaces to support face to face consultations,10.1145/642611.642623,"This paper describes the design and deployment of a novel interactional workspace, intended to provide more effective support for face-to-face consultations between two parties. We focus on the initial consultations between customer and agent that take place during the development of complex products. Findings from an ethnographic study of the existing use of technological systems show the interaction during such consultations to be disjointed and not well supported. As an alternative approach, we developed a novel arrangement of multiple displays intended to promote shoulder-to-shoulder collaboration using a variety of interlinked representations and visualizations. The resulting interactional workspace was used by a travel company as part of a large international trade show attended by the general public. The many consultations that took place between agents and customers were quite different, proving to be more equitable, open, fluid and congenial.",Tom Rodden;Yvonne Rogers;John Halloran 0001;Ian Taylor,
CHI,2003,Understanding sequence and reply relationships within email conversations: a mixed-model visualization,10.1145/642611.642674,"It has been proposed that email clients could be improved if they presented messages grouped into conversations. An email conversation is the tree of related messages that arises from the use of the reply operation. We propose two models of conversation. The first model characterizes a conversation as a chronological sequence of messages; the second as a tree based on the reply relationship. We show how existing email clients and prior research projects implicitly support each model to a greater or lesser degree depending on their design, but none fully supports both models simultaneously. We present a mixed-model visualization that simultaneously presents sequence and reply relationships among the messages of a conversation, making both visible at a glance. We describe the integration of the visualization into a working prototype email client. A usability study indicates that the system meets our usability goals and verifies that the visualization fully conveys both types of relationships within the messages of an email conversation.",Gina Danielle Venolia;Carman Neustaedter,
CHI,2003,Halo: a technique for visualizing off-screen objects,10.1145/642611.642695,"As users pan and zoom, display content can disappear into off-screen space, particularly on small-screen devices. The clipping of locations, such as relevant places on a map, can make spatial cognition tasks harder. Halo is a visualization technique that supports spatial cognition by showing users the location of off-screen objects. Halo accomplishes this by surrounding off-screen objects with rings that are just large enough to reach into the border region of the display window. From the portion of the ring that is visible on-screen, users can infer the off-screen location of the object at the center of the ring. We report the results of a user study comparing Halo with an arrow-based visualization technique with respect to four types of map-based route planning tasks. When using the Halo interface, users completed tasks 16-33% faster, while there were no significant differences in error rate for three out of four tasks in our study.",Patrick Baudisch;Ruth Rosenholtz,
CHI,2003,Recommending collaboration with social networks: a comparative evaluation,10.1145/642611.642714,"Studies of information seeking and workplace collaboration often find that social relationships are a strong factor in determining who collaborates with whom. Social networks provide one means of visualizing existing and potential interaction in organizational settings. Groupware designers are using social networks to make systems more sensitive to social situations and guide users toward effective collaborations. Yet, the implications of embedding social networks in systems have not been systematically studied. This paper details an evaluation of two different social networks used in a system to recommend individuals for possible collaboration. The system matches people looking for expertise with individuals likely to have expertise. The effectiveness of social networks for matching individuals is evaluated and compared. One finding is that social networks embedded into systems do not match individuals' perceptions of their personal social network. This finding and others raise issues for the use of social networks in groupware. Based on the evaluation results, several design considerations are discussed.",David W. McDonald,
CHI,2002,Automating CPM-GOMS,10.1145/503376.503404,"CPM-GOMS is a modeling method that combines the task decomposition of a GOMS analysis with a model of human resource usage at the level of cognitive, perceptual, and motor operations. CPM-GOMS models have made accurate predictions about skilled user behavior in routine tasks, but developing such models is tedious and error-prone. We describe a process for automatically generating CPM-GOMS models from a hierarchical task decomposition expressed in a cognitive modeling tool called Apex. Resource scheduling in Apex automates the difficult task of interleaving the cognitive, perceptual, and motor resources underlying common task operators (e.g. mouse move-and-click). Apex's UI automatically generates PERT charts, which allow modelers to visualize a model's complex parallel behavior. Because interleaving and visualization is now automated, it is feasible to construct arbitrarily long sequences of behavior. To demonstrate the process, we present a model of automated teller interactions in Apex and discuss implications for user modeling",Bonnie E. John;Alonso H. Vera;Michael Matessa;Michael Freed;Roger W. Remington,
CHI,2002,"Keeping things in context: a comparative evaluation of focus plus context screens, overviews, and zooming",10.1145/503376.503423,"Users working with documents that are too large and detailed to fit on the user's screen (e.g. chip designs) have the choice between zooming or applying appropriate visualization techniques. In this paper, we present a comparison of three such techniques. The first, focus plus context screens, are wall-size low-resolution displays with an embedded high-resolution display region. This technique is compared with overview plus detail and zooming/panning. We interviewed fourteen visual surveillance and design professionals from different areas (graphic design, chip design, air traffic control, etc.) in order to create a repre sentative sample of tasks to be used in two experimental comparison studies. In the first experiment, subjects using focus plus context screens to extract information from large static documents completed the two experimental tasks on average 21% and 36% faster than when they used the other interfaces. In the second experiment, focus plus context screens allowed subjects to reduce their error rate in a driving simulation to less than one third of the error rate of the competing overview plus detail setup",Patrick Baudisch;Nathaniel Good;Victoria Bellotti;Pamela K. Schraedley,
CHI,2001,Visualization components for persistent conversations,10.1145/365024.365073,"An appropriately designed interface to persistent, threaded conversations could reinforce socially beneficial behavior by prominently featuring how frequently and to what degree each user exhibits such behaviors. Based on the data generated by the Netscan data-mining project [9], we have developed a set of tools for illustrating the structure of discussion threads like those found in Usenet newsgroups and the patterns of participation within the discussions. We describe the benefits and challenges of integrating these tools into a multi-faceted dashboard for navigating and reading discussions in social cyberspaces like Usenet and related interaction media. Visualizations of the structure of online discussions have applications for research into the sociology of online groups as well as possible interface designs for their members.",Marc A. Smith;Andrew T. Fiore,
CHI,2001,Digital family portraits: supporting peace of mind for extended family members,10.1145/365024.365126,"A growing social problem in the U.S., and elsewhere, is supporting older adults who want to continue living independently, as opposed to moving to an institutional care setting. One key part of this complex problem is providing awareness of senior adults day-to-day activities, promoting peace of mind for extended family members. In this paper, we introduce the concept of a digital family portrait that provides qualitative visualizations of a family members daily life. Leveraging a familiar household object, the picture frame, our design populates the frame with iconic imagery summarizing 28 days. In a final implementation, the digital family portrait would gather information from sensors in the home.",Elizabeth D. Mynatt;Jim Rowan;Sarah Craighill;Annie Jacobs,
CHI,2001,3D or not 3D? evaluating the effect of the third dimension in a document management system,10.1145/365024.365309,"Several recent research systems have provided interactive three-dimensional (3D) visualisations for supporting everyday work such as file and document management. But what improvements do these 3D interfaces offer over their traditional 2D counterparts? This paper describes the comparative evaluation of two document management systems that differ only in the number of dimensions used for displaying and interacting with the data. The 3D system is heavily based on Robertson et al.'s Data Mountain, which supports users in storing, organising and retrieving “thumbnail” representations of documents such as bookmarked Web-pages. Results show that our subjects were faster at storing and retrieving pages in the display when using the 2D interface, but not significantly so. As expected, retrieval times significantly increased as the number of thumbnails increased. Despite the lack of significant differences between the 2D and 3D interfaces, subjective assessments showed a significant preference for the 3D interface.",Andy Cockburn;Bruce J. McKenzie,
CHI,2001,Information scent as a driver of Web behavior graphs: results of a protocol analysis method for Web usability,10.1145/365024.365331,"The purpose of this paper is to introduce a replicable WWW protocol analysis methodology illustrated by application to data collected in the laboratory. The methodology uses instrumentation to obtain detailed recordings of user actions with a browser, caches Web pages encoutered, and videotapes talk-aloud protocols. We apply the current form of the method to the analysis of eight Web protocols, visualizing the structure of the interaction and showing the strong effect of information scent in determining the path followed.",Stuart K. Card;Peter Pirolli;Mija M. Van Der Wege;Julie Bauer Morrison;Robert W. Reeder;Pamela K. Schraedley;Jenea Boshart,
CHI,2001,Visual information foraging in a focus + context visualization,10.1145/365024.365337,"Eye tracking studies of the Hyperbolic Tree browser [10] suggest that visual search in focus+context displays is highly affected by information scent (i.e., local cues, such as text summaries, used to assess and navigate toward distal information sources). When users detected a strong information scent, they were able to reach their goal faster with the Hyperbolic Tree browser than with a conventional browser. When users detected a weak scent or no scent, users exhibited less efficient search of areas with a high density of visual items. In order to interpret these results we present an integration of the CODE Theory of Visual Attention (CTVA) with information foraging theory. Development of the CTVA-foraging theory could lead to deeper analysis of interaction with visual displays of content, such as the World Wide Web or information visualizations.",Peter Pirolli;Stuart K. Card;Mija M. Van Der Wege,
CHI,2000,HandSCAPE: a vectorizing tape measure for on-site measuring applications,10.1145/332040.332417,"We introduce HandSCAPE, an orientation-aware digital tape measure, as an input device for digitizing field measurements, and visualizing the volume of the resulting vectors with computer graphics. Using embedded orientation-sensing hardware, HandSCAPE captures relevant vectors on each linear measurements and transmits this data wirelessly to a remote computer in real-time. To guide us in design, we have closely studied the intended users, their tasks, and the physical workplaces to extract the needs from real worlds. In this paper, we first describe the potential utility of HandSCAPE for three on-site application areas: archeological surveys, interior design, and storage space allocation. We then describe the overall system which includes orientation sensing, vector calculation, and primitive modeling. With exploratory usage results, we conclude our paper for interface design issues and future developments.",Jay Lee;Victor Su;Sandia Ren;Hiroshi Ishii 0001,
CHI,2000,"The scent of a site: a system for analyzing and predicting information scent, usage, and usability of a Web site",10.1145/332040.332423,"Designers and researchers of users' interactions with the World Wide Web need tools that permit the rapid exploration of hypotheses about complex interactions of user goals, user behaviors, and Web site designs. We present an architecture and system for the analysis and prediction of user behavior and Web site usability. The system integrates research on human information foraging theory, a reference model of information visualization and Web data-mining techniques. The system also incorporates new methods of Web site visualization (Dome Tree, Usage Based Layouts), a new predictive modeling technique for Web site use (Web User Flow by Information Scent, WUFIS), and new Web usability metrics.",Ed Huai-hsin Chi;Peter Pirolli;James E. Pitkow,
CHI,2000,Enriching buyers' experiences: the SmartClient approach,10.1145/332040.332446,"In electronic commerce, a satisfying buyer experience is a key competitive element. We show new techniques for better adapting interaction with an electronic catalog system to actual buying behavior. Our model replaces the sequential separation of needs identification and product brokering with a conversation in which both processes occur simultaneously. This conversation supports the buyer in formulating his or her needs, and in deciding which criteria to apply in selecting a product to buy. We have experimented with this approach in the area of travel planning and developed a system called SmartClient Travel which supports this process. It includes tools for need identification, visualization of alternatives, and choosing the most suitable one. We describe the system and its implementation, and report on user studies showing its advantages for electronic catalogs.",Pearl Pu;Boi Faltings,
CHI,2000,The cubic mouse: a new device for three-dimensional input,10.1145/332040.332491,"We have developed a new input device that allows users to intuitively specify three-dimensional coordinates in graphics applications. The device consists of a cube-shaped box with three perpendicular rods passing through the center and buttons on the top for additional control. The rods represent the X, Y, and Z axes of a given coordinate system. Pushing and pulling the rods specifies constrained motion along the corresponding axes. Embedded within the device is a six degree of freedom tracking sensor, which allows the rods to be continually aligned with a coordinate system located in a virtual world. We have integrated the device into two visualization prototypes for crash engineers and geologists from oil and gas companies. In these systems the Cubic Mouse controls the position and orientation of a virtual model and the rods move three orthogonal cutting or slicing planes through the model. We have evaluated the device with experts from these domains, who were enthusiastic about its ease of use.",Bernd Fröhlich 0001;John Plate,
CHI,1999,TouchCounters: Designing Interactive Electronic Labels for Physical Containers,10.1145/302979.303110,"We present TouchCounters, an integrated system of electronicmodules, physical storage containers, and shelving surfaces for thesupport of collaborative physical work. Through physical sensorsand local displays, TouchCounters record and display usage historyinformation upon physical storage containers, thus allowing accessto this information during the performance of real-world tasks. Adistributed communications network allows this data to be exchangedwith a server, such that users can access this information fromremote locations as well.
Based upon prior work in ubiquitous computing and tangibleinterfaces, TouchCounters incorporate new techniques, includingusage history tracking for physical objects and multi-displayvisualization. This paper describes the components, interactions,implementation, and conceptual approach of the TouchCounterssystem.",Paul Yarin;Hiroshi Ishii 0001,
CHI,1999,The Reader's Helper: A Personalized Document Reading Environment,10.1145/302979.303139,"Over the last two centuries, reading styles have shifted awayfrom the reading of documents from beginning to end and toward theskimming of documents in search of relevant information. This trendcontinues today where readers, often confronted with aninsurmountable amount of text, seek more efficient methods ofextracting relevant information from documents. In this paper, anew document reading environment is introduced called the ReadersHelperTM, which supports the reading of electronic and paperdocuments. The Readers Helper analyzes documents and produces arelevance score for each of the readers topics of interest, therebyhelping the reader decide whether the document is actually worthskimming or reading. Moreover, during the analysis process, topicof interest phrases are automatically annotated to help the readerquickly locate relevant information. A new informationvisualization tool, called the ThumbarTM, is used in conjunctionwith relevancy scoring and automatic annotation to portray acontinuous, dynamic thumb-nail representation of the document. Thisfurther supports rapid navigation of the text.",Jamey Graham,
CHI,1999,VR's Frames of Reference: A Visualization Technique for Mastering Abstract Multidimensional Information,10.1145/302979.303141,"This paper describes a research study that investigated howdesigners can use frames of reference (egocentric, exocentric, anda combination of the two) to support the mastery of abstractmultidimensional information. The primary focus of this study wasthe relationship between FORs and mastery; the secondary focus wason other factors (individual characteristics and interactionexperience) that were likely to influence the relationship betweenFORs and mastery. This studys outcomes (1) clarify how FORs work inconjunction with other factors in shaping mastery, (2) highlightstrengths and weaknesses of different FORs, (3) demonstrate thebenefits of providing multiple FORs, and (4) provide the basis forour recommendations to HCI researchers and designers.",Marilyn C. Salzman;Christopher J. Dede;R. Bowen Loftin,
CHI,1999,Excentric Labeling: Dynamic Neighborhood Labeling for Data Visualization,10.1145/302979.303148,"The widespread use of information visualization is hampered bythe lack of effective labeling techniques. An informal taxonomy oflabeling methods is proposed. We then describe excentric labeling,a new dynamic technique to label a neighborhood of objects locatedaround the cursor. This technique does not intrude into theexisting interaction, it is not computationally intensive, and waseasily applied to several visualization applications. A pilot studywith eight subjects indicates a strong speed benefit over a zoominterface for tasks that involve the exploration of large numbersof objects. Observations and comments from users are presented.",Jean-Daniel Fekete;Catherine Plaisant,
CHI,1999,Visualizing Implicit Queries for Information Management and Retrieval,10.1145/302979.303158,"In this paper, we describe the use of similarity metrics in anovel visual environment for storing and retrieving favorite webpages. The similarity metrics, called Implicit Queries, areused to automatically highlight stored web pages that are relatedto the currently selected web page. Two experiments explored howusers manage their personal web information space with and withoutthe Implicit Query highlighting and later retrieve their stored webpages. When storing and organizing web pages, users with ImplicitQuery highlighting generated slightly more categories. ImplicitQueries also led to faster web page retrieval time, although theresults were not statistically significant.",Mary Czerwinski;Susan T. Dumais;George G. Robertson;Susan Dziadosz;Scott Lee Tiernan;Maarten van Dantzich,
CHI,1998,Information Archiving with Bookmarks: Personal Web Space Construction and Organization,10.1145/274644.274651,"Bookmarks are used as ""personal Web information spaces"" to help people remember and retrieve interesting Web pages. A study of personal Web information spaces surveyed 322 Web users and analyzed the bookmark archives of 50 Web users. The results of this study are used to address why people make bookmarks, and how they create, use, and organize them. Recommendations for improving the organization, visualization, representation, and integration of bookmarks are provided. The recommendations include simple mechanisms for filing bookmarks at creation time, the use of time-based visualizations with automated filters, the use of contextual information in representing bookmarks, and the combination of hierarchy formation and Web page authoring to aid in organizing and viewing bookmarks.",David Abrams;Ronald Baecker;Mark H. Chignell,
CHI,1998,Visualizing the Evolution of Web Ecologies,10.1145/274644.274699,"Several visualizations have emerged which attempt to visualize all or part of the World Wide Web. Those visualizations, however, fail to present the dynamically changing ecology of users and documents on the Web. We present new techniques for Web Ecology and Evolution Visualization (WEEV). Disk Trees represent a discrete time slice of the Web ecology. A collection of Disk Trees forms a Time Tube, representing the evolution of the Web over longer periods of time. These visualizations are intended to aid authors and webmasters with the production and organization of content, assist Web surfers making sense of information, and help researchers understand the Web.",Ed Huai-hsin Chi;James E. Pitkow;Jock D. Mackinlay;Peter Pirolli;Rich Gossweiler;Stuart K. Card,
CHI,1998,DIVA: Exploratory Data Analysis with Multimedia Streams,10.1145/274644.274701,"DIVA supports exploratory data analysis of multimedia streams, enabling users to visualize, explore and evaluate patterns in data that change over time. The underlying stream algebra provides the mathematical basis for operating on diverse kinds of streams. The streamer visualization technique provides a smooth transition between spatial and temporal views of the data. Mapping source and presentation streams into a two-dimensional space provides users with a direct manipulation, nontemporal interface for viewing and editing streams. DIVA was developed to help us analyze both qualitative and quantitative data collected in our research with French air traffic controllers, including video of controllers at work, audio records of telephone, radio and other conversations, output from tools such as RADAR, and coded logs based on our observations. Although our emphasis is on exploratory data analysis, DIVA's stream architecture should prove useful for a wide variety of multimedia applications.",Wendy E. Mackay;Michel Beaudouin-Lafon,
CHI,1998,Finding and Visualizing Inter-Site Clan Graphs,10.1145/274644.274705,"For many purposes, the Web page is too small a unit of interaction. Users often want to interact with larger-scale entities, particularly collections of topically related items. We report three innovations that address this user need. l We replaced the web page with the web sire as the basic unit of interaction and analysis* We defined a new information structure, the clan graph, that groups together sets of related sites. l We invented a new graph visualization, the auditorium visualization, that reveals important structural and content properties of sites within a clan graph. We have discovered interesting information that can be extracted from the structure of a clan graph. We can identify structurally important sites with many incoming or outgoing links. Lii between sites serve important functions: they often identify “f?ont door” pages of sites, sometimes identify especially significant pages within a site, and occasionally contain informative anchor text.",Loren G. Terveen;William C. Hill,
CHI,1997,Characterizing Interactive Externalizations,10.1145/258549.258803,"This paper seeks to characterize the space of techniques that exist for interactive externalisations (visualizations). A selection of visualizations are classified with respect to: the types of data represented, the nature of the visible feedback displayed and the forms of interactivity used. Such characterization provides a method for evaluating potential designs and comparing different tools.",Lisa Tweedie,
CHI,1997,Balancing Usability and Learning in an Interface,10.1145/258549.258995,"Creating educational software forces a difficult tradeoff. The software must be easy for the students to use, yet not so simple that the parts that students are to learn from are done for them by the computer. DEVICE (Dynamic Environment for Visualization of Chemical Engineering) is a learning environment aimed at allowing chemical engineering students to model chemical engineering problems, then execute those problems as simulations. In the design of DEVICE, we have attempted to use student tasks to focus attention on the most important parts of the problem without overwhelming students with extnneous detail.",Noel Rappin;Mark Guzdial;Matthew J. Realff;Pete Ludovice,
CHI,1997,Putting Visualization to Work: ProgramFinder for Youth Placement,10.1145/258549.259003,"The Human-Computer Interaction Laboratory (HCIL) and the Maryland Department of Juvenile Justice (DJJ) have been working together to develop the ProgramFinder, a tool for choosing programs for a troubled youth from drug rehabilitation centers to secure residential facilities. The seemingly straightforward journey of the ProgramFinder from an existing user interface technique to a product design required the development of five different prototypes which involved user interface design, prototype implementation, and selecting search criterion. While HCIL’s effort focused primarily on design and implementation, DJJ’s attribute selection process was the most time consuming and difficult task. We also found that a direct link to DJJ’s workflow was needed in the prototypes to generate the necessary “buy-in”. This paper analyzes the interaction between the efforts of HCIL and DJJ and the amount of “buyin” by DJJ staff and management. Lesson learned are presented for developers.",Jason B. Ellis;Anne Rose;Catherine Plaisant,
CHI,1997,Bringing Treasures to the Surface: Iterative Design for the Library of Congress National Digital Library Program,10.1145/258549.259009,"ABSTRACT The Human-Computer Interaction Lab worked with a team for the Library of Congress (LC) to develop and test interface designs for LC's National Digital Library Program. Three iterations are described and illustrate the progression of the project toward a compact design that minimizes scrolling and jumping and anchors users in a screen space that tightly couples search and results. Issues and resolutions are discussed for each iteration and reflect the challenges of incomplete metadata, data visualization, and the rapidly changing web environment.",Catherine Plaisant;Gary Marchionini;Tom Bruns;Anita Komlodi;Laura Campbell,
CHI,1996,Silk from a Sow's Ear: Extracting Usable Structures from the Web,10.1145/238386.238450,"In its current implementation, the World-Wide Web lacks much of the explicit structure and strong typing found in many closed hypertext systems. While this property probably relates to the explosive acceptance of the Web, it further complicates the already difficult problem of identifying usable structures and aggregates in large hypertext collections. These reduced structures, or localities, form the basis for simplifying visualizations of and navigation through complex hypertext systems. Much of the previous research into identifying aggregates utilize graph theoretic algorithms based upon structural topology, i.e., the linkages between items. Other research has focused on content analysis to form document collections. This paper presents our exploration into techniques that utilize both the topology and textual similarity between items as well as usage data collected by servers and page meta-information lke title and size. Linear equations and spreading activation models are employed to arrange Web pages based upon functional categories, node types, and relevancy.",Peter Pirolli;James E. Pitkow;Ramana Rao,
CHI,1996,LifeLines: Visualizing Personal Histories,10.1145/238386.238493,"LifeLines provide a general visualization environment for personal histories that can be applied to medical and court records, professional histories and other types of biographical data. A one screen overview shows multiple facets of the records. Aspects, for example medical conditions or legal cases, are displayed as individual time lines, while icons indicate discrete events, such as physician consultations or legal reviews. Line color and thickness illustrate relationships or significance, rescaling tools and filters allow users to focus on part of the information. LifeLines reduce the chances of missing information, facilitate spotting anomalies and trends, streamline access to details, while remaining tailorable and easily transferable between applications. The paper describes the use of LifeLines for youth records of the Maryland Department of Juvenile Justice and also for medical records. User's feedback was collected using a Visual Basic prototype for the youth record. Techniques to deal with complex records are reviewed and issues of a standard personal record format are discussed.",Catherine Plaisant;Brett Milash;Anne Rose;Seth Widoff;Ben Shneiderman,
CHI,1996,Multiagent Model of Dynamic Design: Visualization as an Emergent Behavior of Active Design Agents,10.1145/238386.238566,"This research has been motivated by the lack of models and languages in the visual design field that are able to address design solutions, which continuously adapt in response to the dynamic changes both in the information itself and in the goals or intentions of the information recipient. This paper postulates a muhiagent model of dynamic design--a theoretical framework of design that provides a model with which the visual designer can think during the course of designing. The model employs a decentralized model of design as a premise, and borrows its conceptual model from the improvisational performance, such as dance and music, and bases its theoretical and technical framework on the field of multiagent systems. A design solution is considered an emergent behavior of a collection of active design agents, or performers, each of which is responsible for presenting a particular segment of information. The graphical behaviors of design agents are described by their dynamic activities--rather than by the traditional method of fixed attributes. The model is illustrated with two design projects, Dynamic News Display System and E-Mail Display, both of which were implemented using a multiagent design simulation system, perform, along with an agent description language, persona.",Suguru Ishizaki,
CHI,1996,Externalising Abstract Mathematical Models,10.1145/238386.238587,"Abstract mathematical models play an important part in engineering design, economic decision making and other activities. Such models can be externalised in the form of Interactive Visualisation Artifacts (IVAs). These IVAs display the data generated by mathematical models in simple graphs which are interactively linked. Visual examination of these graphs enables users to acquire insight into the complex relations embodied in the model. In the engineering context this insight can be exploited to aid design. The paper describes two IVAs for engineering design: The Influence Explorer and The Prosection Matrix. Formative evaluation studies are briefly discussed.",Lisa Tweedie;Robert Spence;Huw Dawkes;Hua Su,
CHI,1996,Interaction Design and Human Factors Support in the Development of a Personal Communicator for Children,10.1145/238386.238603,"Today's computer games for children are primarily focused on boys. Two years ago Philips started the development of a new 'personal communication' product that addresses the needs of young children and especially the needs of young gifts. This article is focused on the interaction design and human factors support provided throughout the development of this product. It illustrates the involvement of the interaction design discipline, ranging from the initial generation and visualization of interface ideas to the final transfer to the software engineering team of detailed user interface specifications. The article also describes how human factors support ensured that potential users were involved on continuously in the design process, as well' as how this involvement influenced the development of the final product. The article concludes with a discussion of the lessons learned in designing products for children.",Ron Oosterholt;Mieko Kusano;Govert de Vries,
CHI,1995,TileBars: Visualization of Term Distribution Information in Full Text Information Access,10.1145/223904.223912,,Marti A. Hearst,
CHI,1995,An Organic User Interface for Searching Citation Links,10.1145/223904.223913,"This paper describes Butterfly, an Information Visualizer application for accessing DIALOG'S Science Citation databases across the Internet. Network information often involves slow access that conflicts with the use of highly-interactive information visualization. Butterfly addresses this problem, integrating search, browsing, and access management via four techniques: 1) visualization supports the assimilation of retrieved information and integrates search and browsing activity, 2) automatically-created ""link-generating"" queries assemble bibliographic records that contain reference information into citation graphs, 3) asynchronous query processes explore the resulting graphs for the user, and 4) process controllers allow the user to manage these processes. We use our positive experience with the Butterfly implementation to propose a general information access approach, called Organic User Inteifacesfor Infomiation Access, in which a virtual landscape grows under user control as information is accessed automatically.",Jock D. Mackinlay;Ramana Rao;Stuart K. Card,
CHI,1995,Space-Scale Diagrams: Understanding Multiscale Interfaces,10.1145/223904.223934,"Big information worlds cause big problems for interfaces. There is too much to see. They are hard to navigate. An armada of techniques has been proposed to present the many scales of information needed. Space-scale diagrams provide an analytic framework for much of this work. By representing both a spatial world and its different magnifications explicitly, the diagrams allow the direct visualization and analysis of important scale related issues for interfaces.",George W. Furnas;Benjamin B. Bederson,
CHI,1995,Providing Assurances in a Multimedia Interactive Environment,10.1145/223904.223936,"In ordinary telephone calls, we rely on cues for the assurance that the connection is active and that the other party is listening to what we are saying. For instance, noise on the line (whether it be someone's voice, traffic sounds, or background static from a bad connection) tells us about the state of our connection. Similarly, the occasional ""uhuh"" or muffled sounds from a side conversation tells us about the focus and activity of the person on the line. Conventional telephony is based on a single connection for communication between two parties — as such, it has relatively simple assurance needs. Multimedia, multiparty systems increase the complexity of the communication in two orthogonal directions, leading to a concomitant increase in assurance needs. As the complexity of these systems and services grows, it becomes increasingly difficult for users to assess the current state of these services and the level of the user interactions within the systems. We have addressed this problem through the use of assurances that are designed to provide information about the connectivity, presence, focus, and activity in an environment that is part virtual and part real. We describe how independent network media services (a virtual meeting room service, a holophonic sound service, an application sharing service, and a 3D augmented reality visualization system) were designed to work together, providing users with coordinated cohesive assurances for virtual contexts in multimedia, multiparty communication and interaction.",Dorée D. Seligmann;Rebecca Mercuri;John T. Edmark,
CHI,1995,Virtual Reality on a WIM: Interactive Worlds in Miniature,10.1145/223904.223938,"This paper explores a user interface technique which augments an immersive head tracked display with a hand-held miniature copy of the virtual environment. We call this interface technique the Worlds in Miniature (WIM) metaphor. By establishing a direct relationship between life-size objects in the virtual world and miniature objects in the WIM, we can use the WIM as a tool for manipulating objects in the virtual environment. In addition to describing object manipulation, this paper explores ways in which Worlds in Miniature can act as a single unifying metaphor for such application independent interaction techniques as object selection, navigation, path planning, and visualization. The WIM metaphor naturally offers multiple points of view and multiple scales at which the user can operate, all without requiring explicit modes or commands. Informal user observation indicates that users adapt to the Worlds in Miniature metaphor quickly and that physical props are helpful in manipulating the WIM and other objects in the environment.",Richard Stoakley;Matthew Conway;Randy F. Pausch,
CHI,1995,Electronic Futures Markets versus Floor Trading: Implications for Interface Design,10.1145/223904.223942,"The primary concern in designing an interface for an electronic trading system is the impact on market liquidity [9]. Current systems make use of efficient order-execution algorithms but fail to capture elements of the trading floor that contribute to an efficient market [9]. We briefly describe tasks conducted in futures pit trading and current off-hours electronic trading systems. Understanding the tasks helps define key components to an interface for electronic trading. These include visualization of the market and its participants, a trading process which allows active participation and price discovery as well as concurrent interaction among each of the participants.",Satu S. Parikh;Gerald L. Lohse,
CHI,1995,Visualizing Complex Hypermedia Networks through Multiple Hierarchical Views,10.1145/223904.223947,"Our work concerns visualizing the information space of hypermedia systems using multiple hierarchical views. Although overview diagrams are useful for helping the user to navigate in a hypermedia system, for any real-world system they become too complicated and large to be really useful. This is because these diagrams represent complex network structures which are very difficult to visualize and comprehend. On the other hand, effective visualizations of hierarchies have been developed. Our strategy is to provide the user with different hierarchies, each giving a different perspective to the underlying information space, to help the user better comprehend the information. We propose an algorithm based on content and structural analysis to form hierarchies from hypermedia networks. The algorithm is automatic but can be guided by the user. The multiple hierarchies can be visualized in various ways. We give examples of the implementation of the algorithm on two hypermedia systems.",Sougata Mukherjea;James D. Foley;Scott E. Hudson,
CHI,1995,A Focus+Context Technique Based on Hyperbolic Geometry for Visualizing Large Hierarchies,10.1145/223904.223956,"We present a new focus+context (fisheye) technique for visualizing and manipulating large hierarchies. Our technique assigns more display space to a portion of the hierarchy while still embedding it in the context of the entire hierarchy. The essence of this scheme is to lay out the hierarchy in a uniform way on a hyperbolic plane an d map this plane onto a circular display region. This supports a smooth blending between focus and context, as well as continuous redirection of the focus. We have developed effective procedures for manipulating the focus using pointer clicks as well as interactive dragging, and for smoothly an imating transitions across such manipulation. A laboratory experiment comparing the hyperbolic browser with a conventional hierarchy browser was conducted.",John Lamping;Ramana Rao;Peter Pirolli,
CHI,1995,GeoSpace: An Interactive Visualization System for Exploring Complex Information Spaces,10.1145/223904.223959,,Ishantha Lokuge;Suguru Ishizaki,
CHI,1995,Bridging the Gulf Between Code and Behavior in Programming,10.1145/223904.223969,"Program debugging can be an expensive, complex and frustrating process. Conventional programming environments provide little explicit support for the cognitive tasks of diagnosis and visualization faced by the programmer.",Henry Lieberman;Christopher Fry,
CHI,1995,Articulating a Metaphor through User-Centered Design,10.1145/223904.223981,"TabWorksTM book metaphor enhances the standard WindowsTM user interface, providing an alternative way to organize applications and documents in a familiar, easy to use environment. The TabWorks interface was designed collaboratively by IDEO and XSoft and was based on a concept developed at Xerox PARe. This briefing describes how a user-centered approach affected the design of the TabWorks user interface: how the metaphor's visualization evolved and how interaction mechanisms were selected and designed.",H. J. Moll-Carrillo;Gitta Salomon;Matthew Marsh;Jane Fulton Suri;Peter Spreenberg,
CHI,1994,Using aggregation and dynamic queries for exploring large data sets,10.1145/191666.191682,"When working with large data sets, users perform three primary types of activities: data manipulation, data analysis, and data visualization. The data manipulation process involves the selection and transformation of data prior to viewing. This paper addresses user goals for this process and the interactive interface mechanisms that support them. We consider three classes of data manipulation goals: controlling the scope (selecting the desired portion of the data), selecting the focus of attention (concentrating on the attributes of data that are relevant to current analysis), and choosing the level of detail (creating and decomposing aggregates of data). We use this classification to evaluate the functionality of existing data exploration interface techniques. Based on these results, we have expanded an interface mechanism called the Aggregate Manipulator (AM) and combined it with Dynamic Query (DQ) to provide complete coverage of the data manipulation goals. We use real estate sales data to demonstrate how the AM and DQ synergistically function in our interface.",Jade Goldstein;Steven F. Roth,
CHI,1994,The cost-of-knowledge characteristic function: display evaluation for direct-walk dynamic information visualizations,10.1145/191666.191753,"In this paper we present a method, the Cost-of-Knowledge Characteristic Function, for characterizing information access from dynamic displays. The paper works out this method for a simple, but important, class of dynamic displays called direct-walk interactive information visualizations, in which information is accessed through a sequence of mouse selections and key selections. The method is used to characterize a simple calendar task for an application of the Information Visualizer, to compute the changes in characterization as the result of possible program variants, and to conduct empirical comparison between different systems with the same function.",Stuart K. Card;Peter Pirolli;Jock D. Mackinlay,
CHI,1994,The movable filter as a user interface tool,10.1145/191666.191774,"Magic Lens filters are a new user interface tool that combine an arbitrarily-shaped region with an operator that changes the view of objects viewed through that region. These tools can be interactively positioned over on-screen applications much as a magnifying glass is moved over a newspaper. They can be used to help the user understand various types of information, from text documents to scientific visualizations. Because these filters are movable and apply to only part of the screen, they have a number of advantages over traditional windowwide viewing modes: they employ an attractive metaphor based on physical lenses, show a modified view in the context of the original view, limit clutter to a small region, allow easy construction of visual macros and provide a uniform paradigm that can be extended across different types of information and applications. This paper describes these advantages in more detail and illustrates them with examples of magic lens filters in use over a variety of applications. CR",Maureen C. Stone;Kenneth P. Fishkin;Eric A. Bier,
CHI,1994,The table lens: merging graphical and symbolic representations in an interactive focus + context visualization for tabular information,10.1145/191666.191776,"We present a new visualization, called the Table Lens, for visualizing and making sense of large tables. The visualization uses a focus+context (fisheye) technique that works effectively on tabular information because it allows display of crucial label information and multiple distal focal areas. In addition, a graphical mapping scheme for depicting table contents has been developed for the most widespread kind of tables, the cases-by-variables table. The Table Lens fuses symbolic and graphical representations into a single coherent view that can be fluidly adjusted by the user. This fusion and interactivity enables an extremely rich and natural style of direct manipulation exploratory data analysis.",Ramana Rao;Stuart K. Card,
CHI,1994,Passive real-world interface props for neurosurgical visualization,10.1145/191666.191821,"We claim that physical manipulation of familiar real-world objects in the user’s real environment is an important technique for the design of three-dimensional user interfaces. These real-world passive inte~ace props are manipulated by the user to specify spatial relationships between interface objects. By unobtrusively embedding free-space position and orientation trackers within the props, we enable the computer to passively observe a natural user dialog in the real world, rather than forcing the user to engage in a contrived dialog in the computer-generated world. We present neurosurgical planning as a driving application and demonstrate the utility of a head viewing prop, a cutting-plane selection prop, and a trajectory selection prop in this domain. Using passive props in this interface exploits the surgeon’s existing skills, provides direct action-task correspondence, eliminates explicit modes for separate tools, facilitates natural two-handed interaction, and provides tactile and kinesthetic feedback for the user. Our informal evaluation sessions have shown that with a cursory introduction, neurosurgeons who have never seenthe interface can understand and use it without training.",Ken Hinckley;Randy Pausch;John C. Goble;Neal F. Kassell,
CHI,1993,Fish tank virtual reality,10.1145/169059.169066,"The defining characteristics of what we call “Fish Tank Virtual Reality” are a stereo image of a three dimensional (3D) scene viewed on a monitor using a perspective projection coupled to the head position of the observer. We discuss some of the relative merits of this mode of viewing as compared to head mounted stereo displays. In addition, we report the experimental investigation of the following variables: 1) whether or not the perspective view is coupled to the actual viewpoint of the observer, 2) whether stereopsis is employed. Experiment 1 involved the subjective comparison of pairs of viewing conditions and the results suggest that head coupling may be more important than stereo in yielding a strong impression of three dimensionality. Experiment 2 involved subjects tracing a path from a leaf of a 3D tree to the correct root (there were two trees intermeshed). The error rates ranged from 22% in the pictorial display, to 1.3% in the head coupled stereo display. The error rates for stereo alone and head coupling alone were 14.7% and 3.2% respectively. We conclude that head coupling is probably more important than stereo in 3D visualization and that head coupling and stereo combined provide an important enhancement to monitor based computer graphics.",Colin Ware;Kevin Arthur;Kellogg S. Booth,
CHI,1993,A space based model for user interaction in shared synthetic environments,10.1145/169059.169068,"In a distributed shared synthetic environment with provisions for high quality 3D visualization and interaction, it is possible to implement a powerful variant of a rooms/space metaphor based on the concept of presence or proximity between participants in 3D space. This kind of model can be used as an interface between the user and the computer, for overview and control of applications, file systems, networks and other computer resources, as well as for communication and collaboration with other users in the networked environment. We model proximity with a geometric volume of the immediate surroundings, the aura, of the participant's representation in the synthetic environment. This proximity, or aura, is used to establish presence at meetings, to establish communication channels and to provide interaction.",Lennart E. Fahlén;Charles Grant Brown;Olov Ståhl;Christer Carlsson,
CHI,1993,Automatic structure visualization for video editing,10.1145/169059.169118,"We developed intelligent functions for the automatic description of video structure, and visualization methods for temporal-spatial video structures obtained by these functions as well as for the functions. The functions offer descriptions of cut separations, motion of the camera and filmed objects, tracts and contour lines of objects, existence of objects, and periods of existence. Furthermore, identical objects are automatically linked. Thus the visualization methods supported by object-links allow users to freely browse and directly manipulate the structure including descriptions and raw video data.",Hirotada Ueda;Takafumi Miyatake;Shigeo Sumino;Akio Nagasaka,
CHI,1993,A synergistic approach to specifying simple number independent layouts by example,10.1145/169059.169221,"A grid-based technique to specify simple number independent layouts by example is described. This technique was originally developed to support layout specification for a parallel program visualization system but can be applied to aid other simple graphical layout tasks as well. The technique works by allowing the user to construct an example layout using a grid-based interaction technique. This example can then be generalized into a layout algorithm which can be applied to create layouts of any size. However, rather than simply choosing the “best” generalization, the system described here takes a synergistic approach. New examples from a set of alternative generalizations are presented to the user so that they can guide and control the generalization process. This provides more understanding and control of the generalization to be constructed from only one small example.",Scott E. Hudson;Chen-Ning Hsi,
CHI,1993,Beyond interface builders: model-based interface tools,10.1145/169059.169305,"Interface builders only support the construction of the menus and dialogue boxes of an application. They do not support the construction of interfaces of many application classes (visualization, simulation, command and control, domain-specific editors) because of the dynamic and complex information that these applications process. HUMANOID is a model-based interface design and construction tool where interfaces are specifkd by building a declarative description (model) of their presentation and behavior. HUMANOID’S modeling language provides simple abstraction, iteration and conditional constructs to model the interface features of these application classes. HUMANOID provides an easy-touse designer’s interface that lets designers build complex interfaces without programming.",Pedro A. Szekely;Ping Luo;Robert Neches,
CHI,1993,High interaction data visualization using Seesoft to visualize program change history (abstract),10.1145/169059.169480,"A problem in developing large software systems is understanding the source code. This problem is difficult because of the volume of code. The listing for a moderately sized system with 100,000 lines, printed 50 lines per page, would run 2,000 pa~s. This video shows a new software tool, Seesoft , that applies scientific visualization techniques to visualizing code. The visualization approach is to represent files in a directoty in columns and the source code lines as rows of colored pixels. The indentation and length of each row of pixe18 corresponds to the actual code. The color of each row of pixels is determined by a statistic such as the age, programmer, or type of line, that we obtain from the change management system. The visual impression is that of a miniature picture of the source code with the indentation showing the usual C controls structure and the color showing the spatial distribution of the statistic. A user may adjust the display using direct manipulation techniques to discover interesting patterns in the code. Software engineering concepts such as complexity and bug fix on fix density can be visualized. The main interest of this work to the human factors community is the use of graphical user interface for selecting and combining statistics from a database, the effective use of hundreds of colors to display a mass of data, and the reduction of the point-and-click direct manipulation metaphor to just pointing, e.g. something of interest will occur where ever the mouse points to on the display.",Joseph L. Steffen;Stephen G. Eick,
CHI,1993,IMPACT (abstract): interactive motion picture authoring system for creative talent,10.1145/169059.169518,"INTRODUCTION We are developing a multimedia authoring system, called IMPACT [1]. It is not easy for non-professionaf users to get good quality motion pictures and to edit them, for instance, in order to create multimedia presentations that express their concepts. To make this kind of tasks feasible for everyone, image-recognition technology is applied. Visualization of the structure of motion pictures is also very important [2]. A couple of visualization technique are developed for time axis editing.",Hirotada Ueda;Takafumi Miyatake;Satoshi Yoshizawa,
CHI,1992,Human-Computer Interaction Research at Georgia Institute of Technology,10.1145/142750.142757,"HCI research at Georgia Tech is found in three cooperating groups: the Engineering Psychology and Experimental Psychology Programs in the School of Psychology, the Center for Human-Machine Systems Research in the School of Industrial and Systems Engineering, and the interdisciplinary Graphics, Visualization and Usability (GVU) Center. We cooperate via cross-listed courses, having students in one area take a minor in another area, collaborative research projects, serving on Ph. D. committees, joint colloquia and brown bag lunches, and joint appointments. The GVU Center (housed in the College of Computing) and Cognitive Science Program (sponsored by Psychology, Industrial and Systems Engineering, and the College of Computing) involves a number of the same faculty, further enhancing our collaborations.",James D. Foley;Christine M. Mitchell;Neff Walker,
CHI,1992,An Interface for Interactive Spatial Reasoning and Visualization,10.1145/142750.142762,"An interface for software that creates a natural environment for engineering graphics students to improve their spatial reasoning and 3D visualization skills is described. The skills of interest involve spatial transformations and rotations, specifically those skills that engineers use to reason about 3D objects based on 2D representations. The software uses an intuitive and interactive interface allowing direct manipulation of objects. Animation capability is provided to demonstrate the relationship between arbitrary positions of an object and standard orthographic views. A second skill of interest requires visualization of a cutting-plane intersection of an object. An interface is developed which allows intuitive positioning of the cutting-plane utilizing the metaphor of a “pool of water” in which the object is partially submerged. The surface of the water represents the cutting plane. Adjustment of the pool depth combined with direct manipulation of the object provides for arbitrary positioning of the cutting-plane. Subjective evaluation of the software thus far indicates that students enjoy using it and find it helpful. A formal testing plan to objectively evaluate the software and interface design is underway.",James R. Osborn;Alice M. Agogino,
CHI,1992,Value bars: an information visualization and navigation tool for multi-attribute listings,10.1145/142750.142817,"INTRODUCTION The need for better information visualization and navigation tools is widely recognized [1], [5]. It is difficult to sort and continuously resort tables or listings by more than one attribute and still maintain an understanding of the origin and natural position of items. The concept of “value bars” was created to help users visualize and navigate large information spaces that have characteristics of a lineoriented listing with multiple, quantifiable attributes. In general, value bars are useful for analyzing multi-attxibute listings and tables where a particular sort order should be maintained and analysis of the top percentage of items within each attribute is beneficial, The main features are: “ the ability to see in one view an attribute distribution overview for the “important” items (as defined by attribute values) in a fisheye view [3] variant, ● very small screenspace footprint, ● the ability to see at once many attribute overviews, ● the ability to locate outliers and exceptions, and ● extremely low cognitive load navigation. This work was spawned from the study of a novel way to visualize large tree data structures, called Tree-maps [4]. A more detailed description, discussion, future value bars research, and results of a usability study can be found in [2].",Richard Chimera,
CHI,1992,TreeViz: treemap visualization of hierarchically structured information,10.1145/142750.142833,"Scientific visualization has received a great deal of attention in recent years. There are many reasons for this but chief among them is the simple observation that humans have difficulty extracting meaningful information from large volumes of data. Our increasing ability to produce, disseminate, and collect information has quite naturally led to a demand for tools which aid in the analysis of this information and support our intuition.",Brian Johnson,
CHI,1992,Multimedia help: a prototype and an experiment,10.1145/142750.142889,"On-line help systems have not paralleled recent advances in user interface technology. In particular, traditional textual help does not support visualization of the interaction processes needed to complete tasks, especially in graphical interfaces. In this demonstration, we present an experimental prototype which is capable of presenting help information in text, audio, static graphics, video, and context-sensitive animation. The prototype is used in a study on how multimedia technology enhances user performance.",Piyawadee Noi Sukaviriya;Ellen Isaacs;Krishna Bharat,
CHI,1992,The MidasPlus molecular modeling system,10.1145/142750.142915,"MidasPlus [6, 7] is an interactive molecular modeling system used to depict three dimensional macromolecular structures such as proteins and nucleic acids, to study how these structures spatially and chemically interact, and to study how small molecules such as drugs bind with these macromolecules, Effective interaction with macromolecular structures presents several challenges: the molecules consist of thousands to tens of thousands of atoms and the scientist user is easily overwhelmed by the sheer volume of data if the displayed information is not limitied and presented in a rational manner. The intellectual process of understanding the structure and function of molecules is linked to visualizing the complex spatial relationships within these structures, and since the user ia only presented images of models, this intellectual process must proceed without being able to physically handle and make experimental “hand driven” modifications of a physical model. Finally, macromolecules are often globular in shape, of course bear no resemblance to macroscopic physical objects in the real world, and hence make it inherently difficult for the human visual system to accurately perceive the complex spatial relationships that are ao crucial to chemical activity.",Thomas E. Ferrin;Conrad C. Huang;Gregory S. Couch;Eric F. Pettersen;Robert Langridge,
CHI,1992,Dynamic Queries for Information Exploration: An Implementation and Evaluation,10.1145/142750.143054,"We designed, implemented and evaluated a new concept for direct manipulation of databases, called dynamic queries, that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster using a dynamic queries interface compared to two interfaces both providing form fill-in as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to explore the periodic table of elements and search on their properties.",Christopher Ahlberg;Christopher Williamson;Ben Shneiderman,
CHI,1992,An Introduction to Zeus: Audiovisualization of Some Elementary Sequential and Parallel Sorting Algorithms,10.1145/142750.143075,"Systems for algorithm animation provide facilities for users to view and interact with an animation of an algorithm, and for programmers to develop such animations. For a user, there are ways to control the data given to an algorithm, the ensemble of active views, and the execution of the algorithm. For a programmer, producing an animation of an algorithm becomes almost as easy as producing a textual trace of it.",Marc H. Brown,
CHI,1992,Pointing and Visualization,10.1145/142750.143078,"The nature of visualizations and the social uses to which they are put rely heavily on pointing behavior. In the context of a switched telephone network visualization, this tape illustrates novel task-specific pointing facilities.",William C. Hill;James D. Hollan,
CHI,1991,The perspective wall: detail and context smoothly integrated,10.1145/108844.108870,"Tasks that involve large information spaces overwhelm workspaces that do not support efiicient use of space and time. For example, case studies indicate that information often contains linear components, which can result in 2D layouts with wide, inefficient aspect ratios. This paper describes a technique called the Perspective W’aU for visualizing linear information by smoothly integrating detailed and contextual views. It uses hardware support for 3D interactive animation to fold wide 2D layouts into intuitive 3D visualizations that have a center panel for detail and two perspective panels for context. The resulting visualization supports efficient use of space and time.",Jock D. Mackinlay;George G. Robertson;Stuart K. Card,
CHI,1991,"The information visualizer, an information workspace",10.1145/108844.108874,"This paper proposes a concept for the user interface of information retrieval systems called an information workspace. The concept goes beyond the usual notion of an information retrieval system to encompass the cost structure of information from secondary storage to immediate use. As an implementation of the concept, the paper describes an experimental system, called the Information Visualizer, and its rationale. The system is based on (1) the use of 3D/Rooms for increasing the capacity of immediate storage avaitable to the user, (2) the Cognitive Co-processor scheduler-based user interface interaction architecture for coupling the user to information agents, and (3) the use of information visualization for interacting with information structure.",Stuart K. Card;George G. Robertson;Jock D. Mackinlay,
CHI,1991,Cone Trees: animated 3D visualizations of hierarchical information,10.1145/108844.108883,"The task of managing and accessing large information spaces is a problem in large scale cognition. Enwrging technologies for 3D visualization and interactive aninlaiion offer potential solutions to this problenl, especially when the structure of the information can be visualized. We describe one of these Information Visualtzaiion techniques, called the Cone Tree, which is used for visualizing hierarchical information structures. The hierarchy is presented in 3D to nlaxilnize effective use of available screen space and enable visualization of the whole structure. Interactive aninlation is used (,o shift sonle of the user’s cognitive load to the human perceptual system,",George G. Robertson;Jock D. Mackinlay;Stuart K. Card,
CHI,1991,IMPACT: an interactive natural-motion-picture dedicated multimedia authoring system,10.1145/108844.108939,"A new approach to achieving a natural-motion-picture dedicated multi-media authoring system is proposed. The main point of this approach, discussed in this paper, is that the user’s environment or interface is improved to encourage user’s creativity, with image processing and recognition technology. According to the discussion, a prototype motion picture authoring system dtat has several image-processing functions is developed. The newly developed functions include object extraction of the picture, semi-automatic visualization of motion pictures structure, and certain descriptions of the scene. Result of using the prototype shows the appropriateness of the proposed approach.",Hirotada Ueda;Takafumi Miyatake;Satoshi Yoshizawa,
CHI,1991,Information visualization using 3D interactive animation,10.1145/108844.109003,"INTRODUCTION Information Visualization uses computer graphics and interactive animation to stimulate recognition of patterns and structure in information. It does so by exploiting the human perceptual system in ways similar to Scientific Visualization, which allows scientists to perceive patterns in large data collections. While Scientific Visualization typically works on data from simulations of physical processes, Information Visualization works on the structure of information inherent in large information spaces. This video shows a prototype system, called the Information Visualizer, and two information visualization techniques used to access information both by structure and by content. Cone Trees are used for visualizing hierarchical information structures. The Perspective Wall is used for visualizing linear information structures. Both techniques use 3D to maximize effective use of available screen space and enable visualization of the whole structure. Interactive animation is used to shift some of the user’s cognitive load to the human perceptual system. The video concludes with a series of examples from an application scenario, based on managing an organization.",George G. Robertson;Jock D. Mackinlay;Stuart K. Card,
CHI,1991,The University of Toronto dynamic graphics project,10.1145/108844.109006,"The University of Toronto’s Dynamic Graphics Project is an interdisciplinary research laboratory within the Computer Science Department and the Computer Systems Research Institute. The labs mission is advanced research and graduate instruction; its theme is the enhancement of human creativity through advances in human-computer interaction, user interface design, and interactive computer graphics (Baecker, 1987). Our research spans input and interaction devices and techniques, user interface management systems, computersupported cooperative work, cognitive modelling, software engineering, computer program visualization, computer animation, multi-media, graphics modelling, and graphics rendering.",Ronald Baecker;Marilyn M. Mantei;William Buxton;Eugene Fiume,
CHI,1990,Stereophonic and surface sound generation for exploratory data analysis,10.1145/97243.97264,"The analysis and interpretation of very high dimensional data require the development and use of data presentation techniques that harness human perceptual powers. The University of Lowell's Exploratory Visualization project (Exvis) aims at designing, implementing, and evaluating perceptually-based tools for data presentation using both visual and auditory domains. This paper describes several auditory data presentation techniques, including the generation of stereophonic sound with apparent depth and sound that appears to emanate from a two-dimensional area. Both approaches can produce sound with auditory texture.",Stuart Smith;R. Daniel Bergeron;Georges G. Grinstein,
CHI,1990,Business instrument panel: a new paradigm for interfacing with financial data,10.1145/97243.97269,"The business instrument panel uses visualization to present, in a comprehensive and integrated manner, all the important elements found in traditional financial statements. By means of analog representation in a simple computer generated picture, the business instrument panel replaces the four traditional financial statements (balance sheet, income statement, cash flow statement, and retained earnings statement). The business instrument panel also embodies a new paradigm for understanding the business world and empowers the user with an unparalleled quick understanding of any firm.",C. Torben Thomsen,
CHI,1990,Track - a trace construction kit,10.1145/97243.97318,TRACK is a kit to interactively construct environments that trace the execution of methods and the flow of messages between SMALLTALK-80 objects. It enables the user to set up traces by means of direct manipulation. This is done by placing obstacles between icons representing specific classes and instances much in the way a jumping course is set up. TRACK may be used to generate multiple visualizations of programs which may be concurrently run. It is a browsing and debugging tool as well as an algorithm animation tool. TRACK is tightly integrated with the standard tools of the SMALL- TALK-80 programming environment.,Heinz-Dieter Böcker;Jürgen Herczeg,
CHI,1989,Constraint grammars-a new model for specifying graphical applications,10.1145/67449.67513,"User Interface Management Systems often attempt to separate the graphical and nongraphical aspects of an application, but rarely succeed. Constraint grammars provide a new model for specifying interfaces that achieves this goal by encapsulating the data structures in a single package, and providing a powerful transformation-based editing model for manipulating them. Constraint grammars incorporate a number of important tools, such as the part-whole hierarchy, almost hierarchical structures, and multidirectional constraints, that permit designers to specify a wide variety of graphical applications, including simulation systems, program visualization systems, and visual programming environments.",Bradley T. Vander Zanden,
CHI,1988,Grasping reality through illusion - interactive graphics serving science,10.1145/57167.57168,"I treat three related subjects: virtual-worlds research—the construction of real-time 3-D illusions by computer graphics; some observations about interfaces to virtual worlds; and the coming application of virtual-worlds techniques to the enhancement of scientific computing.
We need to design generalized interfaces for visualizing, exploring, and steering scientific computations. Our interfaces must be direct-manipulation, not command-string; interactive, not batch; 3-D, not 2-D; multisensory, not just visual.
We need generalized research results for 3-D interactive interfaces. More is known than gets reported, because of a reluctance to share “unproven” results. I propose a shells-of-certainty model for such knowledge.",Frederick P. Brooks Jr.,
CHI,1986,Design principles for the enhanced presentation of computer program source text,10.1145/22627.22348,"In order to make computer programs more readable, understandable, appealing, memorable, and maintainable, the presentation of program source text needs to be enhanced over its conventional treatment. Towards this end, we present five basic design principles for enhanced program visualization and a framework for applying these principles to particular programming languages. The framework deals comprehensively with ten fundamental areas that are central to the structure of programming languages. We then use the principles and the framework to develop a novel design for the effective presentation of source text in the C programming language.",Ronald Baecker;Aaron Marcus,
CHI,1986,"Visual programming, programming by example, and program visualization: a taxonomy",10.1145/22627.22349,"There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.",Brad A. Myers,
CHI,2024,How Do Low-Vision Individuals Experience Information Visualization?,10.1145/3613904.3642188,"In recent years, there has been a growing interest in enhancing the accessibility of visualizations for people with visual impairments. While much of the research has focused on improving accessibility for screen reader users, the specific needs of people with remaining vision (i.e., low-vision individuals) have been largely unaddressed. To bridge this gap, we conducted a qualitative study that provides insights into how low-vision individuals experience visualizations. We found that participants utilized various strategies to examine visualizations using the screen magnifiers and also observed that the default zoom level participants use for general purposes may not be optimal for reading visualizations. We identified that participants relied on their prior knowledge and memory to minimize the traversing cost when examining visualization. Based on the findings, we motivate a personalized tool to accommodate varying visual conditions of low-vision individuals and derive the design goals and features of the tool.",Yanan Wang;Yuhang Zhao 0001;Yea-Seul Kim,
CHI,2024,WAVE: Anticipatory Movement Visualization for VR Dancing,10.1145/3613904.3642145,"Dance games are one of the most popular game genres in Virtual Reality (VR), and active dance communities have emerged on social VR platforms such as VR Chat. However, effective instruction of dancing in VR or through other computerized means remains an unsolved human-computer interaction problem. Existing approaches either only instruct movements partially, abstracting away nuances, or require learning and memorizing symbolic notation. In contrast, we investigate how realistic, full-body movements designed by a professional choreographer can be instructed on the fly, without prior learning or memorization. Towards this end, we describe the design and evaluation of WAVE, a novel anticipatory movement visualization technique where the user joins a group of dancers performing the choreography with different time offsets, similar to spectators making waves in sports events. In our user study (N=36), the participants more accurately followed a choreography using WAVE, compared to following a single model dancer.",Markus Laattala;Roosa Piitulainen;Nadia M. Ady;Monica Tamariz;Perttu Hämäläinen,
CHI,2024,CollageVis: Rapid Previsualization Tool for Indie Filmmaking using Video Collages,10.1145/3613904.3642575,"Previsualization, previs, is essential for film production, allowing cinematographic experiments and effective collaboration. However, traditional previs methods like 2D storyboarding and 3D animation require substantial time, cost, and technical expertise, posing challenges for indie filmmakers. We introduce CollageVis, a rapid previsualization tool using video collages. CollageVis enables filmmakers to create previs through two main user interfaces. First, it automatically segments actors from videos and assigns roles using name tags, color filters, and face swaps. Second, it positions video layers on a virtual stage and allows users to record shots using mobile as a proxy for a virtual camera. These features were developed based on formative interviews by reflecting indie filmmakers' needs and working methods. We demonstrate the system's capability by replicating seven film scenes and evaluate the system's usability with six indie filmmakers. The findings indicate that CollageVis allows more flexible yet expressive previs creation for idea development and collaboration.",Hye-Young Jo;Ryo Suzuki 0001;Yoonji Kim,
CHI,2024,Do You See What I See? A Qualitative Study Eliciting High-Level Visualization Comprehension,10.1145/3613904.3642813,"Designers often create visualizations to achieve specific high-level analytical or communication goals. These goals require people to naturally extract complex, contextualized, and interconnected patterns in data. While limited prior work has studied general high-level interpretation, prevailing perceptual studies of visualization effectiveness primarily focus on isolated, predefined, low-level tasks, such as estimating statistical quantities. This study more holistically explores visualization interpretation to examine the alignment between designers' communicative goals and what their audience sees in a visualization, which we refer to as their comprehension. We found that statistics people effectively estimate from visualizations in classical graphical perception studies may differ from the patterns people intuitively comprehend in a visualization. We conducted a qualitative study on three types of visualizations—line graphs, bar graphs, and scatterplots—to investigate the high-level patterns people naturally draw from a visualization. Participants described a series of graphs using natural language and think-aloud protocols. We found that comprehension varies with a range of factors, including graph complexity and data distribution. Specifically, 1) a visualization's stated objective often does not align with people's comprehension, 2) results from traditional experiments may not predict the knowledge people build with a graph, and 3) chart type alone is insufficient to predict the information people extract from a graph. Our study confirms the importance of defining visualization effectiveness from multiple perspectives to assess and inform visualization practices.",Ghulam Jilani Quadri;Arran Zeyu Wang;Zhehao Wang;Jennifer Adorno Nieves;Paul Rosen 0001;Danielle Albers Szafir,
CHI,2024,RASSAR: Room Accessibility and Safety Scanning in Augmented Reality,10.1145/3613904.3642140,"The safety and accessibility of our homes is critical to quality of life and evolves as we age, become ill, host guests, or experience life events such as having children. Researchers and health professionals have created assessment instruments such as checklists that enable homeowners and trained experts to identify and mitigate safety and access issues. With advances in computer vision, augmented reality (AR), and mobile sensors, new approaches are now possible. We introduce RASSAR, a mobile AR application for semi-automatically identifying, localizing, and visualizing indoor accessibility and safety issues such as an inaccessible table height or unsafe loose rugs using LiDAR and real-time computer vision. We present findings from three studies: a formative study with 18 participants across five stakeholder groups to inform the design of RASSAR, a technical performance evaluation across ten homes demonstrating state-of-the-art performance, and a user study with six stakeholders. We close with a discussion of future AI-based indoor accessibility assessment tools, RASSAR's extensibility, and key application scenarios.",Xia Su;Han Zhang;Kaiming Cheng;Jaewook Lee 0005;Qiaochu Liu;Wyatt Olson;Jon E. Froehlich,
CHI,2024,Glanceable Data Visualizations for Older Adults: Establishing Thresholds and Examining Disparities Between Age Groups,10.1145/3613904.3642776,"We present results of a replication study on smartwatch visualizations with adults aged 65 and older. The older adult population is rising globally, coinciding with their increasing interest in using small wearable devices, such as smartwatches, to track and view data. Smartwatches, however, pose challenges to this population: fonts and visualizations are often small and meant to be seen at a glance. How concise design on smartwatches interacts with aging-related changes in perception and cognition, however, is not well understood. We replicate a study that investigated how visualization type and number of data points affect glanceable perception. We observe strong evidence of differences for participants aged 75 and older, sparking interesting questions regarding the study of visualization and older adults. We discuss first steps toward better understanding and supporting an older population of smartwatch wearers and reflect on our experiences working with this population. Supplementary materials are available at https://osf.io/7x4hq/.",Zack While;Tanja Blascheck;Yujie Gong;Petra Isenberg;Ali Sarvghad,HM
CHI,2024,Cieran: Designing Sequential Colormaps via In-Situ Active Preference Learning,10.1145/3613904.3642903,"Quality colormaps can help communicate important data patterns. However, finding an aesthetically pleasing colormap that looks ""just right"" for a given scenario requires significant design and technical expertise. We introduce Cieran, a tool that allows any data analyst to rapidly find quality colormaps while designing charts within Jupyter Notebooks. Our system employs an active preference learning paradigm to rank expert-designed colormaps and create new ones from pairwise comparisons, allowing analysts who are novices in color design to tailor colormaps to their data context. We accomplish this by treating colormap design as a path planning problem through the CIELAB colorspace with a context-specific reward model. In an evaluation with twelve scientists, we found that Cieran effectively modeled user preferences to rank colormaps and leveraged this model to create new quality designs. Our work shows the potential of active preference learning for supporting efficient visualization design optimization.",Matt-Heun Hong;Zachary Nolan Sunberg;Danielle Albers Szafir,
CHI,2024,When the Body Became Data: Historical Data Cultures and Anatomical Illustration,10.1145/3613904.3642056,"With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past.",Michael Correll;Laura A. Garrison,
CHI,2024,DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing,10.1145/3613904.3642639,"Users often rely on GUIs to edit and interact with visualizations — a daunting task due to the large space of editing options. As a result, users are either overwhelmed by a complex UI or constrained by a custom UI with a tailored, fixed subset of options with limited editing flexibility. Natural Language Interfaces (NLIs) are emerging as a feasible alternative for users to specify edits. However, NLIs forgo the advantages of traditional GUI: the ability to explore and repeat edits and see instant visual feedback. We introduce DynaVis, which blends natural language and dynamically synthesized UI widgets. As the user describes an editing task in natural language, DynaVis performs the edit and synthesizes a persistent widget that the user can interact with to make further modifications. Study participants (n=24) preferred DynaVis over the NLI-only interface citing ease of further edits and editing confidence due to immediate visual feedback.",Priyan Vaithilingam;Elena L. Glassman;Jeevana Priya Inala;Chenglong Wang,BP
CHI,2024,PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement,10.1145/3613904.3642803,"The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model's interpretation and the user's intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user's initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model's attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user's expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.",Zhijie Wang;Yuheng Huang;Da Song;Lei Ma 0003;Tianyi Zhang 0001,
CHI,2024,CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars,10.1145/3613904.3642105,"Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced immersion. Our findings support research on iterative creative processes and the growing potential of personalizable generative AI creativity support tools. We present design implications for leveraging chatbot avatars in the creative writing process.",Hua Xuan Qin;Shan Jin;Ze Gao;Mingming Fan 0001;Pan Hui 0001,
CHI,2024,The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization,10.1145/3613904.3641895,"The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer's interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.",Md. Naimul Hoque;Tasfia Mashiat;Bhavya Ghai;Cecilia D. Shelton;Fanny Chevalier;Kari Kraus;Niklas Elmqvist,
CHI,2024,Damage Optimization in Video Games: A Player-Driven Co-Creative Approach,10.1145/3613904.3642643,"The concept of dealing damage is established and widespread in video games. With growing complexity and countless interactions in modern games, capturing how damage unfolds becomes an intricate problem - for developers just as for players. Misunderstanding how to optimize damage potentials includes risks of game imbalances, game-breaking exploits, mismatches between player skill and challenge (harming flow), and impaired perceived competence. All of these considerably impact player experience, game reception, success, and retention, yet polishing optimal strategies remains often a player community effort. To accelerate, inform and ease this process, we implemented an interactive tool capable of simulating, visualizing, planning and comparing damage strategies in video games. Following a case study within the Guild Wars 2 community, we contribute a player-driven perspective on the problem of damage optimization, as well as an artifact that resulted in empirical improvements – advancing the fields of game analytics, game evaluation methods and self-regulated learning.",Johannes Pfau;Manik Charan;Erica Kleinman;Magy Seif El-Nasr,
CHI,2024,Odds and Insights: Decision Quality in Exploratory Data Analysis Under Uncertainty,10.1145/3613904.3641995,"Recent studies have shown that users of visual analytics tools can have difficulty distinguishing robust findings in the data from statistical noise, but the true extent of this problem is likely dependent on both the incentive structure motivating their decisions, and the ways that uncertainty and variability are (or are not) represented in visualisations. In this work, we perform a crowd-sourced study measuring decision-making quality in visual analytics, testing both an explicit structure of incentives designed to reward cautious decision-making as well as a variety of designs for communicating uncertainty. We find that, while participants are unable to perfectly control for false discoveries as well as idealised statistical models such as the Benjamini-Hochberg, certain forms of uncertainty visualisations can improve the quality of participants' decisions and lead to fewer false discoveries than not correcting for multiple comparisons. We conclude with a call for researchers to further explore visual analytics decision quality under different decision-making contexts, and for designers to directly present uncertainty and reliability information to users of visual analytics tools. The supplementary materials are available at: https://osf.io/xtsfz/.",Abhraneel Sarma;Xiaoying Pu;Yuan Cui;Michael Correll;Eli T. Brown;Matthew Kay 0001,HM
CHI,2024,Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments,10.1145/3613904.3642049,"Situated visualization blends data into the real world to fulfill individuals' contextual information needs. However, interacting with situated visualization in public environments faces challenges posed by users' acceptance and contextual constraints. To explore appropriate interaction design, we first conduct a formative study to identify users' needs for data and interaction. Informed by the findings, we summarize appropriate interaction modalities with eye-based, hand-based and spatially-aware object interaction for situated visualization in public environments. Then, through an iterative design process with six users, we explore and implement interactive techniques for activating and analyzing with situated visualization. To assess the effectiveness and acceptance of these interactions, we integrate them into an AR prototype and conduct a within-subjects study in public scenarios using conventional hand-only interactions as the baseline. The results show that participants preferred our prototype over the baseline, attributing their preference to the interactions being more acceptable, flexible, and practical in public.",Qian Zhu 0010;Zhuo Wang;Wei Zeng 0004;Wai Tong;Weiyue Lin;Xiaojuan Ma,
CHI,2024,Input Visualization: Collecting and Modifying Data with Visual Representations,10.1145/3613904.3642808,"We examine input visualizations, visual representations that are designed to collect (and represent) new data rather than encode preexisting datasets. Information visualization is commonly used to reveal insights and stories within existing data. As a result, most contemporary visualization approaches assume existing datasets as the starting point for design, through which that data is mapped to visual encodings. Meanwhile, the implications of visualizations as inputs and as data sources have received little attention—despite the existence of visual and physical examples stretching back centuries. In this paper, we present a design space of 50 input visualizations analyzing their visual representation, data, artifact, context, and input. Based on this, we identify input modalities, purposes of input visualizations, and a set of design considerations. Finally, we discuss the relationship between input visualization and traditional visualization design and suggest opportunities for future research to better understand these visual representations and their potential.",Nathalie Bressa;Jordan Louis;Wesley Willett;Samuel Huron,
CHI,2024,Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics,10.1145/3613904.3641957,"We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools.",Priya Dhawka;Lauren Perera;Wesley Willett,
CHI,2024,That's Rough! Encoding Data into Roughness for Physicalization,10.1145/3613904.3641900,"While visual channels (e.g., color, shape, size) have been explored for visualizing data in data physicalizations, there is a lack of understanding regarding how to encode data into physical material properties (e.g., roughness, hardness). This understanding is critical for ensuring data is correctly communicated and for potentially extending the channels and bandwidth available for encoding that data. We present a method to encode ordinal data into roughness, validated through user studies. In the first study, we identified just noticeable differences in perceived roughness from this method. In the second study, we 3D-printed proof of concepts for five different multivariate physicalizations using the model. These physicalizations were qualitatively explored (N=10) to understand people's comprehension and impressions of the roughness channel. Our findings suggest roughness may be used for certain types of data encoding, and the context of the data can impact how people interpret roughness mapping direction.",Xiaojiao Du;Kadek Ananta Satriadi;Adam Drogemuller;Brandon J. Matthews;Ross Smith 0001;James A. Walsh;Andrew Cunningham,HM
CHI,2024,VisTorch: Interacting with Situated Visualizations using Handheld Projectors,10.1145/3613904.3642857,"Spatial data is best analyzed in situ, but existing mixed reality technologies can be bulky, expensive, or unsuitable for collaboration. We present VisTorch: a handheld device for projected situated analytics consisting of a pico-projector, a multi-spectrum camera, and a touch surface. VisTorch enables viewing charts situated in physical space by simply pointing the device at a surface to reveal visualizations in that location. We evaluated the approach using both a user study and an expert review. In the former, we asked 20 participants to first organize charts in space and then refer to these charts to answer questions. We observed three spatial and one temporal pattern in participant analyses. In the latter, four experts—a museum designer, a statistical software developer, a theater stage designer, and an environmental educator—utilized VisTorch to derive practical usage scenarios. Results from our study showcase the utility of situated visualizations for memory and recall.",Biswaksen Patnaik;Huaishu Peng;Niklas Elmqvist,
CHI,2024,Reading Between the Pixels: Investigating the Barriers to Visualization Literacy,10.1145/3613904.3642760,"In our current visual-centric digital age, the capability to interpret, understand, and produce visual representations of data —termed visualization literacy— is paramount. However, not everyone is adept at navigating this visual terrain. This paper explores the barriers that individuals who misread a visualization encounter, aiming to understand their specific mental gaps. Utilizing a mixed-method approach, we administered the Visualization Literacy Assessment Test (VLAT) to a group of 120 participants drawn from diverse demographic backgrounds, which provided us with 1774 task completions. We augmented the standard VLAT test to capture quantitative and qualitative data on participants' errors. We collected participant sketches and open-ended text about their analysis approach, providing insight into users' mental models and rationale. Our findings reveal that individuals who incorrectly answer visualization literacy questions often misread visual channels, confound chart labels with data values, or struggle to translate data-driven questions into visual queries. Recognizing and bridging visualization literacy gaps not only ensures inclusivity but also enhances the overall effectiveness of visual communication in our society.",Carolina Nobre;Kehang Zhu;Eric Mörth;Hanspeter Pfister;Johanna Beyer,
CHI,2024,Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality,10.1145/3613904.3642740,"Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.",Shuqi He;Haonan Yao;Luyan Jiang;Kaiwen Li;Nan Xiang;Yue Li 0023;Hai-Ning Liang;Lingyun Yu 0001,
CHI,2024,"""Customization is Key"": Reconfigurable Textual Tokens for Accessible Data Visualizations",10.1145/3613904.3641970,"Customization is crucial for making visualizations accessible to blind and low-vision (BLV) people with widely-varying needs. But what makes for usable or useful customization? We identify four design goals for how BLV people should be able to customize screen-reader-accessible visualizations: presence, or what content is included; verbosity, or how concisely content is presented; ordering, or how content is sequenced; and, duration, or how long customizations are active. To meet these goals, we model a customization as a sequence of content tokens, each with a set of adjustable properties. We instantiate our model by extending Olli, an open-source accessible visualization toolkit, with a settings menu and command box for persistent and ephemeral customization respectively. Through a study with 13 BLV participants, we find that customization increases the ease of identifying and remembering information. However, customization also introduces additional complexity, making it more helpful for users familiar with similar tools.",Shuli Jones;Isabella Pedraza Pineros;Daniel Hajas;Jonathan Zong;Arvind Satyanarayan,
CHI,2024,Data Storytelling in Data Visualisation: Does it Enhance the Efficiency and Effectiveness of Information Retrieval and Insights Comprehension?,10.1145/3613904.3643022,"Data storytelling (DS) is rapidly gaining attention as an approach that integrates data, visuals, and narratives to create data stories that can help a particular audience to comprehend the key messages underscored by the data with enhanced efficiency and effectiveness. It is been posited that DS can be especially advantageous for audiences with limited visualisation literacy, by presenting the data clearly and concisely. However, empirical studies confirming whether data stories indeed provide these benefits over conventional data visualisations are scarce. To bridge this gap, we conducted a study with 103 participants to determine whether DS indeed improve both efficiency and effectiveness in tasks related to information retrieval and insights comprehension. Our findings suggest that data stories do improve the efficiency of comprehension tasks, as well as the effectiveness of comprehension tasks that involve a single insight, compared with conventional visualisations. Interestingly, these benefits were not associated with participants' visualisation literacy.",Hongbo Shao;Roberto Martínez-Maldonado;Vanessa Echeverría;Lixiang Yan;Dragan Gasevic,
CHI,2024,Taking ASCII Drawings Seriously: How Programmers Diagram Code,10.1145/3613904.3642683,"Documentation in codebases facilitates knowledge transfer. But tools for programming are largely text-based, and so developers resort to creating ASCII diagrams—graphical artifacts approximated with text—to show visual ideas within their code. Despite real-world use, little is known about these diagrams. We interviewed nine authors of ASCII diagrams, learning why they use ASCII and what roles the diagrams play. We also compile and analyze a corpus of 507 ASCII diagrams from four open source projects, deriving a design space with seven dimensions that classify what these diagrams show, how they show it, and ways they connect to code. These investigations reveal that ASCII diagrams are professional artifacts used across many steps in the development lifecycle, diverse in role and content, and used because they visualize ideas within the variety of programming tools in use. Our findings highlight the importance of visualization within code and lay a foundation for future programming tools that tightly couple text and graphics.",Devamardeep Hayatpur;Brian Hempel;Kathy Chen;William Duan;Philip J. Guo;Haijun Xia,HM
CHI,2024,PhotoScout: Synthesis-Powered Multi-Modal Image Search,10.1145/3613904.3642319,"Due to the availability of increasingly large amounts of visual data, there is a growing need for tools that can help users find relevant images. While existing tools can perform image retrieval based on similarity or metadata, they fall short in scenarios that necessitate semantic reasoning about the content of the image. This paper explores a new multi-modal image search approach that allows users to conveniently specify and perform semantic image search tasks. With our tool, PhotoScout, the user interactively provides natural language descriptions, positive and negative examples, and object tags to specify their search tasks. Under the hood, PhotoScout is powered by a program synthesis engine that generates visual queries in a domain-specific language and executes the synthesized program to retrieve the desired images. In a study with 25 participants, we observed that PhotoScout allows users to perform image retrieval tasks more accurately and with less manual effort.",Celeste Barnaby;Qiaochu Chen;Chenglong Wang;Isil Dillig,
CHI,2024,SalienTime: User-driven Selection of Salient Time Steps for Large-Scale Geospatial Data Visualization,10.1145/3613904.3642944,"The voluminous nature of geospatial temporal data from physical monitors and simulation models poses challenges to efficient data access, often resulting in cumbersome temporal selection experiences in web-based data portals. Thus, selecting a subset of time steps for prioritized visualization and pre-loading is highly desirable. Addressing this issue, this paper establishes a multifaceted definition of salient time steps via extensive need-finding studies with domain experts to understand their workflows. Building on this, we propose a novel approach that leverages autoencoders and dynamic programming to facilitate user-driven temporal selections. Structural features, statistical variations, and distance penalties are incorporated to make more flexible selections. User-specified priorities, spatial regions, and aggregations are used to combine different perspectives. We design and implement a web-based interface to enable efficient and context-aware selection of time steps and evaluate its efficacy and usability through case studies, quantitative evaluations, and expert interviews.",Juntong Chen;Haiwen Huang;Huayuan Ye;Zhong Peng;Chenhui Li;Changbo Wang,
CHI,2024,Evaluating Navigation and Comparison Performance of Computational Notebooks on Desktop and in Virtual Reality,10.1145/3613904.3642932,"The computational notebook serves as a versatile tool for data analysis. However, its conventional user interface falls short of keeping pace with the ever-growing data-related tasks, signaling the need for novel approaches. With the rapid development of interaction techniques and computing environments, there is a growing interest in integrating emerging technologies in data-driven workflows. Virtual reality, in particular, has demonstrated its potential in interactive data visualizations. In this work, we aimed to experiment with adapting computational notebooks into VR and verify the potential benefits VR can bring. We focus on the navigation and comparison aspects as they are primitive components in analysts' workflow. To further improve comparison, we have designed and implemented a Branching&Merging functionality. We tested computational notebooks on the desktop and in VR, both with and without the added Branching&Merging capability. We found VR significantly facilitated navigation compared to desktop, and the ability to create branches enhanced comparison.",Sungwon In;Eric Krokos;Kirsten Whitley;Chris North 0001;Yalong Yang 0001,
CHI,2024,"""Is Text-Based Music Search Enough to Satisfy Your Needs?"" A New Way to Discover Music with Images",10.1145/3613904.3642126,"Music is intrinsically connected to human experience, yet the plethora of choices often renders the search for the ideal piece perplexing, especially when the search terms are ambiguous. This study questions the viability of employing visual data, specifically images, in innovative queries for music search, and it aims to better align search results with users' moods and situational context. We designed and evaluated three prototype systems for music search—TTTune (text-based), VisTune (image-based), and VTTune (hybrid)—to comparatively assess user experience and system usability. In a comprehensive user study involving 236 participants, each participant interacted with one of the systems and subsequently completed post-experimental surveys. A subset of participants also participated in in-depth interviews to further elucidate the potential and the advantages of image-based music retrieval (IMR) systems. Our findings reveal a marked preference for the user experience and usability offered by the IMR approach, as compared with the traditional text-based method. This underscores the potential of the image in an effective search query. Based on these findings, we discuss interface design guidelines tailored for IMR systems and factors affecting system performance, contributing to the evolving landscape of music search methods.",Jeongeun Park 0003;Hyorim Shin;Changhoon Oh;Ha Young Kim,
CHI,2024,"Understanding Reader Takeaways in Thematic Maps Under Varying Text, Detail, and Spatial Autocorrelation",10.1145/3613904.3642132,"Maps are crucial in conveying geospatial data in diverse contexts such as news and scientific reports. This research, utilizing thematic maps, probes deeper into the underexplored intersection of text framing and map types in influencing map interpretation. In this work, we conducted experiments to evaluate how textual detail and semantic content variations affect the quality of insights derived from map examination. We also explored the influence of explanatory annotations across different map types (e.g., choropleth, hexbin, isarithmic), base map details, and changing levels of spatial autocorrelation in the data. From two online experiments with N = 103 participants, we found that annotations, their specific attributes, and map type used to present the data significantly shape the quality of takeaways. Notably, we found that the effectiveness of annotations hinges on their contextual integration. These findings offer valuable guidance to the visualization community for crafting impactful thematic geospatial representations.",Arlen Fan;Fan Lei;Michelle Mancenido;Alan M. MacEachren;Ross Maciejewski,
CHI,2024,Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models,10.1145/3613904.3642943,"We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.",Hyung-Kwon Ko;Hyeon Jeon;Gwanmo Park;Dae Hyun Kim 0005;Nam Wook Kim;Juho Kim;Jinwook Seo,
CHI,2024,VAID: Indexing View Designs in Visual Analytics System,10.1145/3613904.3642237,"Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.",Lu Ying;Aoyu Wu;Haotian Li 0001;Zikun Deng;Ji Lan;Jiang Wu;Yong Wang 0021;Huamin Qu;Dazhen Deng;Yingcai Wu,
CHI,2024,DoodleTunes: Interactive Visual Analysis of Music-Inspired Children Doodles with Automated Feature Annotation,10.1145/3613904.3642346,"Music and visual arts are essential in children's arts education, and their integration has garnered significant attention. Existing data analysis methods for exploring audio-visual correlations are limited. Yet, relevant research is necessary for innovating and promoting arts integration courses. In our work, we collected substantial volumes of music-inspired doodles created by children and interviewed education experts to comprehend the challenges they encountered in the relevant analysis. Based on the insights we obtained, we designed and constructed an interactive visualization system DoodleTunes. DoodleTunes integrates deep learning-driven methods for automatically annotating several types of data features. The visual designs of the system are based on a four-level analysis structure to construct a progressive workflow, facilitating data exploration and insight discovery between doodle images and corresponding music pieces. We evaluated the accuracy of our feature prediction results and collected usage feedback on DoodleTunes from five domain experts.",Shuqi Liu;Jia Bu;Huayuan Ye;Juntong Chen;Shiqi Jiang;Mingtian Tao;Liping Guo;Changbo Wang;Chenhui Li,
CHI,2024,Doorways Do Not Always Cause Forgetting: Studying the Effect of Locomotion Technique and Doorway Visualization in Virtual Reality,10.1145/3613904.3642879,"The ""doorway effect"" predicts that crossing an environmental boundary affects memory negatively. In virtual reality (VR), we can design the crossing and the appearance of such boundaries in non-realistic ways. However, it is unclear whether locomotion techniques like teleportation, which avoid crossing the boundary altogether, still induce the effect. Furthermore, it is unclear how different appearances of a doorway act as a boundary and thus induce the effect. To address these questions, we conducted two lab studies. First, we conceptually replicated prior doorway effect studies in VR using natural walking and teleportation. Second, we investigated the effect of five doorway visualizations, ranging from doors to portals. The results show no difference in object recognition performance due to the presence of a doorway, locomotion technique, or doorway visualization. We discuss the implications of these findings on the role of boundaries in event-based memory and the design of boundary interactions in VR.",Thomas Van Gemert;Sean Chew;Yiannis Kalaitzoglou;Joanna Bergström,
CHI,2024,SolarClub: Supporting Renewable Energy Communities through an Interactive Coordination System,10.1145/3613904.3642449,"Energy communities are a key focus for governments around the world in support of more sustainable energy practices. However, interactive systems for supporting energy communities to coordinate around renewable energy resources are still lacking. We present SolarClub, a demand-shifting visualization system that supported households in coordinating their energy usage by booking energy-hungry activities when solar energy was available. We deployed SolarClub with four groups of neighbors (N=15) for a month. SolarClub successfully enabled neighbors to coordinate, even when some of those participating households were less flexible. While participants reported that SolarClub did not foster a feeling of community, it helped them empathize with their neighbors. Our findings demonstrate the potential of sensor- and visualization-based technology to help understand the relation between everyday practices and resources consumption, beyond individual eco-feedback. This work thus contributes to the development of a next generation of practices and technologies that support collective action for environmental sustainability.",Georgia Panagiotidou;Enrico Costanza;Kyrill Potapov;Sonia Nkatha;Michael J. Fell;Farhan Samanani;Hannah Knox,
CHI,2024,Co-designing Customizable Clinical Dashboards with Multidisciplinary Teams: Bridging the Gap in Chronic Disease Care,10.1145/3613904.3642618,"Providing care to individuals with chronic diseases benefits from a multidisciplinary approach and longitudinal symptom, event, and disease monitoring, in and out of clinical facilities. Technological advancements, including the ubiquitous presence of sensors and devices, present opportunities to collect large amounts of data and extract evidence-based insights about the patient and disease. Nevertheless, practical examples of clinical utility of those technologies remain sparse, and in specific focus areas (e.g, insights from a single device). This paper explores the challenges and opportunities of multidisciplinary clinical dashboards to support clinicians caring for people with chronic diseases. We report on a focus group and co-design workshops with a multidisciplinary team of clinicians and HCI researchers. We offer insights into how technological outcomes and visualizations can enhance clinical practice and the intricacies of information-sharing dynamics. We discuss the potential of dashboards to trigger actions in clinical settings and emphasize the benefits of customizable dashboards.",Diogo Branco;Margarida Móteiro;Raquel Bouça-Machado;Rita Miranda;Tiago Reis;Élia Decoroso;Rita Cardoso;Joana Ramalho;Filipa Rato;Joana Malheiro;Diana Miranda;Verónica Caniça;Filipa Pona-Ferreira;Daniela Guerreiro;Mariana Leitão;Alexandra Saúde Braz;Joaquim J. Ferreira;Tiago João Guerreiro,
CHI,2024,How Do Analysts Understand and Verify AI-Assisted Data Analyses?,10.1145/3613904.3642497,"Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst's intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts' programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.",Ken Gu;Ruoxi Shang;Tim Althoff;Chenglong Wang;Steven Mark Drucker,
CHI,2024,Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with Real-Time Unit Tests in Extended Reality,10.1145/3613904.3642158,"Advances in ubiquitous computing have enabled end-user authoring of context-aware policies (CAPs) that control smart devices based on specific contexts of the user and environment. However, authoring CAPs accurately and avoiding run-time errors is challenging for end-users as it is difficult to foresee CAP behaviors under complex real-world conditions. We propose Fast-Forward Reality, an Extended Reality (XR) based authoring workflow that enables end-users to iteratively author and refine CAPs by validating their behaviors via simulated unit test cases. We develop a computational approach to automatically generate test cases based on the authored CAP and the user's context history. Our system delivers each test case with immersive visualizations in XR, facilitating users to verify the CAP behavior and identify necessary refinements. We evaluated Fast-Forward Reality in a user study (N=12). Our authoring and validation process improved the accuracy of CAPs and the users provided positive feedback on the system usability.",Xun Qian;Tianyi Wang 0004;Xuhai Xu;Tanya R. Jonker;Kashyap Todi,
CHI,2024,Exploring Visualizations for Precisely Guiding Bare Hand Gestures in Virtual Reality,10.1145/3613904.3642935,"Bare hand interaction in augmented or virtual reality (AR/VR) systems, while intuitive, often results in errors and frustration. However, existing methods, such as a static icon or a dynamic tutorial, can only inform simple and coarse hand gestures and lack corrective feedback. This paper explores various visualizations for enhancing precise hand interaction in VR. Through a comprehensive two-part formative study with 11 participants, we identified four types of essential information for visual guidance and designed different visualizations that manifest these information types. We further distilled four visual designs and conducted a controlled lab study with 15 participants to assess their effectiveness for various single- and double-handed gestures. Our results demonstrate that visual guidance significantly improved users' gesture performance, reducing time and workload while increasing confidence. Moreover, we found that the visualization did not disrupt most users' immersive VR experience or their perceptions of hand tracking and gesture recognition reliability.",Xizi Wang;Ben Lafreniere;Jian Zhao 0010,
CHI,2024,Epigraphics: Message-Driven Infographics Authoring,10.1145/3613904.3642172,"The message a designer wants to convey plays a pivotal role in directing the design of an infographic, yet most authoring workflows start with creating the visualizations or graphics first without gauging whether they fit the message. To address this gap, we propose Epigraphics, a web-based authoring system that treats an ""epigraph"" as the first-class object, and uses it to guide infographic asset creation, editing, and syncing. The system uses the text-based message to recommend visualizations, graphics, data filters, color palettes, and animations. It further supports between-asset interactions and fine-tuning such as recoloring, highlighting, and animation syncing that enhance the aesthetic cohesiveness of the assets. A gallery and case studies show that our system can produce infographics inspired by existing popular ones, and a task-based usability study with 10 designers show that a text-sourced workflow can standardize content, empower users to think more about the big picture, and facilitate rapid prototyping.",Tongyu Zhou;Jeff Huang 0002;Gromit Yeuk-Yin Chan,HM
CHI,2024,Discovering Accessible Data Visualizations for People with ADHD,10.1145/3613904.3642112,"There have been many studies on understanding data visualizations regarding general users. However, we have a limited understanding of how people with ADHD comprehend data visualizations and how it might be different from the general users. To understand accessible data visualization for people with ADHD, we conducted a crowd-sourced survey involving 70 participants with ADHD and 77 participants without ADHD. Specifically, we tested the chart components of color, text amount, and use of visual embellishments/pictographs, finding that some of these components and ADHD affected participants' response times and accuracy. We outlined the neurological traits of ADHD and discussed specific findings on accessible data visualizations for people with ADHD. We found that various chart embellishment types affected accuracy and response times for those with ADHD differently depending on the types of questions. Based on these results, we suggest visual design recommendations to make accessible data visualizations for people with ADHD.",Tien Tran;Hae Na Lee;Ji Hwan Park,HM
CHI,2024,On the Benefits of Image-Schematic Metaphors when Designing Mixed Reality Systems,10.1145/3613904.3642925,"A Mixed Reality (MR) system encompasses various aspects, such as visualization and spatial registration of user interface elements, user interactions and interaction feedback. Image-schematic metaphors (ISMs) are universal knowledge structures shared by a wide range of users. They hold a theoretical promise of facilitating greater ease of learning and use for interactive systems without costly adaptations. This paper investigates whether image-schematic metaphors (ISMs) can improve user learning, by comparing an existing MR instruction authoring system with or without ISM enhancements. In a user study with 32 participants, we found that the ISM-enhanced system significantly improved task performance, learnability and mental efficiency compared to the baseline. Participants also rated the ISM-enhanced system significantly higher in terms of perspicuity, efficiency, and novelty. These results empirically demonstrate multiple benefits of ISMs when integrated into the design of this MR system and encourage further studies to explore the wider applicability of ISMs in user interface design.",Jingyi Li;Per Ola Kristensson,
CHI,2024,Comparison of Spatial Visualization Techniques for Radiation in Augmented Reality,10.1145/3613904.3642646,"Augmented Reality (AR) provides a safe and low-cost option for hazardous safety training that allows for the visualization of aspects that may be invisible, such as radiation. Effectively visually communicating such threats in the environment around the user is not straightforward. This work describes visually encoding radiation using the spatial awareness mesh of an AR Head Mounted Display. We leverage the AR device's GPUs to develop a real time solution that accumulates multiple dynamic sources and uses stencils to prevent an environment being over saturated with a visualization, as well as supporting the encoding of direction explicitly in the visualization. We perform a user study (25 participants) of different visualizations and obtain user feedback. Results show that there are complex interactions and while no visual representation was statistically superior or inferior, user opinions vary widely. We also discuss the evaluation approaches and provide recommendations.",Fintan McGee;Roderick McCall;Joan Baixauli,
CHI,2024,KnitScape: Computational Design and Yarn-Level Simulation of Slip and Tuck Colorwork Knitting Patterns,10.1145/3613904.3642799,"Slipped and tucked stitches introduce small areas of deformation that compound and result in emergent textures on knitted fabrics. When used together with color changes and ladders, these can also produce dramatic colorwork and openwork effects. However, designing slip and tuck colorwork patterns is challenging due to the complex interactions between operations, yarns, and deformations. We present KnitScape, a browser-based tool for design and simulation of stitch patterns for knitting. KnitScape provides a design interface to specify 1) operation repeats, 2) color changes, and 3) needle positions. These inputs are used to build a graph of yarn topology and run a yarn-level spring simulation. This enables visualization of the deformation that arises from slip and tuck operations. Through its design tool and simulation, KnitScape enables rapid exploration of a complex colorwork design space. We demonstrate KnitScape with a series of example swatches.",Hannah Twigg-Smith;Emily Whiting;Nadya Peek,
CHI,2024,Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference,10.1145/3613904.3642628,"On-device machine learning (ML) moves computation from the cloud to personal devices, protecting user privacy and enabling intelligent user experiences. However, fitting models on devices with limited resources presents a major technical challenge: practitioners need to optimize models and balance hardware metrics such as model size, latency, and power. To help practitioners create efficient ML models, we designed and developed Talaria : a model visualization and optimization system. Talaria enables practitioners to compile models to hardware, interactively visualize model statistics, and simulate optimizations to test the impact on inference metrics. Since its internal deployment two years ago, we have evaluated Talaria using three methodologies: (1) a log analysis highlighting its growth of 800+ practitioners submitting 3,600+ models; (2) a usability survey with 26 users assessing the utility of 20 Talaria features; and (3) a qualitative interview with the 7 most active users about their experience using Talaria.",Fred Hohman;Chaoqun Wang;Jinmook Lee;Jochen Görtler;Dominik Moritz;Jeffrey P. Bigham;Zhile Ren;Cecile Foret;Qi Shan;Xiaoyi Zhang 0006,HM
CHI,2024,A Human Information Processing Theory of the Interpretation of Visualizations: Demonstrating Its Utility,10.1145/3613904.3642276,"Providing an approach to model the memory structures that humans build as they use visualizations could be useful for researchers, designers and educators in the field of information visualization. Cheng and colleagues formulated Representation Interpretive Structure Theory (RIST) for that purpose. RIST adopts a human information processing perspective in order to address the immediate, short timescale, cognitive load likely to be experienced by visualization users. RIST is operationalized in a graphical modeling notation and browser-based editor. This paper demonstrates the utility of RIST by showing that (a): RIST models are compatible with established empirical and computational cognitive findings about differences in human performance on alternative representations; (b) they can encompass existing explanations from the literature; and, (c) they provide new explanations about causes of those performance differences.",Peter C.-H. Cheng;Grecia Garcia Garcia;Daniel Raggi;Mateja Jamnik,
CHI,2024,"(Re)activate, (Re)direct, (Re)arrange: Exploring the Design Space of Direct Interactions with Flavobacteria",10.1145/3613904.3642262,"HCI designers increasingly engage in the integration of microbes into artefacts, leveraging their distinct biological affordances for novel interactions. While in many explorations the interaction between humans and microbes is mediated, scholars also highlight the potential of direct interactions, such as visualising mechanical distortions or fostering a sense of relationality with nonhumans through eliciting intimate encounters. Seizing upon this potential, our study delves into the realm of direct interactions involving Flavobacteria, recently introduced as a colour-changing interactive medium in HCI. We present a design space for direct interactions where humans can (re)activate, (re)direct, and (re)arrange Flavobacteria's colourations, thereby fostering a personal and dynamic interplay between humans and microbes. With our work, we aspire to provide pathways and ignite inspiration among HCI designers to create living artefacts that cultivate active engagement and heightened attentiveness towards microbial worlds and beyond.",Clarice Risseeuw;Holly McQuillan;Joana Martins;Elvin Karana,HM
CHI,2024,Data Probes as Boundary Objects for Technology Policy Design: Demystifying Technology for Policymakers and Aligning Stakeholder Objectives in Rideshare Gig Work,10.1145/3613904.3642000,"Despite the evidence of harm that technology can inflict, commensurate policymaking to hold tech platforms accountable still lags. This is pertinent to app-based gig workers, where unregulated algorithms continue to dictate their work, often with little human recourse. While past HCI literature has investigated workers' experiences under algorithmic management and how to design interventions, rarely are the perspectives of stakeholders who inform or craft policy sought. To bridge this, we propose using data probes—interactive visualizations of workers' data that show the impact of technology practices on people—exploring them in 12 semi-structured interviews with policy informers, (driver-)organizers, litigators, and a lawmaker in the rideshare space. We show how data probes act as boundary objects to assist stakeholder interactions, demystify technology for policymakers, and support worker collective action. We discuss the potential for data probes as training tools for policymakers, and considerations around data access and worker risks when using data probes.",Angie Zhang;Rocita Rana;Alexander Boltz;Veena Dubal;Min Kyung Lee,
CHI,2024,Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment,10.1145/3613904.3642911,"Robots are embodied agents that act under several sources of uncertainty. When assisting humans in a collaborative task, robots need to communicate their uncertainty to help inform decisions. In this study, we examine the use of visualising a robot's uncertainty in a high-stakes assisted decision-making task. In particular, we explore how different modalities of uncertainty visualisations (graphical display vs. the robot's embodied behaviour) and confidence levels (low, high, 100%) conveyed by a robot affect the human decision-making and perception during a collaborative task. Our results show that these visualisations significantly impact how participants arrive to their decision as well as how they perceive the robot's transparency across the different confidence levels. We highlight potential trade-offs and offer implications for robot-assisted decision-making. Our work contributes empirical insights on how humans make use of uncertainty visualisations conveyed by a robot in a critical robot-assisted decision-making scenario.",Sarah Schömbs;Saumya Pareek;Jorge Goncalves;Wafa Johal,
CHI,2024,DeepSee: Multidimensional Visualizations of Seabed Ecosystems,10.1145/3613904.3642001,"Scientists studying deep ocean microbial ecosystems use limited numbers of sediment samples collected from the seafloor to characterize important life-sustaining biogeochemical cycles in the environment. Yet conducting fieldwork to sample these extreme remote environments is both expensive and time consuming, requiring tools that enable scientists to explore the sampling history of field sites and predict where taking new samples is likely to maximize scientific return. We conducted a collaborative, user-centered design study with a team of scientific researchers to develop DeepSee, an interactive data workspace that visualizes 2D and 3D interpolations of biogeochemical and microbial processes in context together with sediment sampling history overlaid on 2D seafloor maps. Based on a field deployment and qualitative interviews, we found that DeepSee increased the scientific return from limited sample sizes, catalyzed new research workflows, reduced long-term costs of sharing data, and supported teamwork and communication between team members with diverse research goals.",Adam Coscia;Haley M. Sapers;Noah Deutsch;Malika Khurana;John S. Magyar;Sergio A. Parra;Daniel R. Utter;Rebecca L. Wipfler;David W. Caress;Eric J. Martin;Jennifer B. Paduan;Maggie Hendrie;Santiago V. Lombeyda;Hillary Mushkin;Alex Endert;Scott Davidoff;Victoria J. Orphan,
CHI,2024,PD-Insighter: A Visual Analytics System to Monitor Daily Actions for Parkinson's Disease Treatment,10.1145/3613904.3642215,"People with Parkinson's Disease (PD) can slow the progression of their symptoms with physical therapy. However, clinicians lack insight into patients' motor function during daily life, preventing them from tailoring treatment protocols to patient needs. This paper introduces PD-Insighter, a system for comprehensive analysis of a person's daily movements for clinical review and decision-making. PD-Insighter provides an overview dashboard for discovering motor patterns and identifying critical deficits during activities of daily living and an immersive replay for closely studying the patient's body movements with environmental context. Developed using an iterative design study methodology in consultation with clinicians, we found that PD-Insighter's ability to aggregate and display data with respect to time, actions, and local environment enabled clinicians to assess a person's overall functioning during daily life outside the clinic. PD-Insighter's design offers future guidance for generalized multiperspective body motion analytics, which may significantly improve clinical decision-making and slow the functional decline of PD and other medical conditions.",Jade Kandel;Chelsea Duppen;Qian Zhang 0066;Howard Jiang;Angelos Angelopoulos;Ashley Paula-Ann Neall;Pranav Wagh;Daniel Szafir;Henry Fuchs;Michael Lewek;Danielle Albers Szafir,
CHI,2024,Go-Go Biome: Evaluation of a Casual Game for Gut Health Engagement and Reflection,10.1145/3613904.3642742,"Experts emphasise that maintaining a healthy gut microbial balance requires the public to understand factors beyond diet, such as physical activity, lifestyle, and other real-world influences. Games as experiential systems are known to foster playful engagement and reflection. We propose a novel approach to promoting activity engagement for gut health and its reflection through the design of the Go-Go Biome game. The game simulates the interplay between friendly and unfriendly gut microbes, encouraging real-world activity engagement for gut-microbial balance through interactive visuals, unstructured play mechanics, and reflective design principles. A field study with 14 participants revealed that important facets of our game design led to awareness, playful visualisation, and reflection on factors influencing gut health. Our findings suggest four design lenses– bio-temporality, visceral conversations, wellness comparison, and inner discovery, to aid future playful design explorations to foster gut health engagement and reflection.",Nandini Pasumarthy;Shreyas Nisal;Jessica Danaher;Elise van den Hoven;Rohit Ashok Khot,
CHI,2024,SalChartQA: Question-driven Saliency on Information Visualisations,10.1145/3613904.3642942,"Understanding the link between visual attention and users' information needs when visually exploring information visualisations is under-explored due to a lack of large and diverse datasets to facilitate these analyses. To fill this gap we introduce SalChartQA – a novel crowd-sourced dataset that uses the BubbleView interface to track user attention and a question-answering (QA) paradigm to induce different information needs in users. SalChartQA contains 74,340 answers to 6,000 questions on 3,000 visualisations. Informed by our analyses demonstrating the close correlation between information needs and visual saliency, we propose the first computational method to predict question-driven saliency on visualisations. Our method outperforms state-of-the-art saliency models for several metrics, such as the correlation coefficient and the Kullback-Leibler divergence. These results show the importance of information needs for shaping attentive behaviour and pave the way for new applications, such as task-driven optimisation of visualisations or explainable AI in chart question-answering.",Yao Wang;Weitian Wang;Abdullah Abdelhafez;Mayar Elfares;Zhiming Hu;Mihai Bâce;Andreas Bulling,
CHI,2024,MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation,10.1145/3613904.3642730,"This paper investigates new data exploration experiences that enable blind users to interact with statistical data visualizations—bar plots, heat maps, box plots, and scatter plots—leveraging multimodal data representations. In addition to sonification and textual descriptions that are commonly employed by existing accessible visualizations, our MAIDR (multimodal access and interactive data representation) system incorporates two additional modalities (braille and review) that offer complementary benefits. It also provides blind users with the autonomy and control to interactively access and understand data visualizations. In a user study involving 11 blind participants, we found the MAIDR system facilitated the accurate interpretation of statistical visualizations. Participants exhibited a range of strategies in combining multiple modalities, influenced by their past interactions and experiences with data visualizations. This work accentuates the overlooked potential of combining refreshable tactile representation with other modalities and elevates the discussion on the importance of user autonomy when designing accessible data visualizations.",Jooyoung Seo;Yilin Xia;Bongshin Lee;Sean McCurry;Yu Jun Yam,
CHI,2024,To Cut or Not To Cut? A Systematic Exploration of Y-Axis Truncation,10.1145/3613904.3642102,"Y-axis truncation is a well-known, much-debated visualization practice. Our work complements existing empirical work by providing a systematic analysis of y-axis truncation on grouped bar charts. Drawing upon theoretical frameworks such as Algebraic Visualization Design, we examine how structure-preserving modifications to visualization affect user performance by systematically dividing the space of possible truncations according to their monotonicity and the type of relations in the underlying data. Our results demonstrate that for comparing and estimating the difference between the lengths of two bars, truncating the y-axis does not affect task performance. For comparing or estimating the relative growth between two bars, truncating monotonically has similar performance to no truncation, while truncating non-monotonically is very likely to impair performance. We discuss possible extensions of our work and recommendations for y-axis truncation. All supplementary materials are available at https://osf.io/k4hjd/?view_only=008b087fc3d94be7ba0ce7aea95012a7.",Sheng Long;Matthew Kay 0003,
CHI,2024,Effects of Point Size and Opacity Adjustments in Scatterplots,10.1145/3613904.3642127,"Systematically changing the size and opacity of points on scatterplots can be used to induce more accurate perceptions of correlation by viewers. Evidence points to the mechanisms behind these effects being similar, so one may expect their combination to be additive regarding their effects on correlation estimation. We present a fully-reproducible study in which we combine techniques for influencing correlation perception to show that in reality, effects of changing point size and opacity interact in a non-additive fashion. We show that there is a great deal of scope for using visual features to change viewers' perceptions of data visualizations. Additionally, we use our results to further interrogate the perceptual mechanisms at play when changing point size and opacity in scatterplots.",Gabriel Strain;Andrew J. Stewart;Paul A. Warren;Caroline Jay,
CHI,2024,Promoting Eco-Friendly Behaviour through Virtual Reality - Implementation and Evaluation of Immersive Feedback Conditions of a Virtual CO2 Calculator,10.1145/3613904.3642957,"Climate change is one of the most pressing global challenges in the 21st century. Urgent actions favoring the environment's well-being are essential to mitigate its potentially irreversible consequences. However, the delayed and often distant nature of the effects of sustainable behavior makes it challenging for individuals to connect with the issue personally. Immersive media are an opportunity to introduce innovative feedback mechanisms to highlight the urgency of behavior effects. We introduce a VR carbon calculator that visualizes users' annual carbon footprint as CO2-filled balloons over multiple periods. In a 2 × 2 design, participants calculated and visualized their carbon footprint numerically or as balloons over one or three years. We found no effect of our visualization but a significant impact of the visualized period on participants' environmental self-efficacy. These findings emphasize the importance of target-oriented design in VR behavior interventions.",Carolin Wienrich;Stephanie Vogt;Nina Döllinger;David Obremski,
CHI,2024,'We Do Not Have the Capacity to Monitor All Media': A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams,10.1145/3613904.3642368,"Computer Emergency Response Teams (CERTs) provide advisory, preventive and reactive cybersecurity services for authorities, citizens, and businesses. However, their responsibility of monitoring, analyzing, and communicating cyber threats have become challenging due to the growing volume and varying quality of information disseminated through public channels. Based on a design case study conducted from 2021 to 2023, this paper combines three iterations of expert interviews, design workshops and cognitive walkthroughs to design an automated, cross-platform and real-time cybersecurity dashboard. By adopting the notion of cyber situational awareness, the study extracts user requirements and design heuristics for enhanced threat awareness and mission awareness in CERTs, discussing the aspects of source integration, data management, customizable visualization, relationship awareness, information assessment, software integration, (inter-)organizational collaboration, and communication of stakeholder warnings.",Marc-André Kaufhold;Thea Riebe;Markus Bayer;Christian Reuter 0001,BP
CHI,2024,"""Yeah, this graph doesn't show that"": Analysis of Online Engagement with Misleading Data Visualizations",10.1145/3613904.3642448,"Attempting to make sense of a phenomenon or crisis, social media users often share data visualizations and interpretations that can be erroneous or misleading. Prior work has studied how data visualizations can mislead, but do misleading visualizations reach a broad social media audience? And if so, do users amplify or challenge misleading interpretations? To answer these questions, we conducted a mixed-methods analysis of the public's engagement with data visualization posts about COVID-19 on Twitter. Compared to posts with accurate visual insights, our results show that posts with misleading visualizations garner more replies in which the audiences point out nuanced fallacies and caveats in data interpretations. Based on the results of our thematic analysis of engagement, we identify and discuss important opportunities and limitations to effectively leveraging crowdsourced assessments to address data-driven misinformation.",Maxim Lisnic;Alexander Lex;Marina Kogan,
CHI,2024,ProInterAR: A Visual Programming Platform for Creating Immersive AR Interactions,10.1145/3613904.3642527,"AR applications commonly contain diverse interactions among different AR contents. Creating such applications requires creators to have advanced programming skills for scripting interactive behaviors of AR contents, repeated transferring and adjustment of virtual contents from virtual to physical scenes, testing by traversing between desktop interfaces and target AR scenes, and digitalizing AR contents. Existing immersive tools for prototyping/authoring such interactions are tailored for domain-specific applications. To support programming general interactive behaviors of real object(s)/environment(s) and virtual object(s)/environment(s) for novice AR creators, we propose ProInterAR, an integrated visual programming platform to create immersive AR applications with a tablet and an AR-HMD. Users can construct interaction scenes by creating virtual contents and augmenting real contents from the view of an AR-HMD, script interactive behaviors by stacking blocks from a tablet UI, and then execute and control the interactions in the AR scene. We showcase a wide range of AR application scenarios enabled by ProInterAR, including AR game, AR teaching, sequential animation, AR information visualization, etc. Two usability studies validate that novice AR creators can easily program various desired AR applications using ProInterAR.",Hui Ye;Jiaye Leng;Pengfei Xu 0002;Karan Singh;Hongbo Fu 0001,
CHI,2024,Functional Design Requirements to Facilitate Menstrual Health Data Exploration,10.1145/3613904.3642282,"Menstrual trackers currently lack the affordances required to help individuals achieve their goals beyond menstrual event predictions and symptom logging. Taking an initial step towards this aspiration, we propose, validate, and refine five functional design requirements for future interface designs that facilitate menstrual data exploration. We interviewed 30 individuals who menstruate and collected their feedback on the practical application of these requirements. To elicit ideas and impressions, we designed two proof-of-concept interfaces to use as design probes with similar core functionalities but different presentations of phase timing predictions and signal arrangement. Our analysis revealed participants' feedback regarding the presentation of predictions for menstrual-related events, the visualization of future signal patterns, personalization abilities for viewing signals relevant to their menstrual experience, the availability of resources to understand the underlying biological connections between signals, and the ability to compare multiple cycles side-by-side with context.",Georgianna Lin;Pierre-William Lessard;Minh Ngoc Le;Brenna Li;Fanny Chevalier;Khai N. Truong;Alex Mariakakis,
CHI,2024,V-FRAMER: Visualization Framework for Mitigating Reasoning Errors in Public Policy,10.1145/3613904.3642750,"Existing data visualization design guidelines focus primarily on constructing grammatically-correct visualizations that faithfully convey the values and relationships in the underlying data. However, a designer may create a grammatically-correct visualization that still leaves audiences susceptible to reasoning misleaders, e.g. by failing to normalize data or using unrepresentative samples. Reasoning misleaders are especially pernicious when presenting public policy data, where data-driven decisions can affect public health, safety, and economic development. Through textual analysis, a formative evaluation, and iterative design with 19 policy communicators, we construct an actionable visualization design framework, V-FRAMER, that effectively synthesizes ways of mitigating reasoning misleaders. We discuss important design considerations for frameworks like V-FRAMER, including using concrete examples to help designers understand reasoning misleaders, and using a hierarchical structure to support example-based accessing. We further describe V-FRAMER's congruence with current practice and how practitioners might integrate the framework into their existing workflows. Related materials available at: https://osf.io/q3uta/.",Lily W. Ge;Matthew W. Easterday;Matthew Kay 0001;Evanthia Dimara;Peter Cheng;Steven L. Franconeri,
CHI,2024,"""It is hard to remove from my eye"": Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers",10.1145/3613904.3642261,"Chinese traditional opera (Xiqu) performers often experience skin problems due to the long-term use of heavy-metal-laden face paints. To explore the current skincare challenges encountered by Xiqu performers, we conducted an online survey (N=136) and semi-structured interviews (N=15) as a formative study. We found that incomplete makeup removal is the leading cause of human-induced skin problems, especially the difficulty in removing eye makeup. Therefore, we proposed EyeVis, a prototype that can visualize the residual eye makeup and record the time make-up was worn by Xiqu performers. We conducted a 7-day deployment study (N=12) to evaluate EyeVis. Results indicate that EyeVis helps to increase Xiqu performers’ awareness about removing makeup, as well as boosting their confidence and security in skincare. Overall, this work also provides implications for studying the work of people who wear makeup on a daily basis, and helps to promote and preserve the intangible cultural heritage of practitioners.",Zeyu Xiong;Shihan Fu;Yanying Zhu;Chenqing Zhu;Xiaojuan Ma;Mingming Fan 0001,HM
CHI,2024,An Eye Gaze Heatmap Analysis of Uncertainty Head-Up Display Designs for Conditional Automated Driving,10.1145/3613904.3642219,"This paper reports results from a high-fidelity driving simulator study (N=215) about a head-up display (HUD) that conveys a conditional automated vehicle's dynamic ""uncertainty"" about the current situation while fallback drivers watch entertaining videos. We compared (between-group) three design interventions: display (a bar visualisation of uncertainty close to the video), interruption (interrupting the video during uncertain situations), and combination (a combination of both), against a baseline (video-only). We visualised eye-tracking data to conduct a heatmap analysis of the four groups' gaze behaviour over time. We found interruptions initiated a phase during which participants interleaved their attention between monitoring and entertainment. This improved monitoring behaviour was more pronounced in combination compared to interruption, suggesting pre-warning interruptions have positive effects. The same addition had negative effects without interruptions (comparing baseline & display). Intermittent interruptions may have safety benefits over placing additional peripheral displays without compromising usability.",Michael A. Gerber;Ronald Schroeter;Daniel Johnson 0001;Christian P. Janssen;Andry Rakotonirainy;Jonny Kuo;Mike Lenné,
CHI,2024,From Exploration to End of Life: Unpacking Sustainability in Physicalization Practices,10.1145/3613904.3642248,"Data physicalizations have gained prominence across domains, but their environmental impact has been largely overlooked. This work addresses this gap by investigating the interplay between sustainability and physicalization practices. We conducted interviews with experts from diverse backgrounds, followed by a survey to gather insights into how they approach physicalization projects and reflect on sustainability. Our thematic analysis revealed sustainability considerations throughout the entire physicalization life cycle—a framework that encompasses various stages in a physicalization's existence. Notably, we found no single agreed-upon definition for sustainable physicalizations, highlighting the complexity of integrating sustainability into physicalization practices. We outline sustainability challenges and strategies based on participants' experiences and propose the Sustainable Physicalization Practices (SuPPra) Matrix, providing a structured approach for designers to reflect on and enhance the environmental impact of their future physicalizations.",Luiz Morais;Georgia Panagiotidou;Sarah Hayes;Tatiana Losev;Rebecca Noonan;Uta Hinrichs,BP
CHI,2024,PriviAware: Exploring Data Visualization and Dynamic Privacy Control Support for Data Collection in Mobile Sensing Research,10.1145/3613904.3642815,"With increased interest in leveraging personal data collected from 24/7 mobile sensing for digital healthcare research, supporting user-friendly consent to data collection for user privacy has also become important. This work proposes PriviAware, a mobile app that promotes flexible user consent to data collection with data exploration and contextual filters that enable users to turn off data collection based on time and places that are considered privacy-sensitive. We conducted a user study (N = 58) to explore how users leverage data exploration and contextual filter functions to explore and manage their data and whether our system design helped users mitigate their privacy concerns. Our findings indicate that offering fine-grained control is a promising approach to raising users' privacy awareness under the dynamic nature of the pervasive sensing context. We provide practical privacy-by-design guidelines for mobile sensing research.",Hyunsoo Lee;Yugyeong Jung;Hei Yiu Law;Seolyeong Bae;Uichin Lee,
CHI,2024,Momentary Stressor Logging and Reflective Visualizations: Implications for Stress Management with Wearables,10.1145/3613904.3642662,"Commercial wearables from Fitbit, Garmin, and Whoop have recently introduced real-time notifications based on detecting changes in physiological responses indicating potential stress. In this paper, we investigate how these new capabilities can be leveraged to improve stress management. We developed a smartwatch app, a smartphone app, and a cloud service, and conducted a 100-day field study with 122 participants who received prompts triggered by physiological responses several times a day. They were asked whether they were stressed, and if so, to log the most likely stressor. Each week, participants received new visualizations of their data to self-reflect on patterns and trends. Participants reported better awareness of their stressors, and self-initiating fourteen kinds of behavioral changes to reduce stress in their daily lives. Repeated self-reports over 14 weeks showed reductions in both stress intensity (in 26,521 momentary ratings) and stress frequency (in 1,057 weekly surveys).",Sameer Neupane;Mithun Saha;Nasir Ali;Timothy Hnat;Shahin Alan Samiei;Anandatirtha Nandugudi;David M. Almeida;Santosh Kumar 0001,
CHI,2024,Looking Together ≠ Seeing the Same Thing: Understanding Surgeons' Visual Needs During Intra-operative Coordination and Instruction,10.1145/3613904.3641929,"Shared gaze visualizations have been found to enhance collaboration and communication outcomes in diverse HCI scenarios including computer supported collaborative work and learning contexts. Given the importance of gaze in surgery operations, especially when a surgeon trainer and trainee need to coordinate their actions, research on the use of gaze to facilitate intra-operative coordination and instruction has been limited and shows mixed implications. We performed a field observation of 8 surgeries and an interview study with 14 surgeons to understand their visual needs during operations, informing ways to leverage and augment gaze to enhance intra-operative coordination and instruction. We found that trainees have varying needs in receiving visual guidance which are often unfulfilled by the trainers' instructions. It is critical for surgeons to control the timing of the gaze-based visualizations and effectively interpret gaze data. We suggest overlay technologies, e.g., gaze-based summaries and depth sensing, to augment raw gaze in support of surgical coordination and instruction.",Vitaliy Popov;Xinyue Chen;Jingying Wang;Michael Kemp;Gurjit Sandhu;Taylor Kantor;Natalie Mateju;Xu Wang 0016,HM
CHI,2024,Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users,10.1145/3613904.3642753,"Spreadsheets are widely used for storing, manipulating, analyzing, and visualizing data. Features such as conditional formatting, formulas, sorting, and filtering play an important role when understanding and analyzing data in spreadsheets. They employ visual cues, but we have little understanding of the experiences of blind screen reader (SR) users with such features. We conducted a study with 12 blind SR users to gain insights into their challenges, workarounds, and strategies in understanding and extracting information from a spreadsheet consisting of multiple tables that incorporated data analysis features. We identified five factors that impact blind SR users' experiences: cognitive overload, time-information trade-off, lack of awareness and expertise, inadequate system feedback, and delayed and absent SR responses. Drawn from these findings, we discuss design suggestions and future research agenda to improve SR users' spreadsheet experiences.",Minoli Perera;Bongshin Lee;Eun Kyoung Choe;Kim Marriott,
CHI,2024,Milliways: Taming Multiverses through Principled Evaluation of Data Analysis Paths,10.1145/3613904.3642375,"Multiverse analyses involve conducting all combinations of reasonable choices in a data analysis process. A reader of a study containing a multiverse analysis might question—are all the choices included in the multiverse reasonable and equally justifiable? How much do results vary if we make different choices in the analysis process? In this work, we identify principles for validating the composition of, and interpreting the uncertainty in, the results of a multiverse analysis. We present Milliways, a novel interactive visualisation system to support principled evaluation of multiverse analyses. Milliways provides interlinked panels presenting result distributions, individual analysis composition, multiverse code specification, and data summaries. Milliways supports interactions to sort, filter and aggregate results based on the analysis specification to identify decisions in the analysis process to which the results are sensitive. To represent the two qualitatively different types of uncertainty that arise in multiverse analyses—probabilistic uncertainty from estimating unknown quantities of interest such as regression coefficients, and possibilistic uncertainty from choices in the data analysis—Milliways uses consonance curves and probability boxes. Through an evaluative study with five users familiar with multiverse analysis, we demonstrate how Milliways can support multiverse analysis tasks, including a principled assessment of the results of a multiverse analysis.",Abhraneel Sarma;Kyle Hwang;Jessica Hullman;Matthew Kay 0001,
CHI,2024,"""Ah! I see"" - Facilitating Process Reflection in Gameplay through a Novel Spatio-Temporal Visualization System",10.1145/3613904.3642484,"Educational games have emerged as potent tools for helping students understand complex concepts and are now ubiquitous in global classrooms, amassing vast data. However, there is a notable gap in research concerning the effective visualization of this data to serve two key functions: (a) guiding students in reflecting upon their game-based learning and (b) aiding them in analyzing peer strategies. In this paper, we engage educators, students, and researchers as essential stakeholders. Taking a Design-Based Research (DBR) approach, we incorporate UX design methods to develop an innovative visualization system that helps players learn through gaining insights from their own and peers' gameplay and strategies.",Sai Siddartha Maram;Erica Kleinman;Jennifer Villareale;Jichen Zhu;Magy Seif El-Nasr,
CHI,2002,Polyarchy visualization: visualizing multiple intersecting hierarchies,10.1145/503376.503452,"We describe a new information structure composed of multiple intersecting hierarchies, which we call Polyarchies. Visualizing polyarchies enables use of novel views for discovery of relationships which are very difficult using existing hierarchy visualization tools. This paper will describe the visualization design and system architecture challenges as well as our current solutions. A Mid-Tier Cache architecture is used as a ""polyarchy server"" which supports a novel web-based polyarchy visualization technique, called Visual Pivot. A series of five user studies guided iterative design of Visual Pivot",George G. Robertson;Kim Cameron;Mary Czerwinski;Daniel C. Robbins,
